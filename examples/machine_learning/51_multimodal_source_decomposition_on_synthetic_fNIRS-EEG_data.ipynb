{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "#  Multimodal Source Decomposition on Realistic fNIRS-EEG Data with Synthetic Ground Truth\n",
    "\n",
    "In this example notebook we apply a set of source decomposition methods to a realistic fNIRS-EEG data with synthetic groung truth, created for this purpose, and report on their performance. \n",
    "\n",
    "We divide the notebook in two parts, the first one contains the synthetic data generation pipeline, step by step. It ends in the creation of a few temporary files that are then used to test the source decomposition methods. In the second part of the notebook we test the source decomposition methods in the data we just created, beginning with some preprocessing steps that bring the \"raw\" synthetic data to a suitable format for the method's inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cells setups the environment when executed in Google Colab.\n",
    "try:\n",
    "    import google.colab\n",
    "    !curl -s https://raw.githubusercontent.com/ibs-lab/cedalion/colab_setup/scripts/colab_setup.py -o colab_setup.py\n",
    "    # Select branch with --branch \"branch name\" (default is \"dev\")\n",
    "    %run colab_setup.py\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for the entire notebook\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import xarray as xr\n",
    "import mne\n",
    "from mne.decoding import SSD\n",
    "import pyvista as pv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from scipy.signal import detrend, butter, lfilter, hilbert\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import cedalion\n",
    "import cedalion.datasets\n",
    "import cedalion.imagereco.forward_model as fw\n",
    "import cedalion.sigproc.quality as quality\n",
    "from cedalion.sigproc.frequency import sampling_rate, freq_filter\n",
    "import cedalion.plots as cp\n",
    "import cedalion.io as cio\n",
    "from cedalion.io.probe_geometry import load_tsv\n",
    "from cedalion.vis import plot_sensitivity_matrix\n",
    "from cedalion import units\n",
    "from cedalion.sim.synthetic_hrf import build_spatial_activation, build_stim_df, plot_spatial_activation\n",
    "import cedalion.models.glm as glm\n",
    "\n",
    "from sklearn.decomposition import PCA as PCA_sk\n",
    "from cedalion.sigdecomp.multimodal.cca_models import ElasticNetCCA, StructuredSparseCCA, CCA, RidgeCCA\n",
    "from cedalion.sigdecomp.multimodal.mspoc import mSPoC\n",
    "from cedalion.sigdecomp.multimodal.tcca_models import ElasticNetTCCA, StructuredSparseTCCA, tCCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to load required files from cedalion web server\n",
    "\n",
    "import pooch\n",
    "from pathlib import Path\n",
    "\n",
    "DATASETS = pooch.create(\n",
    "    path=pooch.os_cache(\"cedalion\"),\n",
    "    base_url=\"https://doc.ibs.tu-berlin.de/cedalion/datasets\",\n",
    "    registry={\n",
    "        \"multimodal_eeg_fnirs_paper_files.zip\": \"sha256:08f4fd0c13a790028848ed06803e5d84c33cb83ab7d5de0a0338b949191acbd3\",  # noqa: E501\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "def get_paper_files():\n",
    "    fnames = DATASETS.fetch(\n",
    "        \"multimodal_eeg_fnirs_paper_files.zip\", processor=pooch.Unzip()\n",
    "    )\n",
    "\n",
    "    basedir = Path(fnames[0]).parent\n",
    "\n",
    "    # fmt: off\n",
    "    files = {\n",
    "        \"BACKGROUND_fNIRS_DIR\": str(basedir / \"fnirs_colocalized_raw.nc\"),\n",
    "        \"BACKGROUND_EEG_DIR\":   str(basedir / \"eeg_colocalized_raw.fif\"),\n",
    "        \"MONTAGE_DIR\":          str(basedir / \"montage_bilateral_colocalized.tsv\"),\n",
    "        \"MEASLIST_DIR\":         str(basedir / \"meas_list_bilateral_colocalized.csv\"),\n",
    "        \"SENSITIVITY_DIR\":      str(basedir / \"sensitivity_bilateral_colocalized.nc\"),\n",
    "        \"LEADFIELD_DIR\":        str(basedir / \"lf_simbio_7996_nirfasterVol_colocalized.mat\"),\n",
    "    }\n",
    "    # fmt: on\n",
    "\n",
    "    return basedir, files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Synthetic data\n",
    "\n",
    "In this section we walk trhough the pipeline for generating a realistic fNIRS-EEG data with synthetic ground truth. The resulting dataset comprises biologically plausible EEG-fNIRS neural activity, ensuring shared spatiotemporal co-modulation between sources, localized in the primary motor cortex, via simultaneous EEG alpha-band suppression and oxygenated hemoglobin increase in fNIRS. The simulated neural activity sits on top of a real concurrent HD-fNIRS-EEG recording from a single subject at rest, providing correlation between underlying processes already at noise level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "basedir, files = get_paper_files()\n",
    "BACKGROUND_fNIRS_DIR = files[\"BACKGROUND_fNIRS_DIR\"]\n",
    "BACKGROUND_EEG_DIR = files[\"BACKGROUND_EEG_DIR\"]\n",
    "MONTAGE_DIR = files[\"MONTAGE_DIR\"]\n",
    "MEASLIST_DIR = files[\"MEASLIST_DIR\"]\n",
    "SENSITIVITY_DIR = files[\"SENSITIVITY_DIR\"]\n",
    "LEADFIELD_DIR = files[\"LEADFIELD_DIR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To store temporal variables and datasets\n",
    "TMP_DIR = str(basedir / 'tmp')\n",
    "os.makedirs(TMP_DIR, exist_ok=True)\n",
    "\n",
    "# Some globabl parameters \n",
    "source_location_landmark = 'C3' # Left motor cortex\n",
    "source_freq = (8, 12) # Alpha band"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Background Data\n",
    "\n",
    "To produce realistic background noise underlying the simulated experiment, we collected five minutes of real concurrent HD-fNIRS-EEG resting state data from a single subject."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fNIRS background data\n",
    "fnirs_bg = xr.load_dataarray(BACKGROUND_fNIRS_DIR) \n",
    "wl1, wl2 = fnirs_bg.wavelength.data\n",
    "\n",
    "# Load EEG and EOG background data\n",
    "electrodes_bg = mne.io.read_raw_fif(BACKGROUND_EEG_DIR, preload=True)\n",
    "\n",
    "# Store maximum simulation time\n",
    "T_sim = np.min([float(fnirs_bg.time[-1]), float(electrodes_bg.times[-1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "#### Montage and measurement list\n",
    "\n",
    "The fNIRS dataset comprises optical-density (OD) recordings at two wavelengths (760nm and 850nm) across 100 measurement channels, created by pairings of 14 light sources and 32 detectors arranged in a bilateral high-density hexagonal grid over the motor cortex, with sourceâ€“detector separations of 19mm and 33mm. EEG data represents electrical activity collected from the 32-channel actiCAP arrangement. fNIRS data was recorded by two NIRSport2 devices (NIRx GmbH, Berlin, Germany) at 12.6 Hz sampling rate. EEG data was collected using a 32-channel LiveAmp amplifier (Brain Products GmbH, Gilching, Germany) with active Ag/AgCl electrodes mounted in the NinjaCap following the actiCAP arrangement. The sites normally occupied by FT9, FT10, T7, and T8 were repurposed to record horizontal and vertical EOG channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load montage\n",
    "montage = load_tsv(tsv_fname=MONTAGE_DIR, crs=None, units=None)\n",
    "# Load measurement list\n",
    "meas_list = pd.read_csv(MEASLIST_DIR, sep=',', index_col=0)\n",
    "n_channels_fnirs = len(meas_list)//2\n",
    "channels_fnirs = meas_list['channel'].to_numpy()[:n_channels_fnirs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "#### Small preprocessing on fNIRS background data\n",
    "\n",
    "We now perform a small preprocessing on the background data, required before adding the synthetic stimuli on top. This includes channel prunning via SCI and PSP quality metrics, convertion to OD, and detrending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Channel prunning\n",
    "\n",
    "# Calculate masks for SCI and PSP quality metrics\n",
    "window_length = 5 * units.s\n",
    "sci_thresh = 0.75\n",
    "psp_thresh = 0.1\n",
    "sci_psp_percentage_thresh = 0.75\n",
    "\n",
    "sci, sci_mask = quality.sci(fnirs_bg, window_length, sci_thresh)\n",
    "psp, psp_mask = quality.psp(fnirs_bg, window_length, psp_thresh)\n",
    "sci_x_psp_mask = sci_mask & psp_mask\n",
    "perc_time_clean = sci_x_psp_mask.sum(dim=\"time\") / len(sci.time)\n",
    "sci_psp_mask = [perc_time_clean >= sci_psp_percentage_thresh]\n",
    "\n",
    "# Prune channels that do not pass at least one of the quality test\n",
    "fnirs_bg_pruned, drop_list = quality.prune_ch(fnirs_bg, sci_psp_mask, \"all\")\n",
    "\n",
    "# Display pruned channels and resulting clean signal\n",
    "print(f\"List of pruned channels: {drop_list}  ({len(drop_list)})\")\n",
    "\n",
    "## Convert to OD\n",
    "fnirs_bg_od = cedalion.nirs.int2od(fnirs_bg_pruned)\n",
    "\n",
    "## Detrend\n",
    "fnirs_bg_detrended = fnirs_bg_od.copy()\n",
    "fnirs_bg_detrended.data = detrend(fnirs_bg_detrended.data, axis=2, type='linear')\n",
    "\n",
    "## Final clean version of brackground data\n",
    "fnirs_bg_preprocessed = fnirs_bg_detrended.copy()\n",
    "\n",
    "## Store sampling rate and channel names\n",
    "fnirs_bg_rate = sampling_rate(fnirs_bg_preprocessed.time).magnitude\n",
    "fnirs_bg_channels = fnirs_bg_preprocessed.channel.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "##### Visualize preprocessed fNIRS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the percentage of clean time per channel\n",
    "f, ax = plt.subplots(1, 1, figsize=(5,5))\n",
    "\n",
    "cedalion.plots.scalp_plot(\n",
    "    fnirs_bg,\n",
    "    montage,\n",
    "    perc_time_clean,\n",
    "    ax,\n",
    "    cmap=\"RdYlGn\",\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    title=None,\n",
    "    cb_label=\"Percentage of clean time\",\n",
    "    channel_lw=2\n",
    ")\n",
    "f.tight_layout()\n",
    "\n",
    "# Plot timeseries of the clean data\n",
    "fnirs_ch_to_plot = ['S1D7', 'S1D8'] # [c for c in fnirs_bg_preprocessed.channel.values if 'S1D' in c]\n",
    "f, ax = plt.subplots(len(fnirs_ch_to_plot), 1, figsize=(15, 3*len(fnirs_ch_to_plot)), sharex=True)\n",
    "\n",
    "for i, c in enumerate(fnirs_ch_to_plot):\n",
    "    ax[i].plot(fnirs_bg_preprocessed.time, fnirs_bg_preprocessed.sel(channel=c, wavelength=wl1), label=wl1)\n",
    "    ax[i].plot(fnirs_bg_preprocessed.time, fnirs_bg_preprocessed.sel(channel=c, wavelength=wl2), label=wl2)\n",
    "    ax[i].set_title(f\"Channel {c}\")\n",
    "    ax[i].legend()\n",
    "    ax[i].set_xlabel(\"time (s)\")\n",
    "    ax[i].set_ylabel(\"OD\")\n",
    "    ax[i].grid()\n",
    "\n",
    "plt.xlim(50, 100)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once satisfied with the preprocessing, save background data for later use\n",
    "fnirs_bg_preprocessed.to_netcdf(os.path.join(TMP_DIR, \"fnirs_bg_preprocessed.nc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "#### Small preprocessing on EEG and EOG background data\n",
    "\n",
    "We now perform a small preprocessing on the EEG and EOG background data. We begin with some temporal preprocessing, including detrending, band-pass filtering, and subsampling. We then follow with the identification of bad channels and their interpolation using information from the remaining \"good\" channels, together with average rereferencing. Finally, we remove as much alpha motor activity from EEG data as possible so true sources do not interfere with our synthetically generated ones. To this end, we use the spatio-spectral decomposition (SSD) algorithm (Nikulin et al., 2011) to identify alpha-band neural oscillations and remove the components whose highest activity lay in the left-motor region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_neighbor_channels(data, channel):\n",
    "    \"\"\"\n",
    "    Find the nearest neighbor channel to the target channel.\n",
    "    \"\"\"\n",
    "    \n",
    "    all_channels = data.info['chs']\n",
    "    ch_pos = [c['loc'][:3] for c in all_channels if c['ch_name']==channel][0]\n",
    "    \n",
    "    # Compute Euclidean distance between the target and each other channel.\n",
    "    distances = {}\n",
    "    for ch in all_channels:\n",
    "        ch_name = ch['ch_name']\n",
    "        if ch_name == channel:\n",
    "            continue\n",
    "        pos = ch['loc'][:3]\n",
    "        \n",
    "        # Check position has right format\n",
    "        if pos is None or len(pos) < 3:\n",
    "            raise ValueError('Position with wrong format found...')\n",
    "            \n",
    "        dist = np.linalg.norm(np.array(pos) - np.array(ch_pos))\n",
    "        distances[ch_name] = dist\n",
    "    \n",
    "    # Identify the channels with the smallest distance.\n",
    "    min_dist = min(distances.values())\n",
    "    \n",
    "    nearest_channels = [k for k, v in distances.items() if np.isclose(v, min_dist, rtol=1e-1)]   \n",
    "    nearest_channels += [channel]\n",
    "    \n",
    "    return nearest_channels, min_dist\n",
    "\n",
    "def remove_sources(data, target_channels, freqs_sig, step=1, only_target=False):\n",
    "    \"\"\"\n",
    "    Decompose data into components, recognize those sources that are most similar to the ones\n",
    "    we want to add synthetically and subtract them.\n",
    "    \"\"\"\n",
    "\n",
    "    freqs_noise = [freqs_sig[0] - step, freqs_sig[1] + step]\n",
    "\n",
    "    # Initialize SSD algorithm\n",
    "    ssd = SSD(\n",
    "        info=data.info,\n",
    "        reg=\"oas\",\n",
    "        sort_by_spectral_ratio=True,\n",
    "        filt_params_signal=dict(\n",
    "            l_freq=freqs_sig[0],\n",
    "            h_freq=freqs_sig[1],\n",
    "            l_trans_bandwidth=1,\n",
    "            h_trans_bandwidth=1,\n",
    "        ),\n",
    "        filt_params_noise=dict(\n",
    "            l_freq=freqs_noise[0],\n",
    "            h_freq=freqs_noise[1],\n",
    "            l_trans_bandwidth=1,\n",
    "            h_trans_bandwidth=1,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Fit\n",
    "    ssd.fit(X=data.get_data())\n",
    "    # Transform\n",
    "    ssd_sources = ssd.transform(X=data.get_data())\n",
    "    # Get spatial patterns (invers of filtes)\n",
    "    patterns = ssd.patterns_\n",
    "\n",
    "    data_subtracted = data.copy()\n",
    "    for t_ch in target_channels:\n",
    "        # Get nearest channels to the target source\n",
    "        nearest_channels, _ = find_nearest_neighbor_channels(data, t_ch)\n",
    "\n",
    "        # Get indices of patterns whose highest activity is located at the nearest channels\n",
    "        relevant_pattern_ndx = []\n",
    "        for i, max_ndx in enumerate(np.argmax(patterns, axis=1)):\n",
    "            max_ch = data.info['chs'][max_ndx]['ch_name']\n",
    "            if only_target:\n",
    "                if max_ch == t_ch:\n",
    "                    relevant_pattern_ndx.append(i)\n",
    "            else:\n",
    "                if max_ch in nearest_channels:\n",
    "                    relevant_pattern_ndx.append(i)\n",
    "\n",
    "        if not len(relevant_pattern_ndx):\n",
    "            print(f\"No source found with highest-activty in the neighbourhood of {t_ch}\\n\")\n",
    "            print(f\"We therefore omit the subtraction for this channel...\")\n",
    "            continue\n",
    "\n",
    "        # Build reconstructed signal from selected sources\n",
    "        reconstructed_ssd = patterns[relevant_pattern_ndx].T @ ssd_sources[relevant_pattern_ndx]\n",
    "\n",
    "        # Subtract reconstructed source from original data\n",
    "        data_subtracted._data = data_subtracted.get_data() - reconstructed_ssd\n",
    "\n",
    "    return data_subtracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "electrodes_bg_tmp = electrodes_bg.copy()\n",
    "\n",
    "# Define frequency band of interest\n",
    "l_freq = 0.1  # Low cut-off frequency in Hz\n",
    "h_freq = 45  # High cut-off frequency in Hz\n",
    "new_freq = 100  # New sampling frequency in Hz\n",
    "\n",
    "# Detrend\n",
    "electrodes_bg_tmp._data = mne.filter.detrend(electrodes_bg_tmp.get_data(), order=1)\n",
    "# Apply band-pass filtering and detrending\n",
    "electrodes_bg_tmp.filter(l_freq=l_freq, h_freq=h_freq, method='fir', phase='zero')\n",
    "# Dowsample\n",
    "electrodes_bg_tmp.resample(new_freq)\n",
    "\n",
    "# Mark bad channels\n",
    "electrodes_bg_preprocessed_ch = electrodes_bg_tmp.copy()\n",
    "bad_channels = ['C4', 'P4', 'P8', 'P7', 'O1', 'CP5', 'O2', 'C3']  # Selected manually via prior visualization\n",
    "electrodes_bg_preprocessed_ch.info['bads'] = bad_channels\n",
    "# Interpolate\n",
    "electrodes_bg_preprocessed_ch.interpolate_bads(reset_bads=True); # Reset_bad=true remove bad-channel labels from interpolated channels\n",
    "\n",
    "# Re-reference data via average\n",
    "electrodes_bg_preprocessed_ref = electrodes_bg_preprocessed_ch.copy()\n",
    "electrodes_bg_preprocessed_ref.set_eeg_reference('average', projection=True)\n",
    "electrodes_bg_preprocessed_ref.apply_proj()\n",
    "\n",
    "# Split preprocessed data into EEG and EOG\n",
    "eeg_bg_preprocessed = electrodes_bg_preprocessed_ref.copy().pick(picks=['eeg'])\n",
    "eog = electrodes_bg_preprocessed_ref.copy().pick(picks=['eog'])\n",
    "\n",
    "# Remove sources already present in the background data in the same frequency and location to our synthetic source\n",
    "eeg_bg_preprocessed = remove_sources(eeg_bg_preprocessed, [source_location_landmark], freqs_sig=source_freq)\n",
    "\n",
    "# Convert to xarrays\n",
    "eeg_bg_preprocessed_xr = xr.DataArray(data=eeg_bg_preprocessed._data, \n",
    "                      coords={'channel': eeg_bg_preprocessed.ch_names, 'time': eeg_bg_preprocessed.times})\n",
    "eeg_bg_preprocessed_xr = eeg_bg_preprocessed_xr.assign_coords({'time': eeg_bg_preprocessed_xr.time.assign_attrs({'units': units.s}),\n",
    "                                                               'samples': ('time', np.arange(0, len(eeg_bg_preprocessed_xr.time)))})\n",
    "\n",
    "eog = xr.DataArray(eog._data, \n",
    "                   dims=[\"channel\", \"time\"],\n",
    "                   coords={\"channel\": eog.info['ch_names'],\n",
    "                           'time': eog.times,\n",
    "                           'samples': ('time', np.arange(0, len(eog.times)))})\n",
    "\n",
    "# Store sampling rate and channel names\n",
    "eeg_bg_rate = sampling_rate(eeg_bg_preprocessed_xr.time).magnitude\n",
    "eeg_bg_channels = eeg_bg_preprocessed_xr.channel.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "##### Visualize preprocessed EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_bg_preprocessed.plot_psd(fmin=0, fmax=50)\n",
    "eeg_bg_preprocessed.plot(start=50, duration=10, scalings='auto', show=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When satisfied with the preprocessing, save background data for later use\n",
    "eeg_bg_preprocessed_xr = eeg_bg_preprocessed_xr.assign_coords({'time': eeg_bg_preprocessed_xr.time.pint.dequantify()})\n",
    "eeg_bg_preprocessed_xr.to_netcdf(os.path.join(TMP_DIR, \"eeg_bg_preprocessed.nc\"))\n",
    "eog.to_netcdf(os.path.join(TMP_DIR, \"eog.nc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Source spatial profiles\n",
    "\n",
    "We now build the spatial profiles for the simulated sources. The end-result of this step are the mixing matrices for fNIRS and EEG forward models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "#### Headmodel \n",
    "\n",
    "The source spatial profiles share the same head model of the anatomy of Colin27, segmentation masks (gray/white matter, air, CSF, bone, and skin surfaces), FEM volume mesh, and source location. The latter was chosen to be the point in the brain surface closest to the C3 landmark on the scalp. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load paths to segmentation data for the Colin27 atlas\n",
    "SEG_DIR, mask_files, landmarks_file = cedalion.datasets.get_colin27_segmentation()\n",
    "\n",
    "head = fw.TwoSurfaceHeadModel.from_segmentation(\n",
    "            segmentation_dir=SEG_DIR,\n",
    "            mask_files = mask_files,\n",
    "            landmarks_ras_file=landmarks_file,\n",
    "            brain_face_count=180000,\n",
    "            scalp_face_count=60000,\n",
    "            smoothing=0.5,\n",
    "            fill_holes=True,\n",
    "        )\n",
    "\n",
    "# Set correct units\n",
    "head.brain.units = units.mm\n",
    "head.scalp.units = units.mm\n",
    "head.landmarks = head.landmarks.pint.dequantify()\n",
    "head.landmarks.pint.units = units.mm\n",
    "\n",
    "# Build surfaces for eeg forward model\n",
    "head_eeg = fw.TwoSurfaceHeadModel.from_segmentation(\n",
    "            segmentation_dir=SEG_DIR,\n",
    "            mask_files = mask_files,\n",
    "            landmarks_ras_file=landmarks_file,\n",
    "            brain_face_count=7996,\n",
    "            scalp_face_count=60000,\n",
    "            smoothing=0.5,\n",
    "            fill_holes=True,\n",
    "        )\n",
    "\n",
    "dipoles = head_eeg.brain.vertices\n",
    "orientations = head_eeg.brain.mesh.vertex_normals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align headmodel with montage\n",
    "# montage = head.align_and_snap_to_scalp(montage)\n",
    "\n",
    "# Visualize headmodel with montage\n",
    "plt_pv = pv.Plotter()\n",
    "cp.plot_surface(plt_pv, head.brain, color=\"#d3a6a1\")\n",
    "cp.plot_surface(plt_pv, head.scalp, opacity=.1)\n",
    "cp.plot_labeled_points(plt_pv, montage, show_labels=True)\n",
    "plt_pv.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "#### Sensitivity matrix\n",
    "\n",
    "The sensitivity matrix is calculated via photon simulation using NIRFASTer (Dehghani et al., 2009) within Cedalion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate or load sensitivity matrix\n",
    "LOAD_SENSITIVITY = True\n",
    "\n",
    "if LOAD_SENSITIVITY:\n",
    "    print(\"Loading sensitivity...\")\n",
    "    sensitivity = cio.forward_model.load_Adot(SENSITIVITY_DIR)\n",
    "    if 'source' not in sensitivity.coords._names:\n",
    "        source = [d.split('D')[0] for d in sensitivity.channel.data]\n",
    "        sensitivity = sensitivity.assign_coords({'source': ('channel', source)})\n",
    "    if 'detector' not in sensitivity.coords._names:\n",
    "        detector = ['D' + d.split('D')[1] for d in sensitivity.channel.data]\n",
    "        sensitivity = sensitivity.assign_coords({'detector': ('channel', detector)})\n",
    "    \n",
    "else:\n",
    "    print(\"Calculating sensitivity matrix...\")\n",
    "    fwm = cedalion.imagereco.forward_model.ForwardModel(head, montage, meas_list)\n",
    "    fluence_all, fluence_at_optodes = fwm.compute_fluence_nirfaster()\n",
    "    sensitivity = fwm.compute_sensitivity(fluence_all, fluence_at_optodes)\n",
    "    # Save\n",
    "    cio.forward_model.save_Adot(SENSITIVITY_DIR, sensitivity)\n",
    "\n",
    "# Restrict to only brain vertices, not scalp\n",
    "sensitivity = sensitivity[:, (sensitivity.is_brain).values,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "#### Leadfield matrix\n",
    "\n",
    "The EEG leadfield is computed with the SimBio FEM solver (Vorwerk et al., 2018) as integrated in the FieldTrip MATLAB toolbox (Oostenveld et al., 2011). Since, MATLAB is required for this step, here we simply load the leadfield file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Leadfield matrix\n",
    "lf_all = loadmat(LEADFIELD_DIR, simplify_cells=True)['lf']\n",
    "lf_data = lf_all['leadfield']\n",
    "lf_channel_labels = lf_all['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "#### Source spatial distributions\n",
    "\n",
    "For the modality-specific spatial information, we used a single dipole structure for EEG, and for fNIRS we generated a Gaussian-distributed activity mask, both centered around the common source location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find closest brain vertex to landmark and its cortex location\n",
    "source_location_landmark = 'C3'\n",
    "source_location = montage.sel(label=source_location_landmark)  # Get coordinates on scalp\n",
    "# Find closest vertex on brain for fNIRS\n",
    "seed_vertex_fnirs = head.brain.mesh.kdtree.query(source_location.pint.dequantify())[1]\n",
    "# Find closest vertex on brain (dipole) for EEG\n",
    "seed_vertex_eeg = head_eeg.brain.kdtree.query(source_location.pint.dequantify())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build fnirs spatial activation\n",
    "s_spatial_fnirs = build_spatial_activation(head_model=head,\n",
    "                                           seed_vertex=seed_vertex_fnirs,\n",
    "                                           spatial_scale= 20 * units.mm,\n",
    "                                           intensity_scale= 1 * units.micromolar,\n",
    "                                           hbr_scale=-0.4)\n",
    "# Visualize activity\n",
    "plot_spatial_activation(s_spatial_fnirs.sel(chromo='HbO'), brain=head.brain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "#### Mixing matrices\n",
    "\n",
    "The previously computed forward matrices are then used to create fNIRS and EEG mixing matrices by combining them with the modality-specific spatial information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build fNIRS mixing matrix\n",
    "# Stack chromo and vertex directions\n",
    "s_stacked = fw.stack_flat_vertex(s_spatial_fnirs)\n",
    "\n",
    "# Compute stacked senstivity via extintion coefficient multiplication\n",
    "sensitivity_stacked = fw.ForwardModel.compute_stacked_sensitivity(sensitivity)\n",
    "\n",
    "# Map signal to channel space\n",
    "A_stacked = sensitivity_stacked @ s_stacked\n",
    "\n",
    "# Undo stacking of channels in flat_channel dimension\n",
    "A_fnirs = fw.unstack_flat_channel(A_stacked)\n",
    "A_fnirs = A_fnirs.pint.dequantify()\n",
    "A_fnirs.attrs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build EEG mixing matrix\n",
    "A_eeg = lf_data[:, seed_vertex_eeg, :] @ np.array([-0.2412535 ,  0.9619893 , -0.12795832]) # orientations[seed_vertex_eeg, :]  Pick a specific normal for reproducibility, altough it can be easily changed\n",
    "A_eeg = xr.DataArray(data=A_eeg, \n",
    "                     coords={'channel': lf_channel_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize EEG mixing matrix as topomap\n",
    "A = A_eeg.copy()\n",
    "info = mne.create_info(ch_names=A.channel.data.tolist(), sfreq=100, ch_types=['eeg'] * A.shape[0])\n",
    "raw = mne.io.RawArray(A.data.reshape(-1, 1), info); \n",
    "# Set the electrode layout\n",
    "raw.set_montage(mne.channels.make_standard_montage('easycap-M1'))\n",
    "\n",
    "# Normalize\n",
    "A /= np.abs(A).max()\n",
    "min_max = (A.min(), A.max())\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "im, cn = mne.viz.plot_topomap(A.data, raw.info, axes=ax, show=False, vlim=min_max); \n",
    "cax = fig.colorbar(im, ax=ax)\n",
    "cax.set_label(r'Activity (A.U)')\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save mixing matrices for later use\n",
    "A_fnirs.to_netcdf(os.path.join(TMP_DIR,'A_fnirs.nc'))\n",
    "A_eeg.to_netcdf(os.path.join(TMP_DIR,'A_eeg.nc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "### Source temporal profiles\n",
    "\n",
    "We now build the temporal profiles for the simulated sources. The end-result of this step are the time courses of the fNIRS and EEG sources we want to reconstruct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "#### Experiment stimuli simulation\n",
    "\n",
    "The simulated experiment consists of one single block composed of approximately 12 trials, each of which begins with a 10-second stimulus period followed by a recovery period whose duration is randomly chosen between 8 and 16 seconds. Each trial is assigned a randomly generated \"value\", that is later used to scale the increase in the fNIRS HRF and the decrease in the EEG alpha bandpower (ERD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build experimental stimuli\n",
    "def simulate_experiment_markers(T_stim, T_rest_min, T_rest_max, stim_amp_min, stim_amp_max, source_location_landmark):\n",
    "        \"\"\" Simulate experiment markers.\n",
    "        \"\"\"\n",
    "\n",
    "        stim = build_stim_df(\n",
    "                max_time= T_sim * units.seconds,\n",
    "                trial_types=[source_location_landmark],\n",
    "                min_interval=T_rest_min * units.s,\n",
    "                max_interval=T_rest_max * units.s,\n",
    "                min_stim_dur=T_stim * units.s,\n",
    "                max_stim_dur=T_stim * units.s,\n",
    "                min_stim_value=stim_amp_min,\n",
    "                max_stim_value=stim_amp_max,\n",
    "                order=\"random\",\n",
    "                )\n",
    "\n",
    "        # Build derived quantities\n",
    "        simulation_rate = eeg_bg_rate\n",
    "        Nt_sim = int(T_sim * simulation_rate)  # Number of timepoints of simulation\n",
    "        time_sim = np.linspace(0, T_sim, Nt_sim)\n",
    "\n",
    "        return stim, time_sim\n",
    "\n",
    "T_stim = 10\n",
    "T_rest_min = 8\n",
    "T_rest_max = 16\n",
    "stim_amp_min = 0.5\n",
    "stim_amp_max = 0.8\n",
    "\n",
    "stim, time_sim = simulate_experiment_markers(T_stim, T_rest_min, T_rest_max, stim_amp_min, stim_amp_max, source_location_landmark)\n",
    "stim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "#### fNIRS temporal profile\n",
    "\n",
    "The fNIRS source is modeled using canonical hemodynamic response functions time-locked to the stimuli onsets, including the typical hemodynamic time delay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fnirs_temporal_profile(stim, time_sim, fnirs_bg):\n",
    "    \"\"\"Build fNIRS source temporal profile.\n",
    "    \"\"\"\n",
    "\n",
    "    Nt_sim = len(time_sim)\n",
    "    trial_type = stim.trial_type.unique()[0]\n",
    "    wl2 = fnirs_bg.wavelength.values[1]\n",
    "\n",
    "    # Choose basis for HRF\n",
    "    basis_hrf = glm.Gamma(tau=0 * units.s, sigma=3 * units.s, T=3 * units.s)\n",
    "\n",
    "    # Build synthetic HRF timeseries\n",
    "    ts_tmp = fnirs_bg[:, :, 0] * xr.DataArray(time_sim, coords={'time': time_sim})  # Little hack to get the right time dimension\n",
    "    ts_tmp = ts_tmp.assign_coords({'samples': ('time', np.arange(0, Nt_sim))})  \n",
    "    ts_tmp.time.attrs[\"units\"] = \"second\"\n",
    "    s_temporal_fnirs = glm.design_matrix.hrf_regressors(ts_tmp, stim, basis_hrf).common\n",
    "    s_temporal_fnirs = s_temporal_fnirs.assign_coords({\"regressor\": [trial_type]}).rename({\"regressor\": \"trial_type\"})\n",
    "    s_temporal_fnirs = s_temporal_fnirs.sel(trial_type=trial_type, wavelength=wl2, drop=True)\n",
    "    s_temporal_fnirs = s_temporal_fnirs.assign_coords({'samples': ('time', np.arange(0, len(s_temporal_fnirs.time)))})\n",
    "\n",
    "    return s_temporal_fnirs\n",
    "\n",
    "s_temporal_fnirs = build_fnirs_temporal_profile(stim, time_sim, fnirs_bg_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "#### EEG temporal profile\n",
    "\n",
    "The EEG source is created using band-limited (8â€“12 Hz) noise modulated by slow task-related temporal envelopes, generating an instantaneous power decay during stimuli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_lowpass_filter(data, cut, fs, order=5):\n",
    "    \n",
    "    nyq = 0.5 * fs\n",
    "    cut = cut / nyq\n",
    "    b, a = butter(order, cut, btype='low')\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def drop_by_logistic_functions(t, d, w=0.2):\n",
    "    \"\"\"Compute an envelope that smoothly drops from 1 to (1-d).\n",
    "    \n",
    "    Parameters:\n",
    "        t  : array-like\n",
    "             Time points.\n",
    "        d  : float\n",
    "             Drop amplitude (0 < d < 1).\n",
    "        w  : float\n",
    "             Controls the steepness of the transitions.\n",
    "    \n",
    "    Returns:\n",
    "        envelope : array-like\n",
    "                   The multiplicative envelope.\n",
    "    \"\"\"\n",
    "\n",
    "    # Make borders smoother by starting to drop a bit separated from borders\n",
    "    duration = t[-1] - t[0]\n",
    "    shift = duration * 0.1\n",
    "    t0 = t[0] + shift \n",
    "    t1 = t[-1] - shift\n",
    "\n",
    "    rising = 1 / (1 + np.exp(-(t - t0) / w))\n",
    "    falling = 1 / (1 + np.exp(-(t - t1) / w))\n",
    "    \n",
    "    return 1 - d * (rising - falling)\n",
    "\n",
    "def build_eeg_temporal_profile(stim, time_sim, simulation_rate):\n",
    "    \"\"\"Build EEG source temporal profile.\n",
    "    \"\"\"\n",
    "\n",
    "    Nt_sim = len(time_sim)\n",
    "\n",
    "    # Simulate amplitude-modulated signal\n",
    "    noise = np.random.normal(0, 1, Nt_sim)\n",
    "    s_temporal_eeg_amp = butter_lowpass_filter(noise, cut=.5, fs=simulation_rate, order=4)\n",
    "    s_temporal_eeg_amp += np.abs(s_temporal_eeg_amp.min()) # Add offset to make it positive\n",
    "    s_temporal_eeg_amp /= s_temporal_eeg_amp.max()  # Normalize\n",
    "\n",
    "    # Drop amplitude at each stimulus location\n",
    "    smpl_start = time_sim.searchsorted(stim['onset'])\n",
    "    smpl_stop = time_sim.searchsorted(stim['onset'] + stim['duration'])\n",
    "\n",
    "    for start, stop, value in zip(smpl_start, smpl_stop, stim['value']):\n",
    "        envelope_drop = drop_by_logistic_functions(time_sim[start:stop], d=value, w=0.2)   \n",
    "        s_temporal_eeg_amp[start:stop] = s_temporal_eeg_amp[start:stop] * envelope_drop\n",
    "\n",
    "    # Simulate a random oscillatory source in a specific frequency band\n",
    "    freq_band = (8, 12)\n",
    "\n",
    "    # Define signal in frequency-domain (unit amplitude and random phases)\n",
    "    T = time_sim[-1]\n",
    "    f_min_ndx, f_max_ndx = int(freq_band[0]*T), int(freq_band[1]*T)\n",
    "    Fs = np.zeros(Nt_sim, dtype=complex)\n",
    "    Fs[f_min_ndx: f_max_ndx] = 1 * np.e**(1j * np.random.uniform(0, 2*np.pi, (f_max_ndx - f_min_ndx)))\n",
    "\n",
    "    # Get temporal-domain signal from inverse FT\n",
    "    s_temporal_eeg_osc = np.fft.ifft(Fs).real\n",
    "    osc_env = np.abs(hilbert(s_temporal_eeg_osc))  # Signal envelope\n",
    "    s_temporal_eeg_osc /= osc_env  # Normalize envelope to 1.\n",
    "\n",
    "    # Multiply oscillatory signal by modulated amplitude to get final temporal profile\n",
    "    s_temporal_eeg = s_temporal_eeg_osc * s_temporal_eeg_amp\n",
    "\n",
    "    # Convert to xarray\n",
    "    s_temporal_eeg = xr.DataArray(data=s_temporal_eeg, \n",
    "                                dims=['time'],\n",
    "                                coords={'time': time_sim})\n",
    "    s_temporal_eeg = s_temporal_eeg.assign_coords({'samples': ('time', np.arange(0, len(s_temporal_eeg.time)))})\n",
    "\n",
    "    s_temporal_eeg_amp = xr.DataArray(data=s_temporal_eeg_amp,\n",
    "                                dims=['time'],\n",
    "                                coords={'time': time_sim})\n",
    "    s_temporal_eeg_amp = s_temporal_eeg_amp.assign_coords({'samples': ('time', np.arange(0, len(s_temporal_eeg_amp.time)))})\n",
    "\n",
    "    return s_temporal_eeg, s_temporal_eeg_amp\n",
    "\n",
    "s_temporal_eeg, s_temporal_eeg_amp = build_eeg_temporal_profile(stim, time_sim, eeg_bg_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "### Forward models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply forward models\n",
    "fnirs_sim = A_fnirs * s_temporal_fnirs\n",
    "eeg_sim =  A_eeg * s_temporal_eeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize final simulated data\n",
    "ch_fnirs = 'S1D7'\n",
    "ch_eeg = 'C3'\n",
    "xlim = (60, 150)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 5), sharex=True) \n",
    "\n",
    "ax1.plot(fnirs_sim.time, fnirs_sim.sel(wavelength=wl1, channel=ch_fnirs), label=wl1)\n",
    "ax1.plot(fnirs_sim.time, fnirs_sim.sel(wavelength=wl2, channel=ch_fnirs), label=wl2)\n",
    "for on, off in zip(stim.onset.values, stim.onset.values + stim.duration.values):\n",
    "    ax1.axvline(on, color='k', ls='-', alpha=0.5)\n",
    "    ax1.axvline(off, color='k', ls='--', alpha=0.5)\n",
    "ax1.set_title(f'fNIRS Source at channel {ch_fnirs}')\n",
    "ax1.set_xlim(*xlim)\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(eeg_sim.time, eeg_sim.sel(channel=ch_eeg))\n",
    "for on, off in zip(stim.onset.values, stim.onset.values + stim.duration.values):\n",
    "    ax2.axvline(on, color='k', ls='-', alpha=0.5)\n",
    "    ax2.axvline(off, color='k', ls='--', alpha=0.5)\n",
    "ax2.set_xlim(*xlim)\n",
    "ax2.set_title(f'EEG Source at channel {ch_eeg}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "### Add background to simulated data\n",
    "\n",
    "We now use the background data as realistic noise on top of the simulated stimulus. For that, we first bring simulated and background datasets to compatible formats by restricting them to the same number of channels and sampling rate. Then, the synthetic activity is activity is added to the background data with a scaling parameter $\\gamma$ that allows regulating the SNR. (Here we pick a very high value of $gamma$ just for visualization purposes!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_background(fnirs_bg, eeg_bg, fnirs_sim, eeg_sim, gamma):\n",
    "\n",
    "    # Read channels\n",
    "    fnirs_bg_channels = fnirs_bg.channel.values\n",
    "    eeg_bg_channels = eeg_bg.channel.values\n",
    "\n",
    "    # Restrict simulated data to non-prunned channels\n",
    "    fnirs_sim_compatible = fnirs_sim.sel(channel=fnirs_bg_channels)\n",
    "    eeg_sim_compatible = eeg_sim.sel(channel=eeg_bg_channels)\n",
    "\n",
    "    # Downsample simulated time series to the rate of the smallest one\n",
    "    fnirs_sim_compatible = fnirs_sim_compatible.sel(time=fnirs_bg.time, method='nearest')\n",
    "    fnirs_sim_compatible = fnirs_sim_compatible.assign_coords({'samples': ('time', fnirs_bg.samples.values)})\n",
    "    eeg_sim_compatible = eeg_sim_compatible.sel(time=eeg_bg.time, method='nearest')\n",
    "    eeg_sim_compatible = eeg_sim_compatible.assign_coords({'samples': ('time', eeg_bg.samples.values)})\n",
    "\n",
    "    # Identify channel with maximum simulated activity\n",
    "    ch_max_eeg = np.abs(eeg_sim_compatible).max(dim='time').argmax(dim='channel').data\n",
    "    ch_max_fnirs = np.abs(fnirs_sim_compatible).max(dim=['time', 'wavelength']).argmax(dim='channel').data\n",
    "\n",
    "    # Scale simulated data to match amplitude of background data\n",
    "    eeg_sim_compatible *= np.linalg.norm(eeg_bg.data[ch_max_eeg])/np.linalg.norm(eeg_sim_compatible.data[ch_max_eeg])\n",
    "    for i in range(2):\n",
    "        fnirs_sim_compatible[i] *= np.linalg.norm(fnirs_bg.data[i, ch_max_fnirs])/np.linalg.norm(fnirs_sim_compatible.data[i, ch_max_fnirs])\n",
    "\n",
    "    # Add gamma-scaled simulated data to background noise\n",
    "    fnirs =fnirs_sim_compatible.copy()\n",
    "    fnirs.data = gamma * fnirs_sim_compatible.data + fnirs_bg.data\n",
    "    eeg = eeg_sim_compatible.copy()\n",
    "    eeg.data = gamma * eeg_sim_compatible.data + eeg_bg.data\n",
    "\n",
    "    return fnirs, eeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add background data to simulated data (pick very high value just for visualization!)\n",
    "fnirs, eeg = add_background(fnirs_bg_preprocessed, eeg_bg_preprocessed_xr, fnirs_sim, eeg_sim, gamma=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize final realistic simulated data\n",
    "ch_fnirs = 'S1D7'\n",
    "ch_eeg = 'C3'\n",
    "xlim = (60, 100)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 8), sharex=True) \n",
    "\n",
    "ax1.plot(fnirs.time, fnirs.sel(wavelength=wl1, channel=ch_fnirs), 'b-', label=wl1)\n",
    "ax1.plot(fnirs_bg_preprocessed.time, fnirs_bg_preprocessed.sel(wavelength=wl1, channel=ch_fnirs), 'b--', label=f'{wl1} background')\n",
    "ax1.plot(fnirs.time, fnirs.sel(wavelength=wl2, channel=ch_fnirs), color='orange', ls='-', label=wl2)\n",
    "ax1.plot(fnirs_bg_preprocessed.time, fnirs_bg_preprocessed.sel(wavelength=wl2, channel=ch_fnirs), color='orange', ls='--', label=f'{wl2} background')\n",
    "for on, off in zip(stim.onset.values, stim.onset.values + stim.duration.values):\n",
    "    ax1.axvline(on, color='k', ls='-', alpha=0.5)\n",
    "    ax1.axvline(off, color='k', ls='--', alpha=0.5)\n",
    "ax1.set_title(f'fNIRS {ch_fnirs}')\n",
    "ax1.set_xlim(*xlim)\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(eeg.time, eeg.sel(channel=ch_eeg), 'g-', alpha=0.5)\n",
    "ax2.plot(eeg_bg_preprocessed_xr.time, eeg_bg_preprocessed_xr.sel(channel=ch_eeg), 'r-', alpha=0.5, label='background')\n",
    "for on, off in zip(stim.onset.values, stim.onset.values + stim.duration.values):\n",
    "    ax2.axvline(on, color='k', ls='-', alpha=0.5)\n",
    "    ax2.axvline(off, color='k', ls='--', alpha=0.5)\n",
    "ax2.set_xlim(*xlim)\n",
    "ax2.set_title(f'EEG {ch_eeg}')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "## Source decomposition methods\n",
    "\n",
    "In this section we apply some source decomposition methods on the synthetic data and test and compare their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "The synthetic data corresponds to the raw data as it would come directly from an experiment. We now apply a preprocessing pipeline to fNIRS and EEG data individually to bring it a curated format to which we can apply our source decomposition methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(x, new_time=None, new_rate=None):\n",
    "    \"\"\"Downsample signal x to match new rate.\n",
    "\n",
    "    The subsampled signal is obtained by separating x in equal-size bins and \n",
    "    averaging within them. The new time is defined by the closest time point in x to\n",
    "    the a new downsampled time, time_ds.\n",
    "    \"\"\"\n",
    "    if new_rate:\n",
    "        time_ds = np.arange(x.time[0].data, x.time[-1].data, 1/new_rate)  # Miss last point\n",
    "        time_ds = np.append(time_ds, x.time[-1].data)  # Add last time point\n",
    "        new_time = x.time[x.time.searchsorted(time_ds)] \n",
    "\n",
    "    N = len(new_time)\n",
    "    x_ds = x.groupby_bins(group='time', bins=N).mean().rename({'time_bins': 'time'}).assign_coords({'time': new_time})\n",
    "\n",
    "    return x_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "#### fNIRS\n",
    "\n",
    "fNIRS preprocessing involves channel pruning using the scalp coupling index and peak spectral power quality metrics (Pollonini et al., 2016), bandpass filtering from 0.01 Hz to 0.6 Hz to remove cardiac component and slow drifts, linear detrending, and 2 Hz dowsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_fnirs(fnirs, s_temporal_fnirs, rate_ds, T_sim, wl2=850., source_location_landmark='C3'):\n",
    "\n",
    "    # fNIRS data and ground truth source\n",
    "    y = fnirs.sel(wavelength=wl2).copy().transpose('time', 'channel')\n",
    "    y = y.assign_coords({'time': y.time.assign_attrs({'units': cedalion.units.s})})\n",
    "    sy = s_temporal_fnirs.copy().expand_dims({'source': [source_location_landmark]}).transpose('time', 'source')\n",
    "\n",
    "    # Bandpass filter\n",
    "    fmin = 0.01 * units.Hz\n",
    "    fmax = 0.6 * units.Hz\n",
    "    y = freq_filter(y, fmin, fmax)\n",
    "\n",
    "    # Downsample\n",
    "    time_ds = np.append(np.arange(0, T_sim, 1/rate_ds), T_sim)\n",
    "    N_ds = len(time_ds)\n",
    "    y = y.groupby_bins(group='time', bins=N_ds).mean().rename({'time_bins': 'time'}).assign_coords({'time': time_ds})\n",
    "    sy = sy.groupby_bins(group='time', bins=N_ds).mean().rename({'time_bins': 'time'}).assign_coords({'time': time_ds})\n",
    "\n",
    "    return y, sy\n",
    "\n",
    "y, sy = preprocess_fnirs(fnirs, s_temporal_fnirs, rate_ds=4, T_sim=T_sim, wl2=wl2, source_location_landmark=source_location_landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot preprrocessed fNIRS data\n",
    "fnirs_ch_to_plot = ['S1D7', 'S1D8'] # [c for c in fnirs_bg_preprocessed.channel.values if 'S1D' in c]\n",
    "f, ax = plt.subplots(len(fnirs_ch_to_plot), 1, figsize=(15, 3*len(fnirs_ch_to_plot)), sharex=True)\n",
    "\n",
    "for i, c in enumerate(fnirs_ch_to_plot):\n",
    "    ax[i].plot(y.time, y.sel(channel=c))\n",
    "    ax[i].set_title(f\"Channel {c}\")\n",
    "    ax[i].legend()\n",
    "    ax[i].set_xlabel(\"time (s)\")\n",
    "    ax[i].set_ylabel(\"OD\")\n",
    "    ax[i].grid()\n",
    "\n",
    "plt.xlim(50, 150)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "#### EEG\n",
    "\n",
    "For EEG data we already performed substantial preprocessing before adding the synthetic stimuli. The remaining steps involve a linear EOG regression algorithm for ocular artifact removal, and bandpass filtering in the alpha band. In this step, we also estimate time course bandpower by splitting the data into equal-length segments and calculating the per-segment variance, resulting in an effective 2 Hz downsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EOG_removal(eeg, eog):\n",
    "    \"\"\"Apply a linear regression method via least squares to remove EOG contributions from EEG channels.\n",
    "    \"\"\"\n",
    "\n",
    "    # Bring them to desired format\n",
    "    eeg = eeg.transpose('channel', 'time')\n",
    "    eog = eog.transpose('channel', 'time')\n",
    "\n",
    "    # Define matrices of the linear model\n",
    "    S_artifact = eog.data\n",
    "    X = eeg.data\n",
    "\n",
    "    # Estimate linear projection via least squares\n",
    "    S_artifact_pinv = sp.linalg.pinv(S_artifact)  # Moore-Penrose pseudoinverse\n",
    "    A_artifact = X @ S_artifact_pinv\n",
    "    \n",
    "    # Construct artifact contribution to EEG channels\n",
    "    A_artifact_pinv = sp.linalg.pinv(A_artifact)\n",
    "    X_artifact = (A_artifact @ A_artifact_pinv) @ X\n",
    "\n",
    "    # Subtract from original EEG channels to get a clean version of them\n",
    "    X_clean = X - X_artifact\n",
    "\n",
    "    # Substitute clean data in xArray\n",
    "    eeg_clean = eeg.copy()\n",
    "    eeg_clean.data = X_clean\n",
    "\n",
    "    # Bring back to original format\n",
    "    eeg_clean = eeg_clean.transpose('time', 'channel')\n",
    "\n",
    "    return eeg_clean\n",
    "\n",
    "\n",
    "def preprocess_eeg(eeg, eog, s_temporal_eeg_amp, rate_ds, T_sim, source_location_landmark='C3'):\n",
    "    \"\"\"Preprocess EEG data.\n",
    "    \"\"\"\n",
    "\n",
    "    # EEG data and ground truth source\n",
    "    x = eeg.copy()\n",
    "    x = x.assign_coords({'time': x.time.assign_attrs({'units': cedalion.units.s})}).transpose('time', 'channel')\n",
    "    sx = s_temporal_eeg_amp.copy().expand_dims({'source': [source_location_landmark]}).transpose('time', 'source')\n",
    "\n",
    "    # Apply a linear regression method via least squares to remove EOG contributions from EEG channels\n",
    "    x = EOG_removal(x, eog)\n",
    "\n",
    "    # Bandpass filter in the alpha band range\n",
    "    x = freq_filter(x, fmin=8 * units.Hz, fmax=12 * units.Hz)\n",
    "\n",
    "    # Divide original EEG data into epochs, matching new downsampled time, and estimate power as within-epoch variance.\n",
    "    time_ds = np.append(np.arange(0, T_sim, 1/rate_ds), T_sim)\n",
    "    N_ds = len(time_ds)\n",
    "    x_power = x.groupby_bins(group='time', bins=N_ds).var().rename({'time_bins': 'time'}).assign_coords({'time': time_ds})\n",
    "\n",
    "    # Downsample ground truth \n",
    "    sx = sx.groupby_bins(group='time', bins=N_ds).mean().rename({'time_bins': 'time'}).assign_coords({'time': time_ds})\n",
    "\n",
    "    return x, x_power, sx\n",
    "\n",
    "x, x_power, sx = preprocess_eeg(eeg, eog, s_temporal_eeg_amp, rate_ds=4, T_sim=T_sim, source_location_landmark=source_location_landmark)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot preprrocessed fNIRS data\n",
    "eeg_ch_to_plot = ['C3', 'CP6', 'C4']\n",
    "f, ax = plt.subplots(len(eeg_ch_to_plot), 1, figsize=(15, 3*len(eeg_ch_to_plot)), sharex=True)\n",
    "\n",
    "for i, c in enumerate(eeg_ch_to_plot):\n",
    "    ax[i].plot(x.time, x.sel(channel=c))\n",
    "    ax[i].plot(x_power.time, x_power.sel(channel=c), label='Power')\n",
    "    ax[i].set_title(f\"Channel {c}\")\n",
    "    ax[i].legend()\n",
    "    ax[i].set_xlabel(\"time (s)\")\n",
    "    ax[i].grid()\n",
    "    # ax[i].set_ylim(-10, 20)\n",
    "\n",
    "plt.xlim(50, 150)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "### Split into trials and train/test sets\n",
    "\n",
    "We divide the three datasets, namely fNIRS, EEG, and EEG bandpower time series, into individual trials, composed of the stimulus period (10s) plus pre and post-stimulus resting periods of constant length (4s) each. We then perform a random 80%/20% train/test set split, resulting in 10 and 2 trials, respectively. Trials in the train set are then concatenated along the time direction to generate a single time-course input dataset for each modality, while test trials are kept separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x, dim='time', scale=True):\n",
    "    \"\"\"Standardize x along dimension dim. \n",
    "    \"\"\"\n",
    "\n",
    "    mean = x.mean(dim=dim)\n",
    "\n",
    "    if scale:\n",
    "        std = x.std(dim=dim)\n",
    "        std[std==0] = 1  # Avoid division by 0\n",
    "    else:\n",
    "        std = xr.ones_like(mean)\n",
    "    \n",
    "    x_standard = (x - mean)/std\n",
    "        \n",
    "    return x_standard\n",
    "\n",
    "def shuffle_datasets(*datasets, seed=None):\n",
    "    \"\"\"Shuffle multiple datasets using the same shuffled indices.\n",
    "    \n",
    "    Args:\n",
    "        *datasets: Arrays or lists of the same length to be shuffled.\n",
    "        seed: Optional random seed for reproducibility.\n",
    "        \n",
    "    Returns:\n",
    "        A tuple of shuffled datasets.\n",
    "    \"\"\"\n",
    "    if not datasets:\n",
    "        raise ValueError(\"No datasets provided.\")\n",
    "    \n",
    "    length = len(datasets[0])\n",
    "    for dataset in datasets:\n",
    "        if len(dataset) != length:\n",
    "            raise ValueError(\"All datasets must have the same length.\")\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(length)\n",
    "    \n",
    "    shuffled_datasets = [[dataset[i] for i in indices] for dataset in datasets]\n",
    "    \n",
    "    return shuffled_datasets\n",
    "\n",
    "def train_test_split(datasets_dict, train_size=0.2, seed=None):\n",
    "    \"\"\"Split multiple datasets into training and testing sets using the same shuffle order.\n",
    "    \n",
    "    Args:\n",
    "        datasets_dict: Dictionary containing equal-length datasets to be split.\n",
    "        test_size: Proportion of the dataset to include in the test split (default 0.2).\n",
    "        seed: Optional random seed for reproducibility.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing the train/test splits for each dataset.\n",
    "    \"\"\"\n",
    "    labels = datasets_dict.keys()\n",
    "    datasets = list(datasets_dict.values())\n",
    "\n",
    "    shuffled_datasets = shuffle_datasets(*datasets, seed=seed)\n",
    "    split_idx = int(len(datasets[0]) * train_size)\n",
    "    \n",
    "    train_dict = {}\n",
    "    test_dict = {}\n",
    "    for label, dataset in zip(labels, shuffled_datasets):\n",
    "        train_dict[f\"{label}\"] = dataset[:split_idx]\n",
    "        test_dict[f\"{label}\"] = dataset[split_idx:]\n",
    "    \n",
    "    return train_dict, test_dict\n",
    "\n",
    "\n",
    "def aggregate_trials(trials_dict, time_trial):\n",
    "    \"\"\"Combine trials by concatenating them along the time dimension.\n",
    "    \"\"\"\n",
    "    \n",
    "    T_trial = time_trial[-1]\n",
    "    N_trials = len(list(trials_dict.values())[0])\n",
    "    time_train = np.concatenate([time_trial + i * T_trial for i in range(N_trials)])\n",
    "    \n",
    "    trials_aggregated_dict = {}\n",
    "    for k, trials in trials_dict.items():\n",
    "        trials_aggregated = xr.concat(trials, dim='time').assign_coords({'time': time_train})\n",
    "        trials_aggregated_dict[k] = trials_aggregated\n",
    "    \n",
    "    return trials_aggregated_dict, time_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_trials(t_rest, stim, x, x_power, y, sx, sy):\n",
    "    \"\"\"Split datasets into trials\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare times to split into trials\n",
    "    ti_trials = stim.onset.values - t_rest\n",
    "    tf_trials = stim.onset.values + stim.duration.values  + t_rest\n",
    "\n",
    "    # Since trial sizes may differ due to rounding errors, we truncate them using this minimum value\n",
    "    time_ds = y.time\n",
    "    ti_ndx_y, tf_ndx_y = time_ds.searchsorted(ti_trials), time_ds.searchsorted(tf_trials)\n",
    "    trial_size_y = (tf_ndx_y - ti_ndx_y).min()\n",
    "    # Split donsampled timeseries into trials\n",
    "    time_trials = [time_ds[i:f][:trial_size_y] for i, f in zip(ti_ndx_y, tf_ndx_y)]\n",
    "    x_power_trials = [standardize(x_power[i:f][:trial_size_y], dim='time') for i, f in zip(ti_ndx_y, tf_ndx_y)]\n",
    "    y_trials = [standardize(y[i:f][:trial_size_y], dim='time') for i, f in zip(ti_ndx_y, tf_ndx_y)]\n",
    "    sx_trials = [standardize(sx[i:f][:trial_size_y], dim='time') for i, f in zip(ti_ndx_y, tf_ndx_y)]\n",
    "    sy_trials = [standardize(sy[i:f][:trial_size_y], dim='time') for i, f in zip(ti_ndx_y, tf_ndx_y)]\n",
    "\n",
    "    # Split x into trials and truncate their time to coincide with x_power_trials time.\n",
    "    time_x = x.time\n",
    "    ti_x = [t.time[0].data for t in x_power_trials]\n",
    "    tf_x = [t.time[-1].data for t in x_power_trials]\n",
    "    ti_ndx_x, tf_ndx_x = time_x.searchsorted(ti_x), time_x.searchsorted(tf_x)\n",
    "    trial_size_x = (tf_ndx_x - ti_ndx_x).min()\n",
    "\n",
    "    time_trials_x = [time_x.sel(time=slice(i, f))[:trial_size_x] for i, f in zip(ti_x, tf_x)]\n",
    "    x_trials = [standardize(x.sel(time=slice(i, f))[:trial_size_x], dim='time') for i, f in zip(ti_x, tf_x)]\n",
    "\n",
    "    # Align initial and final times of trials to the ones of x_power_trials\n",
    "    for xt, xpt in zip(x_trials, x_power_trials):\n",
    "        xt.time.data[0] = xpt.time.data[0]\n",
    "        xt.time.data[-1] = xpt.time.data[-1]\n",
    "\n",
    "    # Pick a representative time trial\n",
    "    time_trial = time_trials[0]\n",
    "    time_trial = time_trial - time_trial[0] # Remove onsets\n",
    "\n",
    "    # And a representative trial for x, which is not downsampled\n",
    "    time_trial_x = time_trials_x[0]\n",
    "    time_trial_x = time_trial_x - time_trial_x[0] # Remove onsets\n",
    "\n",
    "    # Split datasets into training and testing sets using the same shuffle order\n",
    "    trials_dict = {'x': x_trials, \n",
    "                    'x_power': x_power_trials,\n",
    "                    'y': y_trials, \n",
    "                    'sx': sx_trials, \n",
    "                    'sy': sy_trials}\n",
    "    \n",
    "    return trials_dict, time_trial, time_trial_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split datasets into trials\n",
    "trials_dict, time_trial, time_trial_x = split_into_trials(T_rest_min // 2, stim, x, x_power, y, sx, sy)\n",
    "\n",
    "# Train/test split\n",
    "train_size = 0.8\n",
    "train_dict, test_dict = train_test_split(trials_dict, train_size)\n",
    "# Separate the only dataset that has a different sampling rate (x)\n",
    "x_train_dict = {'x': train_dict.pop('x')}\n",
    "\n",
    "# Aggregate trials: concatenate all train trials into a continuous train set\n",
    "train_aggregated_dict, time_train = aggregate_trials(train_dict, time_trial)\n",
    "x_train_aggregated_dict, time_train_x = aggregate_trials(x_train_dict, time_trial_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize aggregated train data\n",
    "fnirs_ch = 'S1D8'\n",
    "eeg_ch = 'C3'\n",
    "ndx = 0\n",
    "\n",
    "x_power_train = train_aggregated_dict['x_power'].sel(channel=eeg_ch)\n",
    "x_train = x_train_aggregated_dict['x'].sel(channel=eeg_ch)\n",
    "y_train = train_aggregated_dict['y'].sel(channel=fnirs_ch)\n",
    "sx_train = train_aggregated_dict['sx']\n",
    "sy_train = train_aggregated_dict['sy']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.plot(y_train.time, y_train, 'r-', label='fNIRS')\n",
    "plt.plot(x_train.time, x_train, 'k-', label='EEG', alpha=0.5)\n",
    "plt.plot(x_power_train.time, x_power_train, 'b-', label='EEG Power')\n",
    "plt.plot(sy_train.time, sy_train, 'r--', label='Sy')\n",
    "plt.plot(sx_train.time, sx_train, 'b--', label='Sx')\n",
    "plt.title(f\"Aggregated train trial at channels {fnirs_ch} and {eeg_ch}\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"time (s)\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a single test trial\n",
    "fnirs_ch = 'S1D8'\n",
    "eeg_ch = 'C3'\n",
    "ndx = 0\n",
    "\n",
    "x_power_test = test_dict['x_power'][ndx].sel(channel=eeg_ch)\n",
    "x_test = test_dict['x'][ndx].sel(channel=eeg_ch)\n",
    "y_test = test_dict['y'][ndx].sel(channel=fnirs_ch)\n",
    "sx_test = test_dict['sx'][ndx]\n",
    "sy_test = test_dict['sy'][ndx]\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.plot(y_test.time, y_test, 'r-', label='fNIRS')\n",
    "plt.plot(x_test.time, x_test, 'k-', label='EEG', alpha=0.5)\n",
    "plt.plot(x_power_test.time, x_power_test, 'b-', label='EEG Power')\n",
    "plt.plot(sy_test.time, sy_test, 'r--', label='Sy')\n",
    "plt.plot(sx_test.time, sx_test, 'b--', label='Sx')\n",
    "plt.title(f\"Single test trial at channel {fnirs_ch} and {eeg_ch}\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"time (s)\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "### Test methods performance \n",
    "\n",
    "We now run 50 simulations with 12 trials each. Each simulation produce different temporal profiles for the EEG and fNIRS true sources due to the randomness in stimulus amplitudes and recovery times, but the source spatial profiles and the background data are always\n",
    "the same. For each simulation, we combine synthetic and background data using 20 different SNR values, from -25 dB to 10 dB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "#### Helper functions\n",
    "\n",
    "Before running the simulations, we build some helper functions to run the full simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_trial_correlations(x, y, sx_gt, sy_gt, model):\n",
    "    \"\"\"\n",
    "    Transform x and y and using model and compare the resulting sources with the groun truth sources.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute sources\n",
    "    sx, sy = model.transform(x, y)\n",
    "    sx, sy = standardize(sx).T, standardize(sy).T\n",
    "    # Fix mismatch dimensions due to time shift and truncated padding\n",
    "    Ntx = len(sx.time)\n",
    "    Nty = len(sy.time)\n",
    "    \n",
    "    if Ntx < len(sx_gt.time):\n",
    "        sx_gt = sx_gt[:, :Ntx]\n",
    "    if Nty < len(sy_gt.time):\n",
    "        sy_gt = sy_gt[:, :Nty]\n",
    "\n",
    "    # Compute cross correlations\n",
    "    corrx = np.corrcoef(sx_gt[0], sx[0])[0, 1]\n",
    "    corry = np.corrcoef(sy_gt[0], sy[0])[0, 1]\n",
    "    \n",
    "    return corrx, corry\n",
    "\n",
    "def compute_spatial_pattern_correlations(x, y, Ax, Ay, wx, wy):\n",
    "    \"\"\"Compute correlations between estimated and true spatial patterns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Make sure channels are aligned\n",
    "    x = x.sel(channel=wx.channel)\n",
    "    y = y.sel(channel=wy.channel)\n",
    "    Ax = Ax.sel(channel=wx.channel).data  # Also truncate when necessary\n",
    "    Ay = Ay.sel(channel=wy.channel).data\n",
    "\n",
    "    Ax_model = compute_spatial_pattern_from_weight(x, wx).T\n",
    "    Ay_model = compute_spatial_pattern_from_weight(y, wy).T\n",
    "\n",
    "    # Compute correlations\n",
    "    corrx = np.abs(np.corrcoef(Ax_model[0], Ax)[0, 1])\n",
    "    corry = np.abs(np.corrcoef(Ay_model[0], Ay)[0, 1])\n",
    "\n",
    "    return corrx, corry\n",
    "\n",
    "def compute_spatial_pattern_from_weight(X, W, sample_name='time', feature_name='channel'):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Bring to standard order\n",
    "    X = X.transpose(sample_name, feature_name)\n",
    "    W = W.transpose(feature_name, ...)\n",
    "    \n",
    "    # Work with numpy arrays from now on\n",
    "    N = len(X[sample_name])\n",
    "    X = X.data\n",
    "    W = W.data\n",
    "    # Covariance matrix for X\n",
    "    C = (X.T @ X) / (N - 1)\n",
    "    # Covariance matrix for reconstructed sources\n",
    "    Cs = W.T @ C @ W\n",
    "    # Estimated spattial pattern\n",
    "    A = C @ W @ sp.linalg.pinv(Cs)\n",
    "    \n",
    "    return A\n",
    "\n",
    "def run_simulation(fnirs_bg, eeg_bg, eog, A_fnirs_2wl, A_eeg, gamma_list, models, labels, simulation_parameters):\n",
    "    \n",
    "    # Read parameters from simulation_parameters\n",
    "    source_location_landmark = simulation_parameters['source_location_landmark']\n",
    "    T_sim = simulation_parameters['T_sim']\n",
    "    T_stim = simulation_parameters['T_stim']\n",
    "    T_rest_min = simulation_parameters['T_rest_min']\n",
    "    T_rest_max = simulation_parameters['T_rest_max']\n",
    "    stim_amp_min = simulation_parameters['stim_amp_min']\n",
    "    stim_amp_max = simulation_parameters['stim_amp_max']\n",
    "    simulation_rate = simulation_parameters['simulation_rate']\n",
    "    N_sim = simulation_parameters['N_sim']\n",
    "    train_size = simulation_parameters['train_size']\n",
    "    rate_ds = simulation_parameters['rate_ds']\n",
    "    var_explained = simulation_parameters['pca_var_explained']\n",
    "    \n",
    "    wl2 = fnirs_bg.wavelength.values[1]\n",
    "\n",
    "    # Initialize lists of correlations between real and reconstructed sources\n",
    "    corr_dict = {l: np.zeros([N_sim, len(gamma_list), 8]) for l in labels}\n",
    "\n",
    "    for i in range(N_sim):\n",
    "\n",
    "        print(f\"Simulation {i+1}\")\n",
    "        \n",
    "        # Simulate experiment markers\n",
    "        stim, time_sim = simulate_experiment_markers(T_stim, T_rest_min, T_rest_max, stim_amp_min, stim_amp_max, source_location_landmark)\n",
    "        # Simulate temporal profiles\n",
    "        s_temporal_fnirs = build_fnirs_temporal_profile(stim, time_sim, fnirs_bg_preprocessed)\n",
    "        s_temporal_eeg, s_temporal_eeg_amp = build_eeg_temporal_profile(stim, time_sim, simulation_rate)       \n",
    "        # Apply forward models\n",
    "        fnirs_sim = A_fnirs_2wl * s_temporal_fnirs\n",
    "        eeg_sim =  A_eeg * s_temporal_eeg\n",
    "        # Restrict to one wavelength for later \n",
    "        A_fnirs = A_fnirs_2wl.sel(wavelength=850)\n",
    "        \n",
    "        for j, gamma in enumerate(gamma_list):\n",
    "            \n",
    "            # Add background to simulated data using gamma\n",
    "            fnirs, eeg = add_background(fnirs_bg, eeg_bg, fnirs_sim, eeg_sim, gamma=gamma)\n",
    "\n",
    "            # Preprocess datasets\n",
    "            y, sy = preprocess_fnirs(fnirs, s_temporal_fnirs, rate_ds, T_sim, wl2=wl2, source_location_landmark=source_location_landmark)\n",
    "            x, x_power, sx = preprocess_eeg(eeg, eog, s_temporal_eeg_amp, rate_ds, T_sim, source_location_landmark=source_location_landmark)\n",
    "\n",
    "            # Split datasets into trials\n",
    "            trials_dict, time_trial, time_trial_x = split_into_trials(T_rest_min // 2, stim, x, x_power, y, sx, sy)\n",
    "\n",
    "            # Train/test split\n",
    "            train_dict, test_dict = train_test_split(trials_dict, train_size)\n",
    "            # Separate the only dataset that has a different sampling rate (x)\n",
    "            x_train_dict = {'x': train_dict.pop('x')}\n",
    "\n",
    "            # Aggregate trials: concatenate all train trials into a continuous train set\n",
    "            train_aggregated_dict, time_train = aggregate_trials(train_dict, time_trial)\n",
    "            x_train_aggregated_dict, time_train_x = aggregate_trials(x_train_dict, time_trial_x)\n",
    "\n",
    "            # Separate datasets\n",
    "            sx_train = train_dict['sx']\n",
    "            sy_train = train_dict['sy']\n",
    "            sx_test = test_dict['sx']\n",
    "            sy_test = test_dict['sy']\n",
    "            \n",
    "\n",
    "            for model, label in zip(models, labels):\n",
    "                if 'mSPoC' not in label:\n",
    "                    x_train_full = train_aggregated_dict['x_power']\n",
    "                    x_train = train_dict['x_power']\n",
    "                    x_test = test_dict['x_power']\n",
    "\n",
    "                    y_train_full = train_aggregated_dict['y']\n",
    "                    y_train = train_dict['y']\n",
    "                    y_test = test_dict['y']\n",
    "\n",
    "                    \n",
    "                else:\n",
    "                    x_train_full = x_train_aggregated_dict['x']\n",
    "                    x_train = x_train_dict['x']\n",
    "                    x_test = test_dict['x']\n",
    "\n",
    "                    # Run PCA\n",
    "                    # X modality\n",
    "                    pcax = PCA(N_components=var_explained)\n",
    "                    pcax.fit(x_train_full)\n",
    "                    x_train_full = pcax.transform(x_train_full)\n",
    "                    x_train = [pcax.transform(d) for d in x_train]\n",
    "                    x_test = [pcax.transform(d) for d in x_test]\n",
    "                    # Y modality\n",
    "                    pcay = PCA(N_components=var_explained)\n",
    "                    pcay.fit(y_train_full)\n",
    "                    y_train_full = pcay.transform(y_train_full)\n",
    "                    y_train = [pcay.transform(d) for d in y_train]\n",
    "                    y_test = [pcay.transform(d) for d in y_test]\n",
    "                \n",
    "                # Fit\n",
    "                model.fit(x_train_full, y_train_full)\n",
    "                \n",
    "                # Read filters\n",
    "                if model.Wx.ndim == 3:\n",
    "                    Wx = model.Wx.sel(time_shift=model.optimal_shift)[0]\n",
    "                    Wy = model.Wy\n",
    "                elif 'mSPoC' in label:\n",
    "                    Wx = pcax.inverse_transform(model.Wx.T)\n",
    "                    Wy = pcay.inverse_transform(model.Wy.T)\n",
    "                else:\n",
    "                    Wx = model.Wx\n",
    "                    Wy = model.Wy\n",
    "                \n",
    "                # Transform training data and average over them\n",
    "                n_train = len(sx_train)\n",
    "                corrx_train_avg = 0\n",
    "                corry_train_avg = 0\n",
    "                Acorrx_train_avg = 0\n",
    "                Acorry_train_avg = 0\n",
    "\n",
    "                for k in range(n_train):\n",
    "                    corrx_train, corry_train = compute_trial_correlations(x_train[k], \n",
    "                                                                        y_train[k],\n",
    "                                                                        sx_train[k].T, \n",
    "                                                                        sy_train[k].T, \n",
    "                                                                        model)\n",
    "                    # Compute correlation between estimated and true spatial patterns\n",
    "                    if 'mSPoC' in label:\n",
    "                        x_train_mspoc = pcax.inverse_transform(x_train[k]).T\n",
    "                        y_train_mspoc = pcay.inverse_transform(y_train[k]).T\n",
    "                        Acorrx_train, Acorry_train = compute_spatial_pattern_correlations(x_train_mspoc,\n",
    "                                                                                        y_train_mspoc,\n",
    "                                                                                        A_eeg,\n",
    "                                                                                        A_fnirs,\n",
    "                                                                                        Wx,\n",
    "                                                                                        Wy)\n",
    "                    else:\n",
    "                        Acorrx_train, Acorry_train = compute_spatial_pattern_correlations(x_train_dict['x'][k],\n",
    "                                                                                    y_train[k],\n",
    "                                                                                    A_eeg,\n",
    "                                                                                    A_fnirs,\n",
    "                                                                                    Wx,\n",
    "                                                                                    Wy)\n",
    "                    \n",
    "                    corrx_train_avg += np.abs(corrx_train)\n",
    "                    corry_train_avg += np.abs(corry_train)\n",
    "                    Acorrx_train_avg += np.abs(Acorrx_train)\n",
    "                    Acorry_train_avg += np.abs(Acorry_train)\n",
    "                \n",
    "                corrx_train_avg /= n_train\n",
    "                corry_train_avg /= n_train\n",
    "                Acorrx_train_avg /= n_train\n",
    "                Acorry_train_avg /= n_train\n",
    "\n",
    "                # Transform test data and average over them\n",
    "                n_test = len(sx_test)\n",
    "                corrx_test_avg = 0\n",
    "                corry_test_avg = 0\n",
    "                Acorrx_test_avg = 0\n",
    "                Acorry_test_avg = 0\n",
    "\n",
    "                for k in range(n_test):\n",
    "                    corrx_test, corry_test = compute_trial_correlations(x_test[k], \n",
    "                                                                        y_test[k], \n",
    "                                                                        sx_test[k].T, \n",
    "                                                                        sy_test[k].T, \n",
    "                                                                        model)\n",
    "                    # Compute correlation between estimated and true spatial patterns\n",
    "                    if 'mSPoC' in label:\n",
    "                        x_test_mspoc = pcax.inverse_transform(x_test[k]).T\n",
    "                        y_test_mspoc = pcay.inverse_transform(y_test[k]).T\n",
    "                        Acorrx_test, Acorry_test = compute_spatial_pattern_correlations(x_test_mspoc,\n",
    "                                                                                        y_test_mspoc,\n",
    "                                                                                        A_eeg,\n",
    "                                                                                        A_fnirs,\n",
    "                                                                                        Wx,\n",
    "                                                                                        Wy)\n",
    "                    else:\n",
    "                        Acorrx_test, Acorry_test = compute_spatial_pattern_correlations(test_dict['x'][k],\n",
    "                                                                                        y_test[k],\n",
    "                                                                                        A_eeg,\n",
    "                                                                                        A_fnirs,\n",
    "                                                                                        Wx,\n",
    "                                                                                        Wy)\n",
    "                    \n",
    "                    corrx_test_avg += np.abs(corrx_test)\n",
    "                    corry_test_avg += np.abs(corry_test)\n",
    "                    Acorrx_test_avg += np.abs(Acorrx_test)\n",
    "                    Acorry_test_avg += np.abs(Acorry_test)\n",
    "                \n",
    "                corrx_test_avg /= n_test\n",
    "                corry_test_avg /= n_test\n",
    "                Acorrx_test_avg /= n_test\n",
    "                Acorry_test_avg /= n_test\n",
    "\n",
    "                corr_dict[label][i, j] = [corrx_train_avg, \n",
    "                                        corry_train_avg, \n",
    "                                        Acorrx_train_avg, \n",
    "                                        Acorry_train_avg,\n",
    "                                        corrx_test_avg, \n",
    "                                        corry_test_avg,\n",
    "                                        Acorrx_test_avg, \n",
    "                                        Acorry_test_avg,]\n",
    "                \n",
    "    return corr_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {},
   "source": [
    "#### Run full simulation\n",
    "\n",
    "We finally run the full simulation to compare some source decomposition methods: the mSPoC algorithm and temporally embedded versions of CCA, sCCA, Ridge CCA, ElasticNet CCA, and ssCCA. The regularization parameters for sCCA and Ridge CCA are\n",
    "chosen to be $\\lambda_{x1} = \\lambda_{y1} = 0.2$, and $\\lambda_{x2} = \\lambda_{y2} = 0.8$ respectively, and their combination for ElasticNet CCA. ssCCA uses the same regularization parameters, while the EEG and fNIRS Laplacian matrices\n",
    "are built using a binary nearest neighbors approach in which the adjacency matrices contain unit values where features (channels) are closer than the (pre-defined) distances of 25mm for fNIRS and 60mm for EEG. For the temporally embedded mehtods, time lags range from 1s to 4s in 1s steps. For mSPoC, we include an L2 penalty term to $w_x (\\lambda_{x2} = 0.8)$ together with PCA-based dimensional reduction, keeping only 0.99 of the explained variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA():\n",
    "    \n",
    "    def __init__(self, \n",
    "                 N_components=None):\n",
    "        \n",
    "        self.N_components = N_components\n",
    "        self.pca = PCA_sk(n_components=N_components)\n",
    "        \n",
    "    def fit(self, X, sample_name='time', feature_name='channel'):\n",
    "        \n",
    "        self.sample_name = sample_name\n",
    "        self.feature_name = feature_name\n",
    "        self.feature = X[feature_name]\n",
    "\n",
    "        X = X.transpose(sample_name, feature_name)\n",
    "        \n",
    "        self.pca.fit(X.data)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        X = X.transpose(self.sample_name, self.feature_name)\n",
    "        \n",
    "        X_new = self.pca.transform(X.data) \n",
    "\n",
    "        X_new = xr.DataArray(data=X_new, \n",
    "                             coords = {self.sample_name: X[self.sample_name],\n",
    "                                       self.feature_name: [f'S{i}' for i in range(X_new.shape[1])]})\n",
    "\n",
    "        return X_new\n",
    "    def inverse_transform(self, X):\n",
    "\n",
    "        extra_dim = X.dims[0]\n",
    "        extra_coord = X[extra_dim]\n",
    "\n",
    "        X_new = self.pca.inverse_transform(X.data).T\n",
    "        \n",
    "        X_new = xr.DataArray(data=X_new,\n",
    "                             coords = {self.feature_name: self.feature,\n",
    "                                       extra_dim: extra_coord})\n",
    "\n",
    "        return X_new\n",
    "\n",
    "def get_fnirs_channel_pos(channels, montage):\n",
    "    \n",
    "    ch_pos_dict = {}\n",
    "    for ch in channels:\n",
    "        source, detector = ch.split('D')\n",
    "        detector = 'D' + detector\n",
    "        source_pos = montage.sel(label=source).data.magnitude\n",
    "        detector_pos = montage.sel(label=detector).data.magnitude\n",
    "        ch_pos = (source_pos + detector_pos)/2\n",
    "        ch_pos_dict[ch] = ch_pos\n",
    "        \n",
    "    return ch_pos_dict\n",
    "\n",
    "def get_eeg_channel_pos(channels, montage):\n",
    "    \n",
    "    ch_pos_dict = {ch: montage.sel(label=ch).data.magnitude for ch in channels}\n",
    "        \n",
    "    return ch_pos_dict\n",
    "\n",
    "def build_laplace(nodes, eps):\n",
    "    \"\"\"\n",
    "    Builds Laplacian matrix of a graph, whose nodes are the components of the 1D vector nodes, \n",
    "    by giving unit weight to connected nodes only if they are close enough. The latter condition\n",
    "    is determined by comparing the 2-norm between nodes and eps.\n",
    "    \"\"\"\n",
    "    \n",
    "    N = len(nodes)\n",
    "    W = np.zeros([N, N])  # Adjacency matrix\n",
    "    D = np.eye(N)  # Degree matrix\n",
    "    \n",
    "    for i, xi in enumerate(nodes):\n",
    "        for j, xj in enumerate(nodes):\n",
    "            are_close = np.linalg.norm(xi - xj) < eps\n",
    "            W[i, j] = 1 if are_close else 0\n",
    "        D[i, i] = np.sum(W[i])\n",
    "    \n",
    "    L = D - W  # Laplace matrix\n",
    "    \n",
    "    return W, D, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load background data and mixing matrices to avoid recomputing them\n",
    "fnirs_bg = xr.load_dataarray(os.path.join(TMP_DIR, 'fnirs_bg_preprocessed.nc'))\n",
    "eeg_bg = xr.load_dataarray(os.path.join(TMP_DIR, 'eeg_bg_preprocessed.nc'))\n",
    "eog = xr.load_dataarray(os.path.join(TMP_DIR, 'eog.nc'))\n",
    "A_fnirs = xr.load_dataarray(os.path.join(TMP_DIR, 'A_fnirs.nc'))\n",
    "A_eeg = xr.load_dataarray(os.path.join(TMP_DIR, 'A_eeg.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_parameters = {\n",
    "    'source_location_landmark': 'C3',\n",
    "    'T_sim': T_sim,\n",
    "    'T_stim': 10,\n",
    "    'T_rest_min': 8,\n",
    "    'T_rest_max': 16,\n",
    "    'stim_amp_min': 0.5,\n",
    "    'stim_amp_max': 0.8,\n",
    "    'simulation_rate': eeg_bg_rate,\n",
    "    'N_sim': 5, # 50,\n",
    "    'train_size': 0.8,\n",
    "    'rate_ds': 2,\n",
    "    'pca_var_explained': .99\n",
    "}\n",
    "\n",
    "# SNR list and corresponding gammas\n",
    "snr_list = np.linspace(-25, 10, 20)\n",
    "gamma_list = 10**(snr_list/20)\n",
    "\n",
    "# Temporal embedding parameters\n",
    "dt = 1\n",
    "N_lags = 5\n",
    "time_shifts = np.arange(0, dt*N_lags, dt)\n",
    "print(time_shifts)\n",
    "\n",
    "# Build Laplace matrices for ssCCA\n",
    "Lx_eps = 60\n",
    "Ly_eps = 25\n",
    "ch_fnirs_pos = get_fnirs_channel_pos(fnirs_bg.channel.data.tolist(), montage)\n",
    "ch_eeg_pos = get_eeg_channel_pos(eeg_bg.channel.data.tolist(), montage)\n",
    "W_fnirs, D_fnirs, L_fnirs = build_laplace(ch_fnirs_pos.values(), eps=Ly_eps)\n",
    "W_eeg, D_eeg, L_eeg = build_laplace(ch_eeg_pos.values(), eps=Lx_eps)\n",
    "\n",
    "# Models\n",
    "cca = CCA(N_components=1)\n",
    "tcca = ElasticNetTCCA(N_components=1, l1_reg=0, l2_reg=0.0, \n",
    "                      time_shifts=time_shifts, shift_source=True)\n",
    "stcca = ElasticNetTCCA(N_components=1, l1_reg=0.1, l2_reg=0.0, \n",
    "                       time_shifts=time_shifts, shift_source=True)\n",
    "rtcca = ElasticNetTCCA(N_components=1, l1_reg=0, l2_reg=0.8, \n",
    "                       time_shifts=time_shifts, shift_source=True)\n",
    "elastictcca = ElasticNetTCCA(N_components=1, l1_reg=0.1, l2_reg=0.8, \n",
    "                             time_shifts=time_shifts, shift_source=True)\n",
    "mspoc = mSPoC(N_components=1, N_restarts=4, max_iter=200, tol=1e-4, \n",
    "              time_shifts=time_shifts, shift_source=True)\n",
    "sstcca = StructuredSparseTCCA(N_components=1, Lx=L_eeg, Ly=L_fnirs, l1_reg=0.1, l2_reg=0.8, \n",
    "                              time_shifts=time_shifts, shift_source=True, pls=False)\n",
    "\n",
    "\n",
    "models = [cca, tcca, stcca, rtcca, elastictcca, sstcca, mspoc]\n",
    "labels = ['CCA', 'tCCA', 'stCCA', 'RidgetCCA', 'ElastictCCA', 'sstCCA', 'mSPoC']\n",
    "\n",
    "corr_dict = run_simulation(fnirs_bg, eeg_bg, eog, A_fnirs, A_eeg, gamma_list, models, labels, simulation_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize simulation results\n",
    "\n",
    "figsize=(15, 10)\n",
    "\n",
    "colors = [c for c in mcolors.TABLEAU_COLORS.keys()]\n",
    "\n",
    "fix, ax = plt.subplots(2, 2, figsize=figsize, sharex=True, sharey=True)\n",
    "\n",
    "for j, (l1, corr) in enumerate(corr_dict.items()):\n",
    "    # Compute mean and stds omitting nan values\n",
    "    means = np.nanmean(corr, axis=0)\n",
    "    non_nan_N = np.count_nonzero(~np.isnan(corr), axis=0)  # Number of simulations not cointaining NaN\n",
    "    stds = np.nanstd(corr, axis=0) / np.sqrt(non_nan_N)\n",
    "\n",
    "    for i, l2 in enumerate(['Sx Test (EEG)', 'Sy Test (fNIRS)']):\n",
    "        ax[0, i].plot(snr_list, means[:, 4+i], 'o-', color=colors[j], label=l1)\n",
    "        ax[0, i].plot(snr_list, means[:, 4+i] + stds[:, 4+i], '_', color=colors[j])\n",
    "        ax[0, i].plot(snr_list, means[:, 4+i] - stds[:, 4+i], '_', color=colors[j])\n",
    "        ax[0, i].set_title(l2, fontsize=20)\n",
    "    for i, l2 in enumerate(['Ax Test (EEG)', 'Ay Test (fNIRS)']):\n",
    "        ax[1, i].plot(snr_list, means[:, 6+i], 'o-', color=colors[j], label=l1)\n",
    "        ax[1, i].plot(snr_list, means[:, 6+i] + stds[:, 6+i], '_', color=colors[j])\n",
    "        ax[1, i].plot(snr_list, means[:, 6+i] - stds[:, 6+i], '_', color=colors[j])\n",
    "        ax[1, i].set_title(l2, fontsize=20)\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax[i, j].grid()\n",
    "        ax[1, j].set_yticks(np.linspace(0, 1, 11))\n",
    "        ax[i, j].set_ylim(0, 1)\n",
    "\n",
    "ax[0, 0].legend(fontsize=15)\n",
    "ax[1, 0].set_xlabel('SNR [dB]', fontsize=15)\n",
    "ax[1, 0].set_xticklabels(np.arange(-30, 15, 5), fontsize=15)\n",
    "ax[1, 1].set_xlabel('SNR [dB]', fontsize=15)\n",
    "ax[1, 1].set_xticklabels(np.arange(-30, 15, 5), fontsize=15)\n",
    "ax[0, 0].set_ylabel('Correlation', fontsize=20)\n",
    "ax[0, 0].set_yticklabels(np.round(np.linspace(0, 1, 11), 1), fontsize=15)\n",
    "ax[1, 0].set_yticklabels(np.round(np.linspace(0, 1, 11), 1), fontsize=15)\n",
    "ax[1, 0].set_ylabel('Correlation', fontsize=20)\n",
    "        \n",
    "plt.suptitle('Correlations between reconstructed and ground-truth sources and spatial patterns\\n')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cedalion_250526",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
