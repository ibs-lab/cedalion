{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic single trial fNIRS finger tapping classification  \n",
    "\n",
    "This notebook sketches the analysis of a finger tapping dataset with multiple subjects. A simple Linear Discriminant Analysis (LDA) classifier is trained to distinguish left and right fingertapping.\n",
    "\n",
    "**PLEASE NOTE:** For simplicity's sake we are skipping many preprocessing steps (e.g. pruning, artifact removal, physiology removal). These are subject of other example notebooks. For a rigorous analysis you will want to include such steps. The purpose of this notebook is only to demonstrate easy interfacing of the scikit learn package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cells setups the environment when executed in Google Colab.\n",
    "try:\n",
    "    import google.colab\n",
    "    !curl -s https://raw.githubusercontent.com/ibs-lab/cedalion/dev/scripts/colab_setup.py -o colab_setup.py\n",
    "    # Select branch with --branch \"branch name\" (default is \"dev\")\n",
    "    %run colab_setup.py\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cedalion\n",
    "import cedalion.nirs\n",
    "from cedalion.datasets import get_multisubject_fingertapping_snirf_paths\n",
    "import cedalion.sigproc.quality as quality\n",
    "from cedalion.sigproc.frequency import freq_filter\n",
    "import cedalion.plots as plots\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as p\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score,roc_curve, roc_auc_score, auc\n",
    "\n",
    "from cedalion import units\n",
    "\n",
    "xr.set_options(display_max_rows=3, display_values_threshold=50)\n",
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading raw CW-NIRS data from SNIRF files\n",
    "\n",
    "This notebook uses a finger-tapping dataset in BIDS layout provided by [Rob Luke](https://github.com/rob-luke/BIDS-NIRS-Tapping). It can can be downloaded via `cedalion.datasets`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cedalion's `read_snirf` method returns a list of `Recording` objects. These are containers for timeseries and adjunct data objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = get_multisubject_fingertapping_snirf_paths()\n",
    "subjects = [f\"sub-{i:02d}\" for i in [1, 2, 3]]\n",
    "\n",
    "# store data of different subjects in a dictionary\n",
    "data = {}\n",
    "for subject, fname in zip(subjects, fnames):\n",
    "    records = cedalion.io.read_snirf(fname)\n",
    "    rec = records[0]\n",
    "\n",
    "    # Cedalion registers an accessor (attribute .cd ) on pandas DataFrames.\n",
    "    # Use this to rename trial_types inplace.\n",
    "    rec.stim.cd.rename_events(\n",
    "        {\"1.0\": \"control\", \"2.0\": \"Tapping/Left\", \"3.0\": \"Tapping/Right\"}\n",
    "    )\n",
    "\n",
    "    dpf = xr.DataArray(\n",
    "        [6, 6],\n",
    "        dims=\"wavelength\",\n",
    "        coords={\"wavelength\": rec[\"amp\"].wavelength},\n",
    "    )\n",
    "\n",
    "    rec[\"od\"] = cedalion.nirs.int2od(rec[\"amp\"])\n",
    "    rec[\"conc\"] = cedalion.nirs.od2conc(rec[\"amp\"], rec.geo3d, dpf)\n",
    "\n",
    "    display(subject, rec)\n",
    "\n",
    "    data[subject] = rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    data[\"sub-01\"]\n",
    "    .stim.groupby(\"trial_type\")[[\"trial_type\"]]\n",
    "    .count()\n",
    "    .rename({\"trial_type\": \"# trials\"}, axis=1) # rename column\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency filtering and splitting into epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject, rec in data.items():\n",
    "    # cedalion registers the accessor .cd on DataArrays\n",
    "    # to provide common functionality like frequency filters...\n",
    "    rec[\"conc_freqfilt\"] = freq_filter(\n",
    "        rec[\"conc\"], fmin=0.01 * units.Hz, fmax=0.5 * units.Hz\n",
    "    )\n",
    "\n",
    "    # cedalion registers the accessor .cd on DataArrays\n",
    "    # to provide common functionality like splitting time series into epochs\n",
    "\n",
    "    rec[\"cfepochs\"] = rec[\"conc_freqfilt\"].cd.to_epochs(\n",
    "        rec.stim,  # stimulus dataframe\n",
    "        [\"Tapping/Left\", \"Tapping/Right\"],  # select trials\n",
    "        before=5 * units.s,  # seconds before stimulus\n",
    "        after=20 * units.s,  # seconds after stimulus\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show  the time series before and after `to_epochs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data[\"sub-01\"][\"conc_freqfilt\"])\n",
    "display(data[\"sub-01\"][\"cfepochs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot frequency filtered data\n",
    "Illustrate for a single subject and channel the effect of the bandpass filter.\n",
    "The lowpass remove the cardiac component. The highpass removed slow drift and the DC offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = data[\"sub-01\"]\n",
    "channel = \"S5D7\"\n",
    "\n",
    "f, ax = p.subplots(2, 1, figsize=(12, 4), sharex=True)\n",
    "ax[0].plot(rec[\"conc\"].time, rec[\"conc\"].sel(channel=channel, chromo=\"HbO\"), \"r-\", label=\"HbO\")\n",
    "ax[0].plot(rec[\"conc\"].time, rec[\"conc\"].sel(channel=channel, chromo=\"HbR\"), \"b-\", label=\"HbR\")\n",
    "ax[1].plot(\n",
    "    rec[\"conc_freqfilt\"].time,\n",
    "    rec[\"conc_freqfilt\"].sel(channel=channel, chromo=\"HbO\"),\n",
    "    \"r-\",\n",
    "    label=\"HbO\",\n",
    ")\n",
    "ax[1].plot(\n",
    "    rec[\"conc_freqfilt\"].time,\n",
    "    rec[\"conc_freqfilt\"].sel(channel=channel, chromo=\"HbR\"),\n",
    "    \"b-\",\n",
    "    label=\"HbR\",\n",
    ")\n",
    "ax[0].set_xlim(1000, 1040)\n",
    "ax[1].set_xlabel(\"time / s\")\n",
    "ax[0].set_ylabel(\"$\\Delta c$ / $\\mu M$\")\n",
    "ax[1].set_ylabel(\"$\\Delta c$ / $\\mu M$\")\n",
    "ax[0].legend(loc=\"upper left\")\n",
    "ax[1].legend(loc=\"upper left\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline removal\n",
    "\n",
    "Calculate a baseline by averaging all samples before the stimulus onset (`reltime < 0`>) and subtract it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject, rec in data.items():\n",
    "    # calculate baseline\n",
    "    baseline_conc = rec[\"cfepochs\"].sel(reltime=(rec[\"cfepochs\"].reltime < 0)).mean(\"reltime\")\n",
    "    # subtract baseline\n",
    "    rec[\"cfbl_epochs\"] = rec[\"cfepochs\"] - baseline_conc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data[\"sub-01\"][\"cfbl_epochs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Block Averages of trials for one participant per condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use subject 1 as an example here\n",
    "subject = \"sub-01\"\n",
    "\n",
    "# group trials by trial_type. For each group individually average the epoch dimension\n",
    "blockaverage = data[subject][\"cfbl_epochs\"].groupby(\"trial_type\").mean(\"epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting averaged epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = p.subplots(5, 6, figsize=(12, 10))\n",
    "ax = ax.flatten()\n",
    "for i_ch, ch in enumerate(blockaverage.channel):\n",
    "    for ls, trial_type in zip([\"-\", \"--\"], blockaverage.trial_type):\n",
    "        ax[i_ch].plot(\n",
    "            blockaverage.reltime,\n",
    "            blockaverage.sel(chromo=\"HbO\", trial_type=trial_type, channel=ch),\n",
    "            \"r\",\n",
    "            lw=2,\n",
    "            ls=ls,\n",
    "        )\n",
    "        ax[i_ch].plot(\n",
    "            blockaverage.reltime,\n",
    "            blockaverage.sel(chromo=\"HbR\", trial_type=trial_type, channel=ch),\n",
    "            \"b\",\n",
    "            lw=2,\n",
    "            ls=ls,\n",
    "        )\n",
    "    ax[i_ch].grid(1)\n",
    "    ax[i_ch].set_title(ch.values)\n",
    "    ax[i_ch].set_ylim(-0.3, 0.6)\n",
    "\n",
    "# add legend\n",
    "ax[0].legend([\"HbO Tapping/Left\", \"HbR Tapping/Left\",  \"HbO Tapping/Right\", \"HbR Tapping/Right\"])\n",
    "p.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA classification with Scikit-Learn\n",
    "\n",
    "### Feature Extraction\n",
    "We define simple features to characterize an epoch: the minimium, maximum and average concentration.\n",
    "\n",
    "All of these are calculated in time windows after stimulus onset, for each channel and chromophore.\n",
    "\n",
    "The features are calculated from the blockaveraged concentration time series. The layout of the resulting\n",
    "array is adjusted to match the layout scikit-learn expects.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject, rec in data.items():\n",
    "\n",
    "    # avg signal between 0 and 10 seconds after stimulus onset\n",
    "    fmean = rec[\"cfbl_epochs\"].sel(reltime=slice(0, 10)).mean(\"reltime\")\n",
    "    # min signal between 0 and 15 seconds after stimulus onset\n",
    "    fmin = rec[\"cfbl_epochs\"].sel(reltime=slice(0, 15)).min(\"reltime\")\n",
    "    # max signal between 0 and 15 seconds after stimulus onset\n",
    "    fmax = rec[\"cfbl_epochs\"].sel(reltime=slice(0, 15)).max(\"reltime\")\n",
    "\n",
    "    # concatenate features and stack them into a new dimension ('feature')\n",
    "    # X will have shape (feature, epoch, chromo, channel)\n",
    "    X = xr.concat([fmean, fmin, fmax], dim=\"feature\")\n",
    "    X = X.assign_coords({\"feature\" : [\"mean\", \"min\", \"max\"]})\n",
    "    display(X)\n",
    "\n",
    "    # afterwards stack the 3 per channel and chromo features together into a new\n",
    "    # dimension ('features')\n",
    "    X = X.stack(features=[\"chromo\", \"channel\", \"feature\"])\n",
    "\n",
    "    #X = X.drop_vars(\"features_tmp\") # coordinate created by concat. not needed\n",
    "\n",
    "    # strip units. sklearn would strip them anyway but issue a warning about it.\n",
    "    X = X.pint.dequantify()\n",
    "\n",
    "    # need to manually tell xarray to create an index for trial_type\n",
    "    X = X.set_xindex(\"trial_type\")\n",
    "\n",
    "    # save in recording container\n",
    "    rec.aux_obj[\"X\"] = X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The arrays 'X' have now the layout that scikit-learn expects: (#samples, #features).\n",
    "\n",
    "Features in columns can still be identified via their corresponding coordinates.\n",
    "\n",
    "Epochs in rows have the `trial_type` coorindate to distinguish different epochs. \n",
    "\n",
    "Further coordinates can be added as needed (e.g. the subject when epochs from different subjects are pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data[\"sub-01\"].aux_obj[\"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode trial_type into 0,1 labels for use in scikit-learn\n",
    "# LabelEncoder returns a numpy array. Use apply_ufunc to wrap the result into a xr.DataArray\n",
    "\n",
    "for subject, rec in data.items():\n",
    "    rec.aux_obj[\"y\"] = xr.apply_ufunc(LabelEncoder().fit_transform, rec.aux_obj[\"X\"].trial_type)\n",
    "\n",
    "display(data[\"sub-01\"].aux_obj[\"y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train LDA classifier for each subject using 5-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dictionaries for key metrics for each subject to plot\n",
    "scores = {}\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "for subject, rec in data.items():\n",
    "    X = rec.aux_obj[\"X\"]\n",
    "    y = rec.aux_obj[\"y\"]\n",
    "\n",
    "    classifier = LinearDiscriminantAnalysis(n_components=1)\n",
    "\n",
    "    # Define the cross-validation strategy (e.g., stratified k-fold with 5 folds)\n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "    # Perform cross-validation and get accuracy scores\n",
    "    scores[subject] = cross_val_score(classifier, X, y, cv=cv, scoring=\"accuracy\")\n",
    "\n",
    "    # Get predicted probabilities using cross-validation\n",
    "    pred_prob = cross_val_predict(classifier, X, y, cv=cv, method=\"predict_proba\")[:, 1]\n",
    "\n",
    "\n",
    "    # Calculate ROC curve and AUC\n",
    "    fpr[subject], tpr[subject], thresholds = roc_curve(y, pred_prob)\n",
    "    roc_auc[subject] = auc(fpr[subject], tpr[subject])\n",
    "\n",
    "    # Print the mean accuracy across folds\n",
    "    print(\n",
    "        f\"Cross-validated accuracy for subject {subject}: {scores[subject].mean():.2f}+-{scores[subject].std():.4f}\"\n",
    "    )\n",
    "\n",
    "# barplot of accuracies\n",
    "f, ax = p.subplots()\n",
    "ax.bar(data.keys(), [scores.mean() for scores in scores.values()])\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_xlabel(\"Subject\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ROC curves for subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbsphinx-thumbnail"
    ]
   },
   "outputs": [],
   "source": [
    "# Initialize the ROC plot\n",
    "p.figure(figsize=(10, 8))\n",
    "# Train classifier and plot ROC curve for each subject\n",
    "for subject, rec in data.items():\n",
    "    # Plotting the ROC curve\n",
    "    p.plot(fpr[subject], tpr[subject], lw=2, label=f'Subject {subject} (AUC = {roc_auc[subject]:.2f})')\n",
    "# Plot the diagonal line for random guessing\n",
    "p.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "    # Adding labels and title\n",
    "p.xlabel('False Positive Rate')\n",
    "p.ylabel('True Positive Rate')\n",
    "p.title('ROC Curves for All Subjects')\n",
    "p.legend(loc='lower right')\n",
    "p.grid(True)\n",
    "p.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cedalion_v25.1.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
