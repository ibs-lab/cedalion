{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Recording Container: Cedalion's main data structure and a guide to indexing  \n",
    "\n",
    "This example notebook introduces the main data classes used by cedalion, and provides examples of how to access and index them.\n",
    "\n",
    "## Overview\n",
    "\n",
    "**The class `cedalion.dataclasses.Recording` is Cedalion's main data container that can be used to carry related data objects through the program.** It can store time series, masks, auxiliary timeseries, probe, headmodel and stimulus information as well as meta data about the recording.\n",
    "It has the following properties:\n",
    "\n",
    "- It resembles the [NIRS group in the snirf specification](https://github.com/fNIRS/snirf/blob/v1.1/snirf_specification.md#nirsi), which provides storage for much of the data stored in a `Recording` (e.g. time series map to [data elements](https://github.com/fNIRS/snirf/blob/v1.1/snirf_specification.md#nirsidataj), [probe](https://github.com/fNIRS/snirf/blob/v1.1/snirf_specification.md#nirsiprobe), [stimulus](https://github.com/fNIRS/snirf/blob/v1.1/snirf_specification.md#nirsistimj) and [meta data](https://github.com/fNIRS/snirf/blob/v1.1/snirf_specification.md#nirsimetadatatags) are stored per NIRS element, etc). Consequently, the methods `cedalion.io.read_snirf` and `cedalion.io.write_snirf` methods operate on lists of recordings.\n",
    "- different time series and masks are stored in ordered dictionaries\n",
    "  - the user differentiates time series by name\n",
    "  - there is a set of canonical names used by `read_snirf` to assign names to time series\n",
    "    ```\n",
    "    CANONICAL_NAMES = {\n",
    "          \"unprocessed raw\": \"amp\",\n",
    "          \"processed raw\": \"amp\",\n",
    "          \"processed dOD\": \"od\",\n",
    "          \"processed concentrations\": \"conc\",\n",
    "          \"processed central moments\": \"moments\",\n",
    "          \"processed blood flow index\": \"bfi\",\n",
    "          \"processed HRF dOD\": \"hrf_od\",\n",
    "          \"processed HRF central moments\": \"hrf_moments\",\n",
    "          \"processed HRF concentrations\": \"hrf_conc\",\n",
    "          \"processed HRF blood flow index\": \"hrf_bfi\",\n",
    "          \"processed absorption coefficient\": \"mua\",\n",
    "          \"processed scattering coefficient\": \"musp\",\n",
    "    }\n",
    "    ```\n",
    "- time series are stored in the dictionaries in the order that they were added\n",
    "- convenient access to the last changed time series + canonical names -> consecutive transformations of time series without the need to specify time series by name -> workflows\n",
    "- `rec[key]` is a shortcut for `rec.timeseries[key]` \n",
    "- not all information stored in a `Recording` can be stored in snirf files, e.g. for masks, the headmodel and auxiliar objects there is no provision in the snirf specification. We will probably use sidecard files or sidecar hdf groups to store these.\n",
    "\n",
    "![Recording Container](/img/recording/rec_container_overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the recording container fields with some example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cedalion\n",
    "import cedalion.io\n",
    "import cedalion.datasets\n",
    "import cedalion.xrutils as xrutils\n",
    "import xarray as xr\n",
    "\n",
    "# Loading an example dataset will create a recording container. \n",
    "# Alternatively you can load your ow snirf file using cedalion.io.snirf.read_snirf(PATH_TO_FILE)\n",
    "rec = cedalion.datasets.get_fingertapping()\n",
    "display(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The timeseries field\n",
    "we loaded raw amplitude data and can now access it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(rec[\"amp\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are interested not only in raw \"amp\"litude data, we convert this data to concentration using the modified beer-lambert law and save it under **\"conc\"** in the recording container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cedalion.nirs\n",
    "\n",
    "# define DPFs and convert to HbO/HbR using the beer lambert law law\n",
    "dpf = xr.DataArray(\n",
    "        [6, 6],\n",
    "        dims=\"wavelength\",\n",
    "        coords={\"wavelength\": rec[\"amp\"].wavelength},\n",
    "    )\n",
    "rec[\"conc\"] = cedalion.nirs.beer_lambert(rec[\"amp\"], rec.geo3d, dpf)\n",
    "\n",
    "display(rec[\"conc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The geo3d field\n",
    "we have already used channel distances from this field to calculate the concentrations using the beer-lambert law above. \n",
    "The geo3d and geo2d fields are DataArrays of geometric points, whose \"magnitude\" is the 3d coordinate in 3D / 2D space. They also have two coordinates: a \"label\", such as \"S1\" for Source 1, and a \"type\" of PointType.Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(rec.geo3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The stim field\n",
    "contains labels for any experimental stimuli that were logged during the recording. Turns out each condition in the experiment was 5 seconds long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(rec.stim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the trial_type was encoded numerically, which can be hard to read. If we know the experiment we can rename the stimuli using the \"rename_events\" function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec.stim.cd.rename_events(\n",
    "        {\"1.0\": \"control\", \"2.0\": \"Tapping/Left\", \"3.0\": \"Tapping/Right\"}\n",
    "    )\n",
    "\n",
    "display(rec.stim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The masks field\n",
    "Lastly, we create a **mask** based on an SNR threshold. A mask is a Boolean DataArray that flags each point across all coordinates as either \"true\" or \"false\", according to the metric applied. Here we use an SNR of 3 to flag all channels in the raw \"amp\" timeseries as \"False\" if their SNR is below the threshold. Since SNR is calculated across the whole time, the time dimension gets dropped. Applying this mask later on to a DataArray time series works implitly thanks to the unambiguous xarray coordinates in the mask and timeseries (here for instance the channel name). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cedalion.sigproc.quality as quality\n",
    "# SNR thresholding using the \"snr\" function of the quality subpackage using an SNR of 3\n",
    "_, rec.masks[\"snr_mask\"] = quality.snr(rec[\"amp\"], 3)\n",
    "\n",
    "display(rec.masks[\"snr_mask\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The headmodel / aux_obj field\n",
    "The recording container does not yet contain a mask or head model. We load an ICBM152 atlas and create the **headmodel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cedalion.imagereco.forward_model as fw\n",
    "\n",
    "# load segmentation data from the icbm152 atlas\n",
    "SEG_DATADIR_ic152, mask_files_ic152, landmarks_file_ic152 = cedalion.datasets.get_icbm152_segmentation()\n",
    "\n",
    "# create forward model class for icbm152 atlas\n",
    "rec.head_icbm152 = fw.TwoSurfaceHeadModel.from_surfaces(\n",
    "    segmentation_dir=SEG_DATADIR_ic152,\n",
    "    mask_files = mask_files_ic152,\n",
    "    brain_surface_file= os.path.join(SEG_DATADIR_ic152, \"mask_brain.obj\"),\n",
    "    landmarks_ras_file=landmarks_file_ic152,\n",
    "    brain_face_count=None,\n",
    "    scalp_face_count=None\n",
    ")\n",
    "\n",
    "display(rec.head_icbm152)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xarray  DataArray Indexing and Selecting Data\n",
    "xarray DataArrays in Cedalion can be indexed \"as usual\". For a complete documentation visit the [xarray documentation page](https://docs.xarray.dev/en/latest/user-guide/indexing.html). A brief visual overview: \n",
    "\n",
    "\n",
    "![DataArray Indexing Overview](/img/recording/dataarray_indexing_overview.png)\n",
    "\n",
    "\n",
    "Below we give some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we pull out a time series to save time in the following\n",
    "ts = rec[\"amp\"]\n",
    "display(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it usually helps to know the array's **coordinates**. these can be viewed via the .coords xarray accessor. Note that multiple coordinate axes can overlap. For instance, across the time dimension we can use \"time\" in seconds or \"samples\" in integer values. Across the \"channel\" dimension we can index via Source-Detector pairs (e.g. \"S1D1\") or via only the \"source\" or \"detector\". The latter will give us all matching elements - e.g. \"S1\" will give us all channels that contain source S1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ts.coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing the coordinates we can also acess the items / labels on the coordinate axes directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ts.wavelength) # wavelength dimension\n",
    "\n",
    "display(ts.time) # time dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Direct Bracket Indexing\n",
    "... works as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts[:,0,:] # first item along wavelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts[:,:,::3000] # every 3000th time point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing by Label: .loc and .sel accessors\n",
    "without using the coordinate we require knowledge of the order of dimensions in the DataArray..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.loc[\"S1D1\", 760, :] # time series for channel S1D1 and wavelength 760nm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or we are more explicit, in which case the order does not matter. `.sel` relies on an index. For some  coordinates (time, channel, wavelength) indexes are built. They are printed in bold face when the DataArray is displayed. Indexes are needed for efficient lookup but are not strictly necessary. Hence, we don't always build them by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.sel(channel=\"S1D1\", wavelength=760)  # the same time series as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.sel` accepts dictionaries. Useful when dimension name is a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 'wavelength'\n",
    "dim_value = 760\n",
    "ts.sel({dim : dim_value})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing using logical operations\n",
    "We can, for instance, choose only those data points that come after t=10s and before t=60s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.sel(time= (ts.time  > 10 ) & (ts.time < 60.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "boolean masking works also with the .loc accessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.loc[ts.source == \"S1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing using stringng matching or \"isin\"\n",
    "first via string accessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular expression via str accessor\n",
    "ts.sel(channel=ts.channel.str.match(\"S[2,3]D[1,2]\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or via the use of `isin` to select a fixed tiem or list of items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item\n",
    "ts.sel(channel=\"S1D1\")\n",
    "\n",
    "# list of items\n",
    "ts.sel(channel=ts.channel.isin([\"S1D1\", \"S8D8\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building indices if they are not available\n",
    "Repeat: `.sel` relies on an index. For some  coordinates (time, channel, wavelength) indexes are built. They are printed in bold face when the DataArray is displayed. Indexes are needed for efficient lookup but are not strictly necessary. if we would like to index via a coordinate axis for which no index is available (here the \"source\" coordinate), they can [be built](https://docs.xarray.dev/en/v2024.07.0/generated/xarray.DataArray.set_xindex.html#xarray.DataArray.set_xindex):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the index\n",
    "ts_with_index = ts.set_xindex(\"source\")\n",
    "# now we can select by source index\n",
    "ts_with_index.sel(source=\"S1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using coordinates from one array to index another\n",
    "Here we use `ts.source` to select in `geo3d` values along the 'label' dimension. Because `ts.source` belongs to the 'channel' dimension of `ts`, the resulting `xr.DataArray` has dimensions 'channel' (from ts.source) and 'digitized' (from geo3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(rec.geo3d)\n",
    "display(ts.source)\n",
    "rec.geo3d.loc[ts.source]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing xarray DataArray values with .values\n",
    "e.g. to write them to a numpy array. Example: We want to pull out the actual source names of the first 3 sources.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this way of indexing will not give us what we want, as it returns another xarray with coordinates etc.\n",
    "display(ts.source[:3])\n",
    "\n",
    "# instead we use the .values accessors:\n",
    "display(ts.source.values[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing single items in an xarray with .item\n",
    "indexing a single item in an xarray is still an xarray with coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ts[0,0,0]) # the first time point of the first channel and first wavelength in the DataArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get just the item we use .item()\n",
    "display(ts[0,0,0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# of course this also works with the .sel method\n",
    "ts.sel(channel=\"S1D1\", wavelength= \"760\", time = \"0.0\").item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cedalion_240720",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
