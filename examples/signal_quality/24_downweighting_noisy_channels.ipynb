{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Using Channel Variance as Proxy for Measurement Noise and as a Weight for Global Physiology Removal\n",
    "\n",
    "To improve statistics, channel pruning might not always be the way. \n",
    "An alternative is to use channel weights in the calculation of averages (e.g. across subjects) or image reconstruction. \n",
    "One way of weighting channels is by their estimated measurement noise. \n",
    "Variance can be a proxy of measurement noise, e.g. when calculated across trials of the same condition (within subject) or across time on the residual after GLM fit.\n",
    "This notebook is WIP to provide help to explore this approach with a helper function (quality.measurement_variance) for this purpose.\n",
    "We will first create an intuition how to use the quality.measurement_variance function, and then use the output for weighted global physiology removal with physio.global_physio_subtract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cells setups the environment when executed in Google Colab.\n",
    "try:\n",
    "    import google.colab\n",
    "    !curl -s https://raw.githubusercontent.com/ibs-lab/cedalion/dev/scripts/colab_setup.py -o colab_setup.py\n",
    "    # Select branch with --branch \"branch name\" (default is \"dev\")\n",
    "    %run colab_setup.py\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import numpy as np\n",
    "\n",
    "import cedalion\n",
    "import cedalion.datasets as datasets\n",
    "import cedalion.nirs\n",
    "import cedalion.sigproc.quality as quality\n",
    "import cedalion.sigproc.motion_correct as motion_correct\n",
    "from cedalion import units\n",
    "import cedalion.xrutils as xrutils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some plotting helper functions for this notebook\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "def plot_heatmap(da, cov_wavelength=None, figsize=(12, 4), cmap=None):\n",
    "    dims = da.dims\n",
    "\n",
    "    # VARIANCE CASE: dims = (\"channel\", \"wavelength\")\n",
    "    if set(dims) == {\"channel\", \"wavelength\"}:\n",
    "        # Convert to pandas DataFrame so that rows = channels, cols = wavelengths\n",
    "        df = da.to_pandas()\n",
    "\n",
    "        # We want channels on the x-axis, wavelengths on the y-axis.\n",
    "        #   df.values has shape (n_channels, n_wavelengths), so transpose → (n_wavelengths, n_channels)\n",
    "        arr = df.values.T\n",
    "\n",
    "        x_labels = df.index.tolist()         # channel names\n",
    "        y_labels = [str(int(wl)) for wl in df.columns]  # wavelength values as strings\n",
    "\n",
    "        x_dim_name = \"channel\"\n",
    "        y_dim_name = \"wavelength\"\n",
    "        cbar_label = \"Variance\"\n",
    "\n",
    "    # COVARIANCE CASE: dims = (\"wavelength\", \"channel1\", \"channel2\")\n",
    "    elif set(dims) == {\"wavelength\", \"channel1\", \"channel2\"}:\n",
    "        if cov_wavelength is None:\n",
    "            raise ValueError(\n",
    "                \"When da.dims == ('wavelength','channel1','channel2'), you must supply cov_wavelength.\"\n",
    "            )\n",
    "        # Extract the 2D slice at that wavelength\n",
    "        da2d = da.sel(wavelength=cov_wavelength)\n",
    "        # Make sure dims are in order (channel1, channel2)\n",
    "        da2d = da2d.transpose(\"channel1\", \"channel2\")\n",
    "\n",
    "        arr = da2d.values  # shape = (n_channel1, n_channel2)\n",
    "\n",
    "        x_labels = da2d.coords[\"channel2\"].values.tolist()\n",
    "        y_labels = da2d.coords[\"channel1\"].values.tolist()\n",
    "\n",
    "        x_dim_name = \"channel2\"\n",
    "        y_dim_name = \"channel1\"\n",
    "        cbar_label = f\"Covariance (λ={cov_wavelength})\"\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported DataArray dimensions: {dims}\")\n",
    "\n",
    "    # Plot the 2D array with imshow\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    im = ax.imshow(arr, aspect=\"auto\", cmap=cmap)\n",
    "\n",
    "    # Set x-axis ticks/labels\n",
    "    ax.set_xticks(range(len(x_labels)))\n",
    "    ax.set_xticklabels(x_labels, rotation=90, fontsize=8)\n",
    "\n",
    "    # Set y-axis ticks/labels\n",
    "    ax.set_yticks(range(len(y_labels)))\n",
    "    ax.set_yticklabels(y_labels, fontsize=8)\n",
    "\n",
    "    # Label axes from the dimension names\n",
    "    ax.set_xlabel(x_dim_name)\n",
    "    ax.set_ylabel(y_dim_name)\n",
    "\n",
    "    # Add a colorbar\n",
    "    cbar = fig.colorbar(im, ax=ax)\n",
    "    cbar.set_label(cbar_label)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "\n",
    "def plot_selected_channels(\n",
    "    rec: xr.Dataset,\n",
    "    channels: list,\n",
    "    wavelength: float,\n",
    "    da_name: str = \"od\",\n",
    "    figsize: tuple = (12, 4),\n",
    "    time_xlim: tuple = (0, 500)\n",
    "):\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "\n",
    "    for ch in channels:\n",
    "        series = rec[da_name].sel({ \"channel\": ch, \"wavelength\": wavelength })\n",
    "        ax.plot(rec[da_name].time, series, label=f\"{ch} {wavelength}nm\")\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set_xlim(*time_xlim)\n",
    "    ax.set_xlabel(\"time / s\")\n",
    "    ax.set_ylabel(\"Signal intensity / a.u.\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Channel Variance as a Proxy for Measurement Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Plain Channel Variance\n",
    "Note: channel variance can only be a proxy for measurement noise if calculated OD or CONC. Do not calculate on raw intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get example finger tapping dataset\n",
    "rec = datasets.get_fingertapping()\n",
    "rec[\"od\"] = cedalion.nirs.int2od(rec[\"amp\"])\n",
    "\n",
    "# Plot some data for visual validation\n",
    "f,ax = plt.subplots(1,1, figsize=(12,4))\n",
    "ax.plot( rec[\"od\"].time, rec[\"od\"].sel(channel=\"S1D1\", wavelength=\"850\"), \"r-\", label=\"S1D1 850nm\")\n",
    "ax.plot( rec[\"od\"].time, rec[\"od\"].sel(channel=\"S1D1\", wavelength=\"760\"), \"b-\", label=\"S1D1 760nm\")\n",
    "plt.legend()\n",
    "ax.set_xlim(0, 500)\n",
    "ax.set_xlabel(\"time / s\")\n",
    "ax.set_ylabel(\"Signal intensity / a.u.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Calculate variance of all channels and display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate variance of optical density (OD) measurements for all channels and wavelengths\n",
    "od_var = quality.measurement_variance(rec[\"od\"])\n",
    "\n",
    "fig, ax = plot_heatmap(od_var)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "From the plot above we can identify S6D8 (760nm) as a channel with high variance and and S1D2 (760nm) as a channel with low variance. S7D6 is somewhere inbetween.\n",
    "Lets investigate how the corresponding time series looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some data for visual validation\n",
    "f,ax = plt.subplots(1,1, figsize=(12,4))\n",
    "ax.plot( rec[\"od\"].time, rec[\"od\"].sel(channel=\"S6D8\", wavelength=\"760\"), \"r-\", label=\"S6D8 760nm\")\n",
    "ax.plot( rec[\"od\"].time, rec[\"od\"].sel(channel=\"S1D2\", wavelength=\"760\"), \"b-\", label=\"S1D2 760nm\")\n",
    "ax.plot( rec[\"od\"].time, rec[\"od\"].sel(channel=\"S7D6\", wavelength=\"760\"), \"y-\", label=\"S7D6 760nm\")\n",
    "plt.legend()\n",
    "ax.set_xlim(0, 500)\n",
    "ax.set_xlabel(\"time / s\")\n",
    "ax.set_ylabel(\"Signal intensity / a.u.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "We can see that the Channel with high variance has motion artifacts. These can be removed with [motion correction methods](https://doc.ibs.tu-berlin.de/cedalion/doc/dev/examples/signal_quality/22_motion_artefacts_and_correction.html) and we can recalculate the variance to see if this helped. If we don't, and use the channel variance as is for weighting in further processing, the channel with motion artifacts will be downweighted, as it has higher variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# motion correction using the wavelet and tddr methods  \n",
    "rec[\"od_corrected\"] = motion_correct.tddr(rec[\"od\"])\n",
    "rec[\"od_corrected\"] = motion_correct.motion_correct_wavelet(rec[\"od_corrected\"])\n",
    "\n",
    "\n",
    "# Plot corrected data for visual validation\n",
    "f,ax = plt.subplots(1,1, figsize=(12,4))\n",
    "ax.plot( rec[\"od_corrected\"].time, rec[\"od_corrected\"].sel(channel=\"S6D8\", wavelength=\"760\"), \"r-\", label=\"S6D8 760nm\")\n",
    "ax.plot( rec[\"od_corrected\"].time, rec[\"od_corrected\"].sel(channel=\"S1D2\", wavelength=\"760\"), \"b-\", label=\"S1D2 760nm\")\n",
    "ax.plot( rec[\"od_corrected\"].time, rec[\"od_corrected\"].sel(channel=\"S7D6\", wavelength=\"760\"), \"y-\", label=\"S7D6 760nm\")\n",
    "plt.legend()\n",
    "ax.set_xlim(0, 500)\n",
    "ax.set_xlabel(\"time / s\")\n",
    "ax.set_ylabel(\"Signal intensity / a.u.\")\n",
    "\n",
    "# calculate variance on the corrected signal\n",
    "od_var2 = quality.measurement_variance(rec[\"od_corrected\"])\n",
    "\n",
    "\n",
    "## Display results as a heatmap\n",
    "fig, ax = plot_heatmap(od_var2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "We can see that motion correction took care of some variance (and therefore fixed some channels like S6D8), but not all of it, S4D4 remains partially noisy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Channel variance under consideration of flagged bad channels\n",
    "There are cases in which we don't trust channel variance as a proxy for measurement noise. Examples are saturated channels.\n",
    "We could  also want to penalize channels with motion artifacts particulalry strongly and for instance kick out S4D4, which did only partially profit from artifact rejection.\n",
    "For this we can provide a list of \"bad\" channels and a custom weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets assume we do not want to do motion correction and channel S1D1 is saturated. \n",
    "# We give S1D1 it a constant value of 1V with only the measurement noise of the system of 10mV\n",
    "rec[\"amp\"].loc[{\"channel\": \"S1D1\"}] = (1 + np.random.normal(0, 10e-3, rec[\"amp\"].sel(channel=\"S1D1\").shape))*units.V\n",
    "\n",
    "# now convert the signal to optical density\n",
    "rec[\"od\"] = cedalion.nirs.int2od(rec[\"amp\"])\n",
    "\n",
    "\n",
    "# Plot some data for visual validation\n",
    "f,ax = plt.subplots(1,1, figsize=(12,4))\n",
    "ax.plot( rec[\"od\"].time, rec[\"od\"].sel(channel=\"S1D1\", wavelength=\"760\"), \"b-\", label=\"S1D1 760nm\")\n",
    "ax.plot( rec[\"od\"].time, rec[\"od\"].sel(channel=\"S4D4\", wavelength=\"850\"), \"r-\", label=\"S4D4 850nm\")\n",
    "plt.legend()\n",
    "ax.set_xlim(0, 500)\n",
    "ax.set_xlabel(\"time / s\")\n",
    "ax.set_ylabel(\"Signal intensity / a.u.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Looking at the resulting variance of the saturated channel S1D2 and comparing it with the noisy (motion artifact) channel S4D4..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate variance of optical density (OD) measurements for all channels and chromophores\n",
    "od_var = quality.measurement_variance(rec[\"od\"])\n",
    "\n",
    "# print channel S1D1 760nm and channel S6D8 760nm variance \n",
    "print(\"S1D1 760nm variance:\", od_var.sel(channel=\"S1D1\", wavelength=\"760\").values)\n",
    "print(\"S4D4 760nm variance:\", od_var.sel(channel=\"S4D4\", wavelength=\"850\").values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "we can tell that the metric cannot account for saturation, and we should manually drop / downweight the saturated channel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_bad_channels = [\"S1D1\", \"S4D4\"]\n",
    "bad_rel_var = 1e5 # we use a large factor that will be multiplied with the channel variance to effectively remove the channel from the analysis wherever it is weighted by its variance\n",
    "\n",
    "od_var = quality.measurement_variance(rec[\"od\"], list_bad_channels, bad_rel_var)\n",
    "\n",
    "## Display results as a heatmap, this time on a logarithmic scale as the penalty factor is large\n",
    "fig, ax = plot_heatmap(np.log(od_var))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Using Variance as Proxy for measurement Noise to Downweight Channels\n",
    "Lets apply this now, for instance to normalize signals using the noise proxy (smaller variance will amplify a signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize signals by their variance\n",
    "rec[\"normalized_od\"] = rec[\"od\"] / od_var\n",
    "\n",
    "# Plot normalized data for visual validation\n",
    "f,ax = plt.subplots(1,1, figsize=(12,4))\n",
    "\n",
    "ax.plot( rec[\"normalized_od\"].time, rec[\"normalized_od\"].sel(channel=\"S4D12\", wavelength=\"760\"), \"g-\", label=\"S4D12 760nm, weighted with variance = \" +str(od_var.sel(channel=\"S4D12\", wavelength=\"760\").values))\n",
    "ax.plot( rec[\"normalized_od\"].time, rec[\"normalized_od\"].sel(channel=\"S1D2\", wavelength=\"760\"), \"b-\", label=\"S1D2 760nm, weighted with variance = \" +str(od_var.sel(channel=\"S1D2\", wavelength=\"760\").values))\n",
    "ax.plot( rec[\"normalized_od\"].time, rec[\"normalized_od\"].sel(channel=\"S7D6\", wavelength=\"760\"), \"y-\", label=\"S7D6 760nm, weighted with variance = \" +str(od_var.sel(channel=\"S7D6\", wavelength=\"760\").values))\n",
    "ax.plot( rec[\"normalized_od\"].time, rec[\"normalized_od\"].sel(channel=\"S1D1\", wavelength=\"760\"), \"r-\", label=\"S1D1 760nm, weighted with penalty*variance = \"+str(bad_rel_var*od_var.sel(channel=\"S1D2\", wavelength=\"760\").values))\n",
    "plt.legend()\n",
    "ax.set_xlim(0, 500)\n",
    "ax.set_xlabel(\"time / s\")\n",
    "ax.set_ylabel(\"Signal intensity / a.u.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Channel Covariance\n",
    "Lastly, we might also be interested in channel covariance..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the same function to calculate the covariance of the optical density measurements\n",
    "list_bad_channels = [\"S1D1\", \"S4D4\"]\n",
    "bad_rel_var = 10  # much smaller factor than the default just to highlight the effect\n",
    "\n",
    "od_covar = quality.measurement_variance(rec[\"od\"], list_bad_channels, bad_rel_var, calc_covariance=True)\n",
    "display(od_covar)\n",
    "\n",
    "\n",
    "# use log(Var) again because we penalized the bad channels with a large factor\n",
    "fig, ax = plot_heatmap(od_covar, cov_wavelength=760.0, figsize=(10, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## (Weighted) Global Physiology Removal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cedalion.sigproc.physio import global_component_subtract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# just another helper function to make the relevant things below easier to read\n",
    "def plot_channel_wavelength(\n",
    "    rec: xr.Dataset,\n",
    "    dname: str,\n",
    "    diff: dict,\n",
    "    global_comp: xr.DataArray,\n",
    "    channel: str,\n",
    "    wavelength: float\n",
    "):\n",
    "    f, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "\n",
    "    # Original signal\n",
    "    ax.plot(\n",
    "        rec[\"od\"].time,\n",
    "        rec[\"od\"].sel({ \"channel\": channel, \"wavelength\": wavelength }),\n",
    "        \"b-\",\n",
    "        label=f\"{channel} {wavelength}nm (raw)\"\n",
    "    )\n",
    "\n",
    "    # Corrected signal\n",
    "    ax.plot(\n",
    "        rec[dname].time,\n",
    "        rec[dname].sel({ \"channel\": channel, \"wavelength\": wavelength }),\n",
    "        \"g-\",\n",
    "        label=f\"{channel} {wavelength}nm (corrected)\"\n",
    "    )\n",
    "\n",
    "    # Global component\n",
    "    ax.plot(\n",
    "        global_comp.time,\n",
    "        global_comp.sel({ \"wavelength\": wavelength }),\n",
    "        \"y-\",\n",
    "        label=f\"Global Component {wavelength}nm\"\n",
    "    )\n",
    "\n",
    "    # Difference (raw – corrected)\n",
    "    ax.plot(\n",
    "        rec[\"od\"].time,\n",
    "        diff[dname].sel({ \"channel\": channel, \"wavelength\": wavelength }),\n",
    "        \"r-\",\n",
    "        label=\"Difference (raw − corrected)\"\n",
    "    )\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set_xlim(100, 200)\n",
    "    ax.set_xlabel(\"time / s\")\n",
    "    ax.set_ylabel(\"Signal intensity / a.u.\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "First we get the original data and highpass filter it to remove slow drifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cedalion.sigproc import frequency\n",
    "\n",
    "# Refresh Data\n",
    "rec[\"od\"] = cedalion.nirs.int2od(rec[\"amp\"])\n",
    "\n",
    "# highpass filter data to remove slow drifts\n",
    "rec[\"od\"] = frequency.freq_filter(rec[\"od\"], fmin=0.01*units.Hz, fmax=2*units.Hz, butter_order=4)\n",
    "\n",
    "# initialize empty dictionary\n",
    "diff = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### (Fitted) Global Mean Subtraction\n",
    "We can use global_physio_subtract to remove the global average signal from each channel/vertex/voxel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dname = \"od_corr_gm\"\n",
    "\n",
    "rec[dname], global_comp = global_component_subtract(rec[\"od\"], ts_weights=None, k=0)\n",
    "diff[dname] = rec[\"od\"] - rec[dname] \n",
    "\n",
    "\n",
    "# plot results for channel S1D2 at 760nm\n",
    "plot_channel_wavelength(\n",
    "    rec=rec,\n",
    "    dname=dname,\n",
    "    diff=diff,\n",
    "    global_comp=global_comp,\n",
    "    channel=\"S1D2\",\n",
    "    wavelength=760.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### Weighted Global Mean Subtraction\n",
    "Since some channels might have a lot of artifacts or are noisy, we can use the variance as proxy for channel measurement noise from above in this notebook, to downweight noisy channel in the global mean subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "od_var = quality.measurement_variance(rec[\"od\"], calc_covariance=False)\n",
    "\n",
    "dname = \"od_corr_wgm\"\n",
    "rec[dname], global_comp = global_component_subtract(rec[\"od\"], ts_weights=1/od_var, k=0)\n",
    "diff[dname] = rec[\"od\"] - rec[dname] \n",
    "\n",
    "\n",
    "# plot results for channel S1D2 at 760nm\n",
    "plot_channel_wavelength(\n",
    "    rec=rec,\n",
    "    dname=dname,\n",
    "    diff=diff,\n",
    "    global_comp=global_comp,\n",
    "    channel=\"S1D2\",\n",
    "    wavelength=760.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### Remove exactly the first Principal Component (unweighted)\n",
    "Instead of the global mean we can also use PCA to find and remove global components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dname = \"od_corr_1pc\"\n",
    "rec[dname], global_comp = global_component_subtract(rec[\"od\"], ts_weights=None, k=1)\n",
    "diff[dname] = rec[\"od\"] - rec[dname] \n",
    "\n",
    "\n",
    "# plot results for channel S1D2 at 760nm\n",
    "plot_channel_wavelength(\n",
    "    rec=rec,\n",
    "    dname=dname,\n",
    "    diff=diff,\n",
    "    global_comp=global_comp,\n",
    "    channel=\"S1D2\",\n",
    "    wavelength=760.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "### Remove 1 PCA component but using measurement‐variance weights on the data\n",
    "If we want we can also include the channel weights from above in the PCA-based global signal removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "od_var = quality.measurement_variance(rec[\"od\"], calc_covariance=False)\n",
    "dname = \"od_corr_w1pc\"\n",
    "\n",
    "rec[dname], global_comp = global_component_subtract(rec[\"od\"], ts_weights= 1/od_var, k=1)\n",
    "diff[dname] = rec[\"od\"] - rec[dname]\n",
    "\n",
    "# plot results for channel S1D2 at 760nm\n",
    "plot_channel_wavelength(\n",
    "    rec=rec,\n",
    "    dname=dname,\n",
    "    diff=diff,\n",
    "    global_comp=global_comp,\n",
    "    channel=\"S1D2\",\n",
    "    wavelength=760.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "### Remove 95% of global variance (weighted)\n",
    "Often we dont know how many components to remove exactly, but how much variance the components we want to remove should explain. We can use k<1 to indicate the percent of variance we want removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dname = \"od_corr_w0.95pc\"\n",
    "rec[dname], global_comp = global_component_subtract(rec[\"od\"], ts_weights=1/od_var, k=0.95)\n",
    "diff[dname] = rec[\"od\"] - rec[dname] \n",
    "\n",
    "\n",
    "# plot results for channel S1D2 at 760nm\n",
    "plot_channel_wavelength(\n",
    "    rec=rec,\n",
    "    dname=dname,\n",
    "    diff=diff,\n",
    "    global_comp=global_comp,\n",
    "    channel=\"S1D2\",\n",
    "    wavelength=760.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "### Overall comparison of the effects of the shown approaches \n",
    "Lastly lets look at the difference (raw-corrected) signals for all of the approaches. Note that the differences between methods can be much stronger for more noisy data (our dataset here is quite clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots all signals for channel S1D2, 760nm in diff[dname] for all dnames and puts the dnames in the legend\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(12,4))\n",
    "\n",
    "for dname in diff.keys():\n",
    "    ax.plot(\n",
    "        rec[\"od\"].time,\n",
    "        diff[dname].sel({ \"channel\": \"S7D6\", \"wavelength\": 760.0 }),\n",
    "        label=dname\n",
    "    )\n",
    "ax.set_title(\"Difference between raw and corrected signals for channel S1D2, 760nm\")\n",
    "ax.legend()\n",
    "ax.set_xlim(100, 200)\n",
    "ax.set_xlabel(\"time / s\")\n",
    "ax.set_ylabel(\"Signal intensity / a.u.\")\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cedalion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
