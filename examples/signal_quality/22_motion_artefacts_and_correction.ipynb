{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion Artefact Detection and Correction\n",
    "This notebook shows how to identify and correct motion-artefacts using xarray-based masks and cedalion's correction functionality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cells setups the environment when executed in Google Colab.\n",
    "try:\n",
    "    import google.colab\n",
    "    !curl -s https://raw.githubusercontent.com/ibs-lab/cedalion/colab_setup/scripts/colab_setup.py -o colab_setup.py\n",
    "    # Select branch with --branch \"branch name\" (default is \"dev\")\n",
    "    %run colab_setup.py\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as p\n",
    "\n",
    "import cedalion\n",
    "import cedalion.datasets as datasets\n",
    "import cedalion.nirs\n",
    "import cedalion.sigproc.motion_correct as motion_correct\n",
    "import cedalion.sigproc.quality as quality\n",
    "import cedalion.sim.synthetic_artifact as synthetic_artifact\n",
    "from cedalion import units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get example finger tapping dataset\n",
    "\n",
    "rec = datasets.get_fingertapping()\n",
    "rec[\"od\"] = cedalion.nirs.int2od(rec[\"amp\"])\n",
    "\n",
    "# Add some synthetic spikes and baseline shifts\n",
    "artifacts = {\n",
    "    \"spike\": synthetic_artifact.gen_spike,\n",
    "    \"bl_shift\": synthetic_artifact.gen_bl_shift,\n",
    "}\n",
    "timing = synthetic_artifact.random_events_perc(rec[\"od\"].time, 0.01, [\"spike\"])\n",
    "timing = synthetic_artifact.add_event_timing(\n",
    "    [(200, 0), (400, 0)], \"bl_shift\", None, timing\n",
    ")\n",
    "rec[\"od\"] = synthetic_artifact.add_artifacts(rec[\"od\"], timing, artifacts)\n",
    "\n",
    "# Plot some data for visual validation\n",
    "f, ax = p.subplots(1, 1, figsize=(12, 4))\n",
    "ax.plot(\n",
    "    rec[\"od\"].time, rec[\"od\"].sel(channel=\"S3D3\", wavelength=\"850\"), \"r-\", label=\"850nm\"\n",
    ")\n",
    "ax.plot(\n",
    "    rec[\"od\"].time, rec[\"od\"].sel(channel=\"S3D3\", wavelength=\"760\"), \"g-\", label=\"760nm\"\n",
    ")\n",
    "\n",
    "# indicate added artefacts\n",
    "for _,row in timing.iterrows():\n",
    "    p.axvline(row[\"onset\"], c=\"k\", alpha=.2)\n",
    "\n",
    "p.legend()\n",
    "ax.set_xlim(0, 500)\n",
    "ax.set_xlabel(\"time / s\")\n",
    "ax.set_ylabel(\"OD\")\n",
    "\n",
    "\n",
    "display(rec[\"od\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(timing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting Motion Artifacts and generating the MA mask\n",
    "The example below shows how to check channels for motion artefacts using standard thresholds from Homer2/3. \n",
    "The output is a mask that can be handed to motion correction algorithms that require segments flagged as artefact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use Optical Density data for motion artifact detection\n",
    "fnirs_data = rec[\"od\"]\n",
    "\n",
    "# define parameters for motion artifact detection. We follow the method from Homer2/3:\n",
    "# \"hmrR_MotionArtifactByChannel\" and \"hmrR_MotionArtifact\".\n",
    "t_motion = 0.5 * units.s  # time window for motion artifact detection\n",
    "t_mask = 1.0 * units.s    # time window for masking motion artifacts\n",
    "                          # (+- t_mask s before/after detected motion artifact)\n",
    "stdev_thresh = 7.0        # threshold for std. deviation of the signal used to detect\n",
    "                          # motion artifacts. Default is 50. We set it very low to find\n",
    "                          # something in our good data for demonstration purposes.\n",
    "amp_thresh = 5.0          # threshold for amplitude of the signal used to detect motion\n",
    "                          # artifacts. Default is 5.\n",
    "\n",
    "# to identify motion artifacts with these parameters we call the following function\n",
    "ma_mask = quality.id_motion(fnirs_data, t_motion, t_mask, stdev_thresh, amp_thresh)\n",
    "\n",
    "# it hands us a boolean mask (xarray) of the input dimension, where False indicates a\n",
    "# motion artifact at a given time point:\n",
    "ma_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output mask is quite detailed and still contains all original dimensions (e.g. single wavelengths) and allows us to combine it with a mask from another motion artifact detection method. This is the same approach as for the channel quality metrics above.\n",
    "\n",
    "Let us now plot the result for an example channel. Note, that for both wavelengths a different number of artifacts was identified, which can sometimes happen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.figure()\n",
    "p.plot(ma_mask.time, ma_mask.sel(channel=\"S3D3\", wavelength=\"760\"), \"b-\")\n",
    "p.plot(ma_mask.time, ma_mask.sel(channel=\"S3D3\", wavelength=\"850\"), \"r-\")\n",
    "\n",
    "# indicate added artefacts\n",
    "for _,row in timing.iterrows():\n",
    "    p.axvline(row[\"onset\"], c=\"k\", alpha=.2)\n",
    "\n",
    "p.xlim(0, 500)\n",
    "p.xlabel(\"time / s\")\n",
    "p.ylabel(\"Motion artifact mask\")\n",
    "\n",
    "\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the mask and the data together (we have to rescale a bit to make both fit): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.figure()\n",
    "p.plot(fnirs_data.time, fnirs_data.sel(channel=\"S3D3\", wavelength=\"760\"), \"r-\")\n",
    "p.plot(ma_mask.time, ma_mask.sel(channel=\"S3D3\", wavelength=\"760\") / 10, \"k-\")\n",
    "\n",
    "# indicate added artefacts\n",
    "for _,row in timing.iterrows():\n",
    "    p.axvline(row[\"onset\"], c=\"k\", alpha=.2)\n",
    "\n",
    "p.xlim(0, 500)\n",
    "p.xlabel(\"time / s\")\n",
    "p.ylabel(\"fNIRS Signal / Motion artifact mask\")\n",
    "p.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refining the MA Mask\n",
    "At the latest when we want to correct motion artifacts, we usually do not need the level of granularity that the mask provides. For instance, we usually want to treat a detected motion artifact in either of both wavelengths or chromophores of one channel as a single artifact that gets flagged for both. We might also want to flag motion artifacts globally, i.e. mask time points for all channels even if only some of them show an artifact. This can easily be done by using the \"id_motion_refine\" function. The function also returns useful information about motion artifacts in each channel in \"ma_info\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refine the motion artifact mask. This function collapses the mask along dimensions\n",
    "# that are chosen by the \"operator\" argument. Here we use \"by_channel\", which will yield\n",
    "# a mask for each channel by collapsing the masks along either the wavelength or\n",
    "# concentration dimension.\n",
    "ma_mask_refined, ma_info = quality.id_motion_refine(ma_mask, \"by_channel\")\n",
    "\n",
    "# show the refined mask\n",
    "ma_mask_refined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the mask does not have the \"wavelength\" or \"concentration\" dimension anymore, and the masks of these dimensions are combined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the figure\n",
    "p.figure()\n",
    "p.plot(fnirs_data.time, fnirs_data.sel(channel=\"S3D3\", wavelength=\"760\"), \"r-\")\n",
    "p.plot(ma_mask_refined.time, ma_mask_refined.sel(channel=\"S3D3\") / 10, \"k-\")\n",
    "\n",
    "# indicate added artefacts\n",
    "for _,row in timing.iterrows():\n",
    "    p.axvline(row[\"onset\"], c=\"k\", alpha=.2)\n",
    "\n",
    "p.xlim(0, 500)\n",
    "p.xlabel(\"time / s\")\n",
    "p.ylabel(\"fNIRS Signal / Refined Motion artifact mask\")\n",
    "p.show()\n",
    "\n",
    "# show the information about the motion artifacts: we get a pandas dataframe telling us\n",
    "# 1) for which channels artifacts were detected,\n",
    "# 2) what is the fraction of time points that were marked as artifacts and\n",
    "# 3) how many artifacts where detected\n",
    "ma_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we look at the \"all\" operator, which will collapse the mask across all dimensions except time, leading to a single motion artifact mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"all\", yields a mask that flags an artifact at any given time if flagged for\n",
    "# any channetransl, wavelength, chromophore, etc.\n",
    "ma_mask_refined, ma_info = quality.id_motion_refine(ma_mask, 'all')\n",
    "\n",
    "# show the refined mask\n",
    "ma_mask_refined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the figure\n",
    "p.figure()\n",
    "p.plot(fnirs_data.time, fnirs_data.sel(channel=\"S3D3\", wavelength=\"760\"), \"r-\")\n",
    "p.plot(ma_mask_refined.time, ma_mask_refined/10, \"k-\")\n",
    "p.xlim(0,500)\n",
    "p.xlabel(\"time / s\")\n",
    "p.ylabel(\"fNIRS Signal / Refined Motion artifact mask\")\n",
    "p.show()\n",
    "\n",
    "# show the information about the motion artifacts: we get a pandas dataframe telling us\n",
    "# 1) that the mask is for all channels\n",
    "# 2) fraction of time points that were marked as artifacts for this mask across all\n",
    "#    channels\n",
    "# 3) how many artifacts where detected in total\n",
    "ma_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motion Correction\n",
    "\n",
    "Here we illustrate effect of different motion correction methods. Cedalion might have more methods, so make sure to check the API documentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_raw_cleaned(rec, key_raw, key_cleaned, title):\n",
    "    chwl = dict(channel=\"S3D3\", wavelength=\"850\")\n",
    "    f, ax = p.subplots(1, 1, figsize=(12, 4))\n",
    "    ax.plot(\n",
    "        rec[key_raw].time,\n",
    "        rec[key_raw].sel(**chwl),\n",
    "        \"r-\",\n",
    "        label=\"850nm raw\",\n",
    "    )\n",
    "    ax.plot(\n",
    "        rec[key_cleaned].time,\n",
    "        rec[key_cleaned].sel(**chwl),\n",
    "        \"g-\",\n",
    "        label=\"850nm cleaned\",\n",
    "    )\n",
    "    ax.set_xlim(0, 500)\n",
    "    ax.set_ylabel(\"OD\")\n",
    "    ax.set_xlabel(\"time / s\")\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "\n",
    "    # indicate added artefacts\n",
    "    for _,row in timing.iterrows():\n",
    "        p.axvline(row[\"onset\"], c=\"k\", alpha=.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SplineSG method: \n",
    "1. identifies baselineshifts in the data and uses spline interpolation to correct these shifts\n",
    "2. uses a Savitzky-Golay filter to remove spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_size = 10 * units.s\n",
    "rec[\"od_splineSG\"] = motion_correct.motion_correct_splineSG(\n",
    "    rec[\"od\"], frame_size=frame_size, p=1\n",
    ")\n",
    "\n",
    "compare_raw_cleaned(rec, \"od\", \"od_splineSG\", \"SplineSG\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TDDR:\n",
    "\n",
    "- Temporal Derivative Distribution Repair (TDDR) is a robust regression based motion correction algorithm.\n",
    "- Doesn't require any user-supplied parameters\n",
    "- See <cite data-cite=\"Fishburn2019\">(Fishburn, 2019)</cite>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbsphinx-tumbnail"
    ]
   },
   "outputs": [],
   "source": [
    "rec[\"od_tddr\"] = motion_correct.tddr(rec[\"od\"])\n",
    "\n",
    "compare_raw_cleaned(rec, \"od\", \"od_tddr\", \"TDDR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "\n",
    "- Apply motion correction using PCA filter on motion artefact segments (identified by mask).\n",
    "- Implementation is based on Homer3 v1.80.2 \"hmrR_MotionCorrectPCA.m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec[\"od_pca\"], nSV_ret, svs = motion_correct.motion_correct_PCA(\n",
    "    rec[\"od\"], ma_mask_refined\n",
    ")\n",
    "\n",
    "compare_raw_cleaned(rec, \"od\", \"od_pca\", \"PCA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive PCA\n",
    "\n",
    "- If any active channel exhibits signal change greater than STDEVthresh or AMPthresh, then that segment of data is marked as a motion artefact. \n",
    "- motion_correct_PCA is applied to all segments of data identified as a motion artefact.\n",
    "- This is called until maxIter is reached or there are no motion artefacts identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec[\"od_pca_r\"], svs, nSV, tInc = motion_correct.motion_correct_PCA_recurse(\n",
    "    rec[\"od\"], t_motion, t_mask, stdev_thresh, amp_thresh\n",
    ")\n",
    "\n",
    "compare_raw_cleaned(rec, \"od\", \"od_pca_r\", \"Recursive PCA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wavelet Motion Correction\n",
    "\n",
    "- Focused on spike artifacts\n",
    "- Can set iqr factor, wavelet, and wavelet decomposition level.\n",
    "- Higher iqr factor leads to more coefficients being discarded, i.e. more drastic correction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbsphinx-thumbnail"
    ]
   },
   "outputs": [],
   "source": [
    "rec[\"od_wavelet\"] = motion_correct.motion_correct_wavelet(rec[\"od\"])\n",
    "\n",
    "compare_raw_cleaned(rec, \"od\", \"od_wavelet\", \"Wavelet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cedalion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
