{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(sys.version)\n",
    "\n",
    "import matplotlib.pyplot as p\n",
    "from matplotlib.lines import Line2D\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "import pyvista as pv\n",
    "pv.set_jupyter_backend('server')\n",
    "#pv.set_jupyter_backend('static')\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "import cedalion\n",
    "import cedalion.sigproc.quality as quality\n",
    "import cedalion.dataclasses as cdc\n",
    "import cedalion.datasets\n",
    "import cedalion.geometry.registration # import icp_with_full_transform, find_spread_points\n",
    "import cedalion.geometry.segmentation\n",
    "from cedalion.geometry.photogrammetry.processors import ColoredStickerProcessor, geo3d_from_scan\n",
    "from cedalion.geometry.landmarks import order_ref_points_6\n",
    "import cedalion.imagereco.forward_model as fw\n",
    "import cedalion.imagereco.tissue_properties\n",
    "import cedalion.io\n",
    "import cedalion.plots # import OptodeSelector\n",
    "import cedalion.xrutils as xrutils\n",
    "from cedalion.imagereco.solver import pseudo_inverse_stacked\n",
    "from cedalion import units\n",
    "\n",
    "# for dev purposes\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "\n",
    "prefix =  'C:/Users/avonl/OneDrive/Work/Research/projects/2024 - AvLtapCedalion/data/' # local\n",
    "# prefix =  '/home/avonluh/data/' # cluster\n",
    "\n",
    "## Data loading directories and files\n",
    "# head segmentations\n",
    "SEG_DATADIR = prefix+'mri/segmented/'\n",
    "landmarks = 'landmarks.mrk.json'\n",
    "# Finger Tapping fNIRS data\n",
    "FT_DATADIR = prefix+'fnirs/data/'\n",
    "dataset ='2024-02-05_013.snirf'\n",
    "# Photogrammetric Scan\n",
    "PG_DATADIR = prefix+'photogrammetry/scan.obj'\n",
    "#PG_DATADIR = 'C://Users//avonl//My Drive (ibs.bifold@gmail.com)//photogrammetry//shift4.obj'\n",
    "# Fluence Profile (precalculated)\n",
    "FP_DATADIR = prefix+'fluence/'\n",
    "TEMP_DATADIR = prefix+'tempdata/'\n",
    "datafull = 'ftfull.snirf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Finger Tapping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME temporarily define ADU unit in this dataset to avoid an error\n",
    "#cedalion.units.define(\"ADU = 1\")\n",
    "#record = cedalion.io.read_snirf(FT_DATADIR+dataset)\n",
    "#rec = record[0]\n",
    "rec = cedalion.datasets.get_fingertappingDOT()\n",
    "# rename events\n",
    "rec.stim.cd.rename_events(\n",
    "        {\"1\": \"Rest\", \n",
    "         \"2\": \"FTapping/Left\", \n",
    "         \"3\": \"FTapping/Right\",\n",
    "         \"4\": \"BallSqueezing/Left\",\n",
    "         \"5\": \"BallSqueezing/Right\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Headmodel\n",
    "Getting segmented MRI scans from AvL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks={'csf': 'csf.nii', 'gm': 'gm.nii', 'scalp': 'scalp.nii', 'skull': 'skull.nii', 'wm': 'wm.nii'}\n",
    "\n",
    "head = fw.TwoSurfaceHeadModel.from_segmentation(\n",
    "    segmentation_dir=SEG_DATADIR,\n",
    "    mask_files = masks,\n",
    "    landmarks_ras_file=landmarks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot loaded head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = pv.Plotter(notebook=True, off_screen=False)\n",
    "plt.clear()  # Clear any previous plots\n",
    "\n",
    "cedalion.plots.plot_surface(plt, head.brain, color=\"#d3a6a1\")\n",
    "cedalion.plots.plot_surface(plt, head.scalp, opacity=.1)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register Probe to Headmodel using Photogrammetric scan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First plot the default probe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot montage\n",
    "cedalion.plots.plot_montage3D(rec[\"amp\"], rec.geo3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Display Photogrammetric Scan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load scan\n",
    "scan = cedalion.io.read_einstar_obj(PG_DATADIR)\n",
    "\n",
    "# find label stickers on the scan\n",
    "PGprocessor = cedalion.geometry.photogrammetry.processors.ColoredStickerProcessor(\n",
    "    colors={\n",
    "        \"O\" : ((0.11, 0.21, 0.7, 1)), # (hue_min, hue_max, value_min, value_max)\n",
    "        #\"L\" : ((0.25, 0.37, 0.35, 0.6))\n",
    "    }\n",
    ")\n",
    "sticker_centers, normals, details = PGprocessor.process(scan, details=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optodes can be manually removed or added, if not all were found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = cedalion.plots.OptodeSelector(scan, sticker_centers, normals)\n",
    "visualizer.plot()\n",
    "visualizer.enable_picking()\n",
    "cedalion.plots.plot_surface(visualizer.plotter, scan, opacity=1.0)\n",
    "visualizer.plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After selecting all optodes, update sticker_centers and normals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sticker_centers = visualizer.points\n",
    "normals = visualizer.normals if visualizer.normals is not None else normals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optode projection and landmark selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optode_length = 22.6 * cedalion.units.mm\n",
    "\n",
    "scalp_coords = sticker_centers.copy()\n",
    "mask_optodes = sticker_centers.group == 'O'\n",
    "scalp_coords[mask_optodes] = sticker_centers[mask_optodes] - optode_length*normals[mask_optodes]\n",
    "#display(scalp_coords)\n",
    "\n",
    "plt = pv.Plotter()\n",
    "cedalion.plots.plot_surface(plt, scan, opacity=0.3)\n",
    "cedalion.plots.plot_labeled_points(plt, sticker_centers, color=\"r\")\n",
    "cedalion.plots.plot_labeled_points(plt, scalp_coords, color=\"g\")\n",
    "cedalion.plots.plot_vector_field(plt, sticker_centers, normals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Landmark selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = pv.Plotter()\n",
    "get_landmarks = cedalion.plots.plot_surface(plt, scan, opacity=1.0, pick_landmarks = True)\n",
    "plt.show(interactive = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get landmarks from the plot\n",
    "Call *get_landmarks* from the previous cell and write into xarray\n",
    "* 1st value - coordinates of picked landmarks\n",
    "* 2nd - labels of corresponding landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "\n",
    "landmark_coordinates, landmark_labels = get_landmarks()\n",
    "\n",
    "# write into Xarray\n",
    "landmarks = xr.DataArray(\n",
    "    np.vstack(landmark_coordinates),\n",
    "    dims=[\"label\", \"digitized\"],\n",
    "    coords={\n",
    "        \"label\": (\"label\", landmark_labels),\n",
    "        \"type\": (\"label\", [cdc.PointType.LANDMARK]*5),\n",
    "        \"group\": (\"label\", [\"L\"]*5),\n",
    "    },\n",
    ").pint.quantify(\"mm\")\n",
    "\n",
    "\n",
    "display(landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load montage info from snirf file and find transformation between  montage to landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage_elements = rec.geo3d\n",
    "montage_elements = montage_elements.rename({\"digitized\" : \"aligned\"})\n",
    "#montage_elements\n",
    "# find transformation between landmarks and montage elements\n",
    "trafo = cedalion.geometry.registration.register_trans_rot(landmarks, montage_elements)\n",
    "\n",
    "# apply the transformation to the montage elements\n",
    "filtered_montage_elements = montage_elements.where((montage_elements.type == cdc.PointType.SOURCE) | (montage_elements.type == cdc.PointType.DETECTOR), drop=True)\n",
    "filtered_montage_elements_t = filtered_montage_elements.points.apply_transform(trafo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coregistration: find and assign optode labels of scalp coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalp_coords = sticker_centers.copy()\n",
    "\n",
    "# iterative closest point registration\n",
    "idx = cedalion.geometry.registration.icp_with_full_transform(scalp_coords, \n",
    "                                                                            filtered_montage_elements_t, max_iterations = 100) \n",
    "# extract labels for detected optodes\n",
    "label_dict = {}\n",
    "for i, label in enumerate(filtered_montage_elements.coords['label'].values):\n",
    "    label_dict[i] = label\n",
    "labels = [label_dict[index] for index in idx]\n",
    "\n",
    "# write labels to scalp_coords\n",
    "scalp_coords = scalp_coords.assign_coords(label=labels)\n",
    "\n",
    "\n",
    "## visualize results\n",
    "# Green points represent optode centers\n",
    "# Next to them there shall be labels assumed by ICP algorithm (*show_labels = True*)\n",
    "plt = pv.Plotter()\n",
    "cedalion.plots.plot3d(None, scan.mesh, filtered_montage_elements_t, None, plotter = plt) \n",
    "cedalion.plots.plot_labeled_points(plt, scalp_coords, color=\"green\", show_labels = True)\n",
    "plt.show(interactive = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update geo3D coordinates for the headmodel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform coordinates to headmodel coordinates and snap to surface. Save them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update geo3D with accurate optode scalp positions and landmarks\n",
    "geo3Dscan = geo3d_from_scan(scalp_coords, landmarks)\n",
    "# save geo3Dscan to disk via snirf by using a copy of rec\n",
    "rectmp = rec\n",
    "rectmp.geo3d = geo3Dscan\n",
    "\n",
    "# save data\n",
    "SAVEDATA = False\n",
    "if SAVEDATA:\n",
    "    cedalion.io.write_snirf(TEMP_DATADIR + datafull, rectmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Finger Tapping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prune with SNR threshold\n",
    "snr_thresh = 10 # dB\n",
    "snr, rec.masks[\"snr_mask\"] = quality.snr(rec[\"amp\"], snr_thresh)\n",
    "# prune channels using the masks and the operator \"all\", which will keep only channels that pass all three metrics\n",
    "rec[\"amp_pruned\"], drop_list = quality.prune_ch(rec[\"amp\"], [rec.masks[\"snr_mask\"]], \"all\")\n",
    "\n",
    "# Convert to OD\n",
    "rec[\"od\"] = cedalion.nirs.int2od(rec[\"amp\"])\n",
    "\n",
    "## find and remove movement artifacts\n",
    "# define parameters for motion artifact detection. We follow the method from Homer2/3: \"hmrR_MotionArtifactByChannel\" and \"hmrR_MotionArtifact\".\n",
    "t_motion = 0.5*units.s  # time window for motion artifact detection\n",
    "t_mask = 1.0*units.s    # time window for masking motion artifacts (+- t_mask s before/after detected motion artifact)\n",
    "stdev_thresh = 4.0      # threshold for standard deviation of the signal used to detect motion artifacts. Default is 50. We set it very low to find something in our good data for demonstration purposes.\n",
    "amp_thresh = 5.0        # threshold for amplitude of the signal used to detect motion artifacts. Default is 5.\n",
    "# to identify motion artifacts with these parameters we call the following function\n",
    "rec.masks[\"ma_mask\"] = quality.id_motion(rec[\"od\"], t_motion, t_mask, stdev_thresh, amp_thresh)\n",
    "rec.masks[\"ma_mask\"], ma_info = quality.id_motion_refine(rec.masks[\"ma_mask\"], 'by_channel')\n",
    "# THIS IS WHERE WE WOULD APPLY SPLINE SG\n",
    "# XXXXXXXXXXXXXXX\n",
    "# XXXXXXXXXXXXXXX\n",
    "\n",
    "\n",
    "# Convert to  HbO/HbR\n",
    "dpf = xr.DataArray(\n",
    "        [6, 6],\n",
    "        dims=\"wavelength\",\n",
    "        coords={\"wavelength\": rec[\"amp\"].wavelength},\n",
    "    )\n",
    "rec[\"conc\"] = cedalion.nirs.beer_lambert(rec[\"amp_pruned\"], rec.geo3d, dpf)\n",
    "\n",
    "\n",
    "# lowpass od concentration data for image recon later\n",
    "rec[\"od_freqfilt\"] = rec[\"od\"].cd.freq_filter(\n",
    "        fmin=0.01, fmax=0.5, butter_order=4\n",
    "    )\n",
    "# lowpass filter concentration data for block averages below\n",
    "rec[\"conc_freqfilt\"] = rec[\"conc\"].cd.freq_filter(\n",
    "        fmin=0.01, fmax=0.5, butter_order=4\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot a channel for quality control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.figure()\n",
    "p.plot(rec[\"conc\"].time, rec[\"conc\"].sel(channel=\"S1D2\", chromo=\"HbO\"), \"r-\", label=\"HbO\")\n",
    "p.plot(rec[\"conc\"].time, rec[\"conc\"].sel(channel=\"S1D2\", chromo=\"HbR\"), \"b-\", label=\"HbR\")\n",
    "\n",
    "# Adding vertical stimulus lines\n",
    "clr = {'Rest': 'g', 'FTapping/Left': 'y', 'FTapping/Right': 'm', 'BallSqueezing/Left': 'c', 'BallSqueezing/Right': 'k'}\n",
    "for idx, onset in enumerate(rec.stim['onset']):\n",
    "    # Use the index to get the corresponding element in the 'duration' column\n",
    "    type = rec.stim.at[idx, 'trial_type']\n",
    "    p.axvline(x=onset, color=clr[type], linestyle='--', label=type)\n",
    "\n",
    "p.xlabel(\"time / s\")\n",
    "p.ylabel(\"delta Conc / ÂµM\")\n",
    "\n",
    "\n",
    "# Defining custom legend handles and labels\n",
    "custom_handles = [\n",
    "    p.Line2D([0], [0], color='g', lw=2, label='Rest'),\n",
    "    p.Line2D([0], [0], color='y', lw=2, label='FTapping/Left'),\n",
    "    p.Line2D([0], [0], color='m', lw=2, label='FTapping/Right'),\n",
    "    p.Line2D([0], [0], color='c', lw=2, label='BallSqueezing/Left'),\n",
    "    p.Line2D([0], [0], color='k', lw=2, label='BallSqueezing/Right'),\n",
    "]\n",
    "\n",
    "# Adding the custom legend\n",
    "p.legend(handles=custom_handles, loc='upper right')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Block Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## keep only subset of long channels\n",
    "sd_threshs = [2, 4.5]*units.cm # defines the lower and upper bounds for the source-detector separation that we would like to keep\n",
    "ch_dist, rec.masks[\"sd_mask\"] = quality.sd_dist(rec[\"conc_freqfilt\"], rec.geo3d, sd_threshs)\n",
    "rec[\"conc_freqfilt_LD\"], masked_elements = xrutils.apply_mask(rec[\"conc_freqfilt\"], rec.masks[\"sd_mask\"], \"drop\", \"channel\")\n",
    "\n",
    "\n",
    "# segment data into epochs\n",
    "rec[\"cfepochs\"] = rec[\"conc_freqfilt_LD\"].cd.to_epochs(\n",
    "        rec.stim,  # stimulus dataframe\n",
    "        [\"FTapping/Left\", \"FTapping/Right\"],#, \"BallSqueezing/Left\", \"BallSqueezing/Right\"], # select events. do not use \"Rest\"\n",
    "        before=5*units.s,  # seconds before stimulus\n",
    "        after=20*units.s,  # seconds after stimulus\n",
    ")\n",
    "\n",
    "# calculate baseline\n",
    "baseline_conc = rec[\"cfepochs\"].sel(reltime=(rec[\"cfepochs\"].reltime < 0)).mean(\"reltime\")\n",
    "# subtract baseline\n",
    "rec[\"conc_epochs_blcorrected_LD\"] = rec[\"cfepochs\"] - baseline_conc\n",
    "\n",
    "# group trials by trial_type. For each group individually average the epoch dimension\n",
    "rec[\"blockaverage_conc\"] = rec[\"conc_epochs_blcorrected_LD\"] .groupby(\"trial_type\").mean(\"epoch\")\n",
    "\n",
    "# Define line styles and trial types\n",
    "line_styles = [\"-\", \"--\", \"-.\", \":\"]\n",
    "trial_types = [\"FTapping/Left\", \"FTapping/Right\", \"BallSqueezing/Left\", \"BallSqueezing/Right\"]\n",
    "\n",
    "# Create custom legend handles\n",
    "legend_handles = [Line2D([0], [0], color='k', lw=2, ls=ls, label=tt) for ls, tt in zip(line_styles, trial_types)]\n",
    "\n",
    "# plot single channels\n",
    "noPlts2 = int(np.ceil(np.sqrt(len(rec[\"blockaverage_conc\"].channel))))\n",
    "f, ax = p.subplots(noPlts2, noPlts2, figsize=(12, 10))\n",
    "ax = ax.flatten()\n",
    "for i_ch, ch in enumerate(rec[\"blockaverage_conc\"].channel):\n",
    "    for ls, trial_type in zip(line_styles, rec[\"blockaverage_conc\"].trial_type):\n",
    "        ax[i_ch].plot(\n",
    "            rec[\"blockaverage_conc\"].reltime,\n",
    "            rec[\"blockaverage_conc\"].sel(chromo=\"HbO\", trial_type=trial_type, channel=ch),\n",
    "            \"r\",\n",
    "            lw=2,\n",
    "            ls=ls,\n",
    "        )\n",
    "        ax[i_ch].plot(\n",
    "            rec[\"blockaverage_conc\"].reltime,\n",
    "            rec[\"blockaverage_conc\"].sel(chromo=\"HbR\", trial_type=trial_type, channel=ch),\n",
    "            \"b\",\n",
    "            lw=2,\n",
    "            ls=ls,\n",
    "        )\n",
    "    ax[i_ch].grid(1)\n",
    "    ax[i_ch].set_title(ch.values)\n",
    "    ax[i_ch].set_ylim(-0.3, 0.6)\n",
    "\n",
    "# Add the legend to the first subplot\n",
    "ax[0].legend(handles=legend_handles, title=\"Trial Types\", loc='lower right')\n",
    "p.tight_layout()\n",
    "\n",
    "p.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOT Image Reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optode Registration\n",
    "Align the photogrammetrically registered optode positions with the scalp surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_SCANCOORDS = False\n",
    "# if we did the photogrammetric coregistration in a previous session and saved the results, load them here from our temp snirf file\n",
    "if LOAD_SCANCOORDS:\n",
    "    recordtmp = cedalion.io.read_snirf(TEMP_DATADIR + datafull)\n",
    "    rectmp = record[0]\n",
    "    geo3Dscan = rectmp.geo3d\n",
    "\n",
    "geo3dscan_snapped_ijk = head.align_and_snap_to_scalp(geo3Dscan)\n",
    "\n",
    "plt = pv.Plotter(notebook=True, off_screen=False)\n",
    "cedalion.plots.plot_surface(plt, head.brain, color=\"#d3a6a1\")\n",
    "cedalion.plots.plot_surface(plt, head.scalp, opacity=.1)\n",
    "cedalion.plots.plot_labeled_points(plt, geo3dscan_snapped_ijk, show_labels = True)\n",
    "plt.show(interactive = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate light propagation with MCX or NIRFASTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwm = cedalion.imagereco.forward_model.ForwardModel(head, geo3dscan_snapped_ijk, rec._measurement_lists[\"amp\"])\n",
    "\n",
    "USE_CACHED = True\n",
    "RUN_PACKAGE = 'NIRFASTer' # or 'MCX'\n",
    "\n",
    "if USE_CACHED:\n",
    "    fname = FP_DATADIR+'AvL_fluence.pickle.gz'\n",
    "    with gzip.GzipFile(fname) as fin:        \n",
    "        fluence_all, fluence_at_optodes = pickle.load(fin)\n",
    "else:\n",
    "    if RUN_PACKAGE == 'MCX':\n",
    "        fluence_all, fluence_at_optodes = fwm.compute_fluence_mcx()\n",
    "    elif RUN_PACKAGE == 'NIRFASTer':\n",
    "        fluence_all, fluence_at_optodes = fwm.compute_fluence_nirfaster()\n",
    "    # save computed fluence data (xarrays) to disk to avoid having to re-run each time\n",
    "    file = gzip.GzipFile(FP_DATADIR+'AvL_fluence.pickle.gz', 'wb')\n",
    "    file.write(pickle.dumps([fluence_all, fluence_at_optodes]))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot fluence\n",
    "\n",
    "To illustrate the tissue probed by light travelling from a source to the detector two fluence profiles need to be multiplied. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(1)\n",
    "\n",
    "plt = pv.Plotter()\n",
    "\n",
    "f = fluence_all.loc[\"S1\", 760].values * fluence_all.loc[\"D8\",760].values\n",
    "f[f<=0] = f[f>0].min()\n",
    "f = np.log10(f)\n",
    "vf = pv.wrap(f)\n",
    "\n",
    "plt.add_volume(\n",
    "    vf,\n",
    "    log_scale=False, \n",
    "    cmap='plasma_r',\n",
    "    clim=(-10,0),\n",
    ")\n",
    "cedalion.plots.plot_surface(plt, head.brain, color=\"w\")\n",
    "cedalion.plots.plot_labeled_points(plt, geo3dscan_snapped_ijk, show_labels = True)\n",
    "\n",
    "cog = head.brain.vertices.mean(\"label\").values\n",
    "plt.camera.position = cog + [-300,30, 150]\n",
    "plt.camera.focal_point = cog \n",
    "plt.camera.up = [0,0,1] \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the sensitivity matrices\n",
    "\n",
    "The sensitivity matrix describes the effect of an absorption change at a given surface vertex in the OD recording in a given channel and at given wavelength. The coordinate `is_brain` holds a mask to distinguish brain and scalp voxels.\n",
    "\n",
    "The sensitivity `Adot` has shape (nchannel, nvertex, nwavelenghts). To solve the inverse problem we need a matrix that relates OD in channel space to absorption in image space. Hence, the sensitivity must include the extinction coefficients to translate between OD and concentrations. Furthermore, channels at different wavelengths must be  stacked as well vertice and chromophores into new dimensions (flat_channel, flat_vertex):\n",
    "\n",
    "$$ \\left( \\begin{matrix} OD_{c_1, \\lambda_1} \\\\ \\vdots \\\\ OD_{c_N,\\lambda_1} \\\\ OD_{c_1,\\lambda_2} \\\\ \\vdots \\\\ OD_{c_N,\\lambda_2} \\end{matrix}\\right) = A \\cdot\n",
    "\\left( \\begin{matrix} \\Delta c_{v_1, HbO} \\\\ \\vdots \\\\ \\Delta c_{v_N, HbO} \\\\ \\Delta c_{v_1, HbR} \\\\ \\vdots \\\\ \\Delta c_{v_N, HbR} \\end{matrix}\\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute sensitivity matrix\n",
    "Adot = fwm.compute_sensitivity(fluence_all, fluence_at_optodes)\n",
    "Adot_stacked = fwm.compute_stacked_sensitivity(Adot)\n",
    "# Invert the matrix\n",
    "B = pseudo_inverse_stacked(Adot_stacked, alpha = 0.01, alpha_spatial = 0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate average concentration changes on the cortex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_epochs = rec[\"od_freqfilt\"].cd.to_epochs(\n",
    "        rec.stim, # stimulus dataframe\n",
    "        [\"FTapping/Left\", \"FTapping/Right\", \"BallSqueezing/Left\", \"BallSqueezing/Right\"],  # select events\n",
    "        before=5*units.s, # seconds before stimulus\n",
    "        after=20*units.s  # seconds after stimulus\n",
    ")\n",
    "\n",
    "# calculate baseline\n",
    "od_baseline = od_epochs.sel(reltime=(od_epochs.reltime < 0)).mean(\"reltime\")\n",
    "# subtract baseline\n",
    "od_epochs_blcorrected = od_epochs - od_baseline\n",
    "\n",
    "# group trials by trial_type. For each group individually average the epoch dimension\n",
    "od_blockaverage = od_epochs_blcorrected.groupby(\"trial_type\").mean(\"epoch\")\n",
    "\n",
    "\n",
    "\n",
    "# calculate the concentration on cortex by multiypling with the inverted sensitivity matrix\n",
    "dC_brain, dC_scalp = fw.apply_inv_sensitivity(od_blockaverage, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results of image recon\n",
    "\n",
    "Using functionality from pyvista and VTK plot the concentration changes on the brain surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cedalion.plots import image_recon_multi_view \n",
    "\n",
    "filename_multiview = 'image_recon_multiview'\n",
    "\n",
    "# prepare data\n",
    "X_ts = xr.concat([dC_brain.sel(trial_type=\"FTapping/Right\"), dC_scalp.sel(trial_type=\"FTapping/Right\")], dim=\"vertex\")\n",
    "X_ts = X_ts.rename({\"reltime\": \"time\"})\n",
    "X_ts = X_ts.transpose(\"vertex\", \"chromo\", \"time\")\n",
    "X_ts = X_ts.assign_coords(is_brain=('vertex', Adot.is_brain.values))\n",
    "\n",
    "scl = np.percentile(np.abs(X_ts.sel(chromo='HbO').values.reshape(-1)),99)\n",
    "clim = (-scl,scl)\n",
    "\n",
    "# selects the nearest time sample at t=10s in X_ts\n",
    "#X_ts = X_ts.sel(time=5*units.s, method=\"nearest\")\n",
    "\n",
    "image_recon_multi_view(\n",
    "    X_ts,  # time series data; can be 2D (static) or 3D (dynamic)\n",
    "    head,\n",
    "    cmap='seismic',\n",
    "    clim=clim,\n",
    "    view_type='hbo_brain',\n",
    "    title_str='HbO',\n",
    "    filename=filename_multiview,\n",
    "    SAVE=True,\n",
    "    time_range=(-5,30,0.5)*units.s,\n",
    "    fps=6,\n",
    "    geo3d_plot = None, #  geo3d_plot\n",
    "    wdw_size = (1024, 768)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(data=open(\"image_recon_multiview.png\",'rb').read(), format='png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cedalion.plots import image_recon_multi_view \n",
    "\n",
    "filename_multiview = 'image_recon_multiview_scalp'\n",
    "\n",
    "\n",
    "image_recon_multi_view(\n",
    "    X_ts,  # time series data; can be 2D (static) or 3D (dynamic)\n",
    "    head,\n",
    "    cmap='seismic',\n",
    "    clim=clim,\n",
    "    view_type='hbo_scalp',\n",
    "    title_str='HbO',\n",
    "    filename=filename_multiview,\n",
    "    SAVE=True,\n",
    "    time_range=(-5,30,0.5)*units.s,\n",
    "    fps=6,\n",
    "    geo3d_plot = None, #  geo3d_plot\n",
    "    wdw_size = (1024, 768)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(data=open(\"image_recon_multiview_scalp.gif\",'rb').read(), format='png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WIP! Training a LDA classifier with Scikit-Learn\n",
    "For this example we use a very simple non-sophisticated approach. This section is currently WIP and probably flawed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with the frequency-filtered, epoched and baseline-corrected concentration data\n",
    "# discard the samples before the stimulus onset\n",
    "epochs = rec[\"conc_epochs_blcorrected_LD\"].sel(reltime=rec[\"conc_epochs_blcorrected_LD\"].reltime >=0)\n",
    "# strip units. sklearn would strip them anyway and issue a warning about it.\n",
    "epochs = epochs.pint.dequantify()\n",
    "\n",
    "# need to manually tell xarray to create an index for trial_type\n",
    "epochs = epochs.set_xindex(\"trial_type\")\n",
    "# pool finger tapping and ball squeezing trial types into only \"left\" vs \"right\"\n",
    "\n",
    "#calculate the mean amplitude in the interval 8-15s after stimulus onset as a feature\n",
    "epochs_meanfeature = epochs.sel(reltime=slice(8,15)).mean(\"reltime\")\n",
    "# stack the features of all channels and chromophores into a single feature vector \n",
    "X = epochs_meanfeature.stack(features=[\"chromo\", \"channel\"])\n",
    "#display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# reduce the set of trials to include only the desired trial types, here Finger Tapping\n",
    "ttype_des = [\"FTapping/Left\", \"FTapping/Right\"] # \"BallSqueezing/Left\", \"BallSqueezing/Right\"\n",
    "X_des = X.where(X.trial_type.isin(ttype_des), drop=True)\n",
    "display(X_des.sel(channel=\"S4D6\", chromo =\"HbO\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plot of an example feature: HbO at Channel S4D6 for both trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select the data for HbO and HbR\n",
    "HbO_data_l = X_des.sel(channel=\"S4D6\", chromo=\"HbO\", trial_type=\"FTapping/Left\")\n",
    "HbO_data_r = X_des.sel(channel=\"S4D6\", chromo=\"HbO\", trial_type=\"FTapping/Right\")\n",
    "\n",
    "# Extract the values to be plotted\n",
    "HbO_data_lvs = HbO_data_l.values\n",
    "HbO_data_rvs = HbO_data_r.values\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(HbO_data_lvs, HbO_data_rvs, c='blue', alpha=0.5, label=\"HbO L vs HbO R\")\n",
    "plt.plot([-0.4, 0.8], [-0.4, 0.8], 'r--', label='y = x')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"HbO Values L\")\n",
    "plt.ylabel(\"HbO Values R\")\n",
    "plt.title(\"Scatter Plot of HbO L vs R (Channel: S4D6)\")\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the trial types and train classifier\n",
    "y = xr.apply_ufunc(LabelEncoder().fit_transform, X.trial_type)\n",
    "\n",
    "# Initialize the classifier\n",
    "classifier = LinearDiscriminantAnalysis(n_components=1)\n",
    "\n",
    "# Set up 10-fold cross-validation\n",
    "kf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# Perform cross-validation\n",
    "cross_val_scores = cross_val_score(classifier, X, y, cv=kf)\n",
    "\n",
    "# Print the accuracy for each fold\n",
    "print(\"Cross-validation accuracy scores for each fold:\")\n",
    "for i, score in enumerate(cross_val_scores, start=1):\n",
    "    print(f\"Fold {i}: {score:.4f}\")\n",
    "\n",
    "# Print the mean accuracy across all folds\n",
    "print(f\"\\nMean accuracy across all folds: {cross_val_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = p.subplots(1, 2, figsize=(12, 3))\n",
    "\n",
    "for trial_type, c in zip([\"FTapping/Left\", \"FTapping/Right\"], [\"r\", \"g\"]):\n",
    "    kw = dict(alpha=0.5, fc=c, label=trial_type)\n",
    "    ax[0].hist(classifier.decision_function(X_train.sel(trial_type=trial_type)), **kw)\n",
    "    ax[1].hist(classifier.decision_function(X_test.sel(trial_type=trial_type)), **kw)\n",
    "\n",
    "ax[0].set_xlabel(\"LDA score\")\n",
    "ax[1].set_xlabel(\"LDA score\")\n",
    "ax[0].set_title(\"train\")\n",
    "ax[1].set_title(\"test\")\n",
    "ax[0].legend(ncol=1, loc=\"upper left\")\n",
    "ax[1].legend(ncol=1, loc=\"upper left\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cedalion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
