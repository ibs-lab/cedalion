{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Head Models and Coordinate Reference Systems (CRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cells setups the environment when executed in Google Colab.\n",
    "try:\n",
    "    import google.colab\n",
    "    !curl -s https://raw.githubusercontent.com/ibs-lab/cedalion/colab_setup/scripts/colab_setup.py -o colab_setup.py\n",
    "    # Select branch with --branch \"branch name\" (default is \"dev\")\n",
    "    %run colab_setup.py\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "#pv.set_jupyter_backend('server')\n",
    "pv.set_jupyter_backend('static')\n",
    "\n",
    "import os\n",
    "import xarray as xr\n",
    "\n",
    "import cedalion\n",
    "import cedalion.io\n",
    "import cedalion.plots\n",
    "import cedalion.datasets\n",
    "import cedalion.imagereco.forward_model as fw\n",
    "\n",
    "xr.set_options(display_expand_data=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the ICBM-152 head model\n",
    "\n",
    "- the `TwoSurfaceHeadModel` holds the segmented MRT image and derived cortex and scalp surfaces\n",
    "- we provide functionality to derive these surfaces from the masks or to load them from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pathes to segmentation data for the icbm-152 atlas\n",
    "SEG_DATADIR, mask_files, landmarks_file = cedalion.datasets.get_icbm152_segmentation()\n",
    "\n",
    "# create forward model class for icbm152 atlas\n",
    "head_icbm152 = fw.TwoSurfaceHeadModel.from_surfaces(\n",
    "    segmentation_dir=SEG_DATADIR,\n",
    "    mask_files=mask_files,\n",
    "    brain_surface_file=os.path.join(SEG_DATADIR, \"mask_brain.obj\"),\n",
    "    landmarks_ras_file=landmarks_file,\n",
    "    brain_face_count=None,\n",
    "    scalp_face_count=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbsphinx-thumbnail"
    ]
   },
   "outputs": [],
   "source": [
    "plt = pv.Plotter()\n",
    "cedalion.plots.plot_surface(plt, head_icbm152.brain, color=\"#d3a6a1\")\n",
    "cedalion.plots.plot_surface(plt, head_icbm152.scalp, opacity=.1)\n",
    "cedalion.plots.plot_labeled_points(plt, head_icbm152.landmarks, show_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation masks\n",
    "\n",
    "The head model comprises masks for different tissue types: CSF, Gray Matter, White Matter, Scalp and Skull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_icbm152.segmentation_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coordinate System\n",
    "\n",
    "- we need to distinguish several coordinate systems: voxel space, scanner space, subject space, ...\n",
    "- geometric data types carry information about which crs they use\n",
    "- transformations between coordinate systems through affine transformations\n",
    "\n",
    "\n",
    "The head model is loaded in voxel space ('ijk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_icbm152.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The head model contains initial landmarks ('Nz', 'Iz', 'LPA' and 'RPA') stored as a LabeledPointCloud.\n",
    "The crs is stored as the name of the second dimension, easily retrievable through the `.points`-accessor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(head_icbm152.landmarks)\n",
    "display(head_icbm152.landmarks.points.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Triangulated surface meshes of the scalp and brain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(head_icbm152.brain)\n",
    "display(head_icbm152.scalp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_icbm152.t_ijk2ras # transformation from voxel to subject (RAS) space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change to subject (RAS) space by applying an affine transformation on the head model.\n",
    "This transforms all components.\n",
    "\n",
    "Here, the subject space is called 'aligned' (the label is derived from information in the mask's nifti file)\n",
    "\n",
    "The scanner space also uses physical units whereas coordinates in voxel space are dimensionless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trafo = head_icbm152.t_ijk2ras\n",
    "\n",
    "head_icbm152_ras = head_icbm152.apply_transform(trafo)\n",
    "\n",
    "display(head_icbm152_ras.crs)\n",
    "display(head_icbm152_ras.landmarks.points.crs)\n",
    "display(head_icbm152_ras.brain.crs)\n",
    "\n",
    "display(head_icbm152.landmarks.pint.units)\n",
    "display(head_icbm152_ras.landmarks.pint.units)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cedalion_240902",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
