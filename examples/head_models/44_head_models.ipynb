{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRI T1 Processing and Segmentation Documentation\n",
    "\n",
    "This notebook outlines the workflow for MRI T1 processing and segmentation, specifically tailored for use within Cedalion. Cedalion workflows require either individual or standard head models, built from raw T1 images through a series of segmentation and brain surface extraction steps. This document details the complete processing pipeline for creating standard head models, facilitating the extension of these methods to individual head models.\n",
    "\n",
    "## Overview of the Processing Workflow\n",
    "\n",
    "The workflow integrates multiple tools outside Python, including Brainstorm, CAT12, and FreeSurfer, for sequential processing of MRI data. This documentation provides a step-by-step guide to help ensure efficient data preparation, segmentation, and model alignment.\n",
    "\n",
    "### Step 1: T1 Image Preprocessing with CAT12 in Brainstorm\n",
    "\n",
    "1. **Brainstorm Overview**:  \n",
    "   Brainstorm is an open-source application designed for the analysis of brain recordings. It can be used as a standalone version or installed via MATLAB, and is integral to many neuroimaging workflows. It makes it easy to perform CAT12 and Freesurfer analysis.\n",
    "\n",
    "2. **CAT12 Toolbox**:  \n",
    "   CAT12 is a computational toolbox within the SPM (Statistical Parametric Mapping) environment, primarily used for structural MRI (sMRI) analysis. CAT12 automates many preprocessing steps required for sMRI, including:\n",
    "   - **Tissue segmentation** into six types (skull, scalp, cerebrospinal fluid [CSF], gray matter, white matter, and air).\n",
    "   - **Normalization and modulation** of images.\n",
    "   - **Surface generation** for brain and head models.\n",
    "\n",
    "   **Output from CAT12**: For Cedalion, we use CAT12’s outputted 6-type tissue segmentations (skull, scalp, CSF, gray matter, white matter, and air) and the generated head surface.\n",
    "\n",
    "### Step 2: T1 Image Preprocessing with SPM12 (using Nils code)\n",
    "\n",
    "   Nils has a repository which contains a MATLAB workflow for MRI segmentation + postprocessing. I usually do the segmentation with using both CAT12 in Brainstorm and Nils workflow and choose the best one!\n",
    "\n",
    "### Step 3: Detailed Analysis with FreeSurfer\n",
    "\n",
    "1. **FreeSurfer Overview**:  \n",
    "   FreeSurfer is a widely-used software package in neuroimaging, specifically for MRI structural analysis. Known for its precise and reproducible methods, FreeSurfer is used to segment brain structures, reconstruct cortical surfaces, and quantify cortical thickness, surface area, and volume.\n",
    "\n",
    "2. **Processing Outputs**:  \n",
    "   In this workflow, FreeSurfer provides details including:\n",
    "   - **Cortical and subcortical segmentation**\n",
    "   - **Gray and white matter segmentation**\n",
    "   - **Detailed brain surface model**\n",
    "\n",
    "   **Key Outputs from FreeSurfer**: Cedalion’s workflow uses FreeSurfer’s gray matter and white matter segmentations and its detailed brain surface model.\n",
    "\n",
    "### Step 4: Parcellation using Schaefer Atlas\n",
    "   The Schaefer Atlas is a popular parcellation scheme for the human brain used in neuroimaging research. It was developed by Schaefer et al. (2018) and provides a fine-grained parcellation of the cortex based on functional connectivity data from resting-state fMRI. One of the distinctive features of the Schaefer Atlas is its organization of brain regions into well-defined networks that reflect patterns of correlated brain activity.\n",
    "   The atlas offers two primary options for network parcellation:\n",
    "\n",
    "   1. Schaefer Atlas with 7 Networks\n",
    "      This version divides the brain into 7 broad functional networks. Often used in studies where the focus is on high-level brain networks, such as understanding large-scale brain organization, general connectivity patterns, or when simplifying data for group analyses.\n",
    "\n",
    "   2. Schaefer Atlas with 17 Networks\n",
    "      This version provides a more granular division of the brain into 17 functional networks. These include the original 7 networks, but with further subdivisions. Suitable for studies that require more detailed parcellation to capture subtle differences in brain function, such as exploring intra-network connectivity or specific functional regions within the brain's broader networks.\n",
    "   \n",
    "   Parcellations are computed in Freesurfer.\n",
    "\n",
    "### Step 5: Alignment and Optimization in Brainstorm\n",
    "\n",
    "1. **Data Alignment**:  \n",
    "   To ensure consistency, outputs from CAT12 and FreeSurfer are loaded into Brainstorm, where tissue segmentation files and surfaces are aligned to MNI coordinates. This step is crucial for integrating data accurately within Cedalion’s models.\n",
    "\n",
    "2. **Mesh Optimization**:  \n",
    "   Since FreeSurfer surfaces contain ~300K vertices, we downsample the mesh in Brainstorm to a more manageable 15K vertices, which balances detail and processing efficiency in Cedalion.\n",
    "\n",
    "### Step 6: Post-Processing of Tissue Segmentation Masks\n",
    "\n",
    "1. **Post-Processing Workflow**:  \n",
    "   To finalize tissue segmentation masks, Cedalion applies additional post-processing steps to smoothen boundaries and fill small gaps. These operations ensure cleaner and more continuous tissue delineation.\n",
    "\n",
    "2. **Preservation of Key Segmentations**:\n",
    "   - **Gray and White Matter**: FreeSurfer’s gray and white matter segmentations are retained without modification due to their high accuracy. Final checks are applied to prevent overlap between masks and to ensure clarity in tissue delineation.\n",
    "\n",
    "### Final Outputs\n",
    "\n",
    "For each T1 image, the workflow yields the following:\n",
    "\n",
    "- **6 Tissue Segmentation Masks**: skull, scalp, CSF, gray matter, white matter, and air (air mask optional).\n",
    "- **Head Surface and Brain Surface** \n",
    "- **Parcellations json file**\n",
    "\n",
    "Note that the brain surface, along with gray and white matter masks, originates from FreeSurfer. All other segmentation masks and the head surface are generated from CAT12.\n",
    "\n",
    "The flowchart below provides a visual summary of this processing pipeline.\n",
    "\n",
    "![Alt Text](MRI_processing_diagram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dependencies\n",
    "\n",
    "import pyvista as pv\n",
    "# pv.set_jupyter_backend('client')\n",
    "pv.set_jupyter_backend('static')\n",
    "\n",
    "import os\n",
    "\n",
    "import cedalion\n",
    "import cedalion.io\n",
    "import cedalion.plots\n",
    "import cedalion.datasets\n",
    "import cedalion.imagereco.forward_model as fw\n",
    "import cedalion.dataclasses as cdc\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as p\n",
    "\n",
    "import nibabel as nib\n",
    "from nilearn import plotting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colin 27\n",
    "\n",
    "The Colin27 head is a high-resolution, standardized anatomical brain template based on a series of MRI scans from a single individual, known as “Colin.” The final dataset was created by averaging 27 separate scans of Colin’s brain, resulting in an exceptionally high signal-to-noise ratio and high anatomical detail.\n",
    "\n",
    "\n",
    "### Limitations of the Colin27 Head\n",
    "- Single-Subject Template: Because Colin27 is based on a single individual, it may not represent anatomical variations found in a broader population. Templates like MNI152 or the ICBM (International Consortium for Brain Mapping) average, which are based on multiple subjects, may be preferred in population studies.\n",
    "- Older MRI Technology: The Colin27 scans were acquired in the 1990s using MRI technology of that time, which, while high-quality, may not match the resolution possible with modern imaging techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Two-Surface Head Model\n",
    "\n",
    "#### Using from_surfaces method\n",
    "\n",
    "This method utilizes the brain surface extracted from Freesurfer analysis and the head surface extracted from CAT12. Note that if either of the surface files are not provided it uses the segmentation files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load segmentation data from the colin27 atlas\n",
    "SEG_DATADIR_cl27, mask_files_cl27, landmarks_file_cl27 = cedalion.datasets.get_colin27_segmentation()\n",
    "PARCEL_DIR_cl27 = cedalion.datasets.get_colin27_parcel_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEG_DATADIR_cl27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using from_segmentations method\n",
    "\n",
    "This method utilizes tissue segmentation files and creates brain and head surfaces from the provided masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_colin27 = fw.TwoSurfaceHeadModel.from_segmentation(\n",
    "    segmentation_dir=SEG_DATADIR_cl27,\n",
    "    mask_files = mask_files_cl27,\n",
    "    landmarks_ras_file=landmarks_file_cl27,\n",
    "    brain_face_count=None,\n",
    "    scalp_face_count=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_colin27.brain.vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot Colin headmodel\n",
    "plt = pv.Plotter()\n",
    "cedalion.plots.plot_surface(plt, head_colin27.brain, color=\"w\")\n",
    "cedalion.plots.plot_surface(plt, head_colin27.scalp, opacity=.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create forward model class for colin 27 atlas\n",
    "head_colin27 = fw.TwoSurfaceHeadModel.from_surfaces(\n",
    "    segmentation_dir=SEG_DATADIR_cl27,\n",
    "    mask_files = mask_files_cl27,\n",
    "    brain_surface_file= os.path.join(SEG_DATADIR_cl27, \"mask_brain.obj\"),\n",
    "    scalp_surface_file= os.path.join(SEG_DATADIR_cl27, \"mask_scalp.obj\"),\n",
    "    landmarks_ras_file=landmarks_file_cl27,\n",
    "    brain_face_count=None,\n",
    "    scalp_face_count=None,\n",
    "    parcel_file=PARCEL_DIR_cl27\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot Colin headmodel\n",
    "plt = pv.Plotter()\n",
    "cedalion.plots.plot_surface(plt, head_colin27.brain, color=\"w\")\n",
    "cedalion.plots.plot_surface(plt, head_colin27.scalp, opacity=.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize different tisue segmentation volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colin27_mask_data = (\n",
    "    head_colin27.segmentation_masks.sel(segmentation_type='wm') +\n",
    "    head_colin27.segmentation_masks.sel(segmentation_type='gm') +\n",
    "    head_colin27.segmentation_masks.sel(segmentation_type='csf') +\n",
    "    head_colin27.segmentation_masks.sel(segmentation_type='scalp') +\n",
    "    head_colin27.segmentation_masks.sel(segmentation_type='skull')\n",
    ")\n",
    "\n",
    "mask_data = colin27_mask_data.values\n",
    "\n",
    "# Create a PyVista ImageData object with correct dimensions\n",
    "grid = pv.ImageData(dimensions=mask_data.shape)\n",
    "grid.spacing = (1.0, 1.0, 1.0)  # Replace with actual voxel dimensions if available\n",
    "\n",
    "flattened_mask_data = mask_data.flatten(order='F')\n",
    "\n",
    "# Choose the specific label to visualize (e.g., Label 2 for 'gm')\n",
    "label_to_visualize = 5 \n",
    "binary_mask = np.where(flattened_mask_data == label_to_visualize, 1.0, 0.0)\n",
    "\n",
    "# Add binary mask to the grid as 'SpecificLabel'\n",
    "grid.point_data['SpecificLabel'] = binary_mask.astype(float)*100\n",
    "\n",
    "# Plotting\n",
    "plotter = pv.Plotter()\n",
    "# Adding the volume with the appropriate opacity mapping\n",
    "\n",
    "plotter.add_volume(\n",
    "    grid, \n",
    "    scalars='SpecificLabel', \n",
    "    cmap='Greys', \n",
    "    clim=[0, 255], \n",
    "    opacity=[0.0, 0.3], \n",
    "    shade=True, \n",
    "    show_scalar_bar=False)\n",
    "\n",
    "plotter.add_axes()\n",
    "plotter.show_bounds(grid=True)\n",
    "plotter.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_img = nib.Nifti1Image(colin27_mask_data, affine=head_colin27.t_ras2ijk)\n",
    "\n",
    "# Plot the Anatomy\n",
    "plotting.plot_anat(mri_img, display_mode='ortho', title='Tissue Segmentations')\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Parcellations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the whole brain surface with their projected parcellations and related colors provided bu Schaefer Atlas. There are almost 600 different colors in this plot but the neighbor regions have near color codes; therefore, it might be difficult to distinguish the borders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels = cedalion.io.read_parcellations(PARCEL_DIR_cl27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbsphinx-thumbnail"
    ]
   },
   "outputs": [],
   "source": [
    "b = cdc.VTKSurface.from_trimeshsurface(head_colin27.brain)\n",
    "b = pv.wrap(b.mesh)\n",
    "b[\"parcels\"] = parcels.Color.tolist()\n",
    "\n",
    "plt = pv.Plotter()\n",
    "\n",
    "plt.add_mesh(\n",
    "    b,\n",
    "    scalars=\"parcels\",\n",
    "    rgb=True\n",
    ")\n",
    "\n",
    "cog = head_colin27.brain.vertices.mean(\"label\").values\n",
    "\n",
    "plt.camera.position = cog + [0,0,400]\n",
    "plt.camera.focal_point = cog \n",
    "plt.camera.up = [0,1,0] \n",
    "plt.reset_camera()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the brain surface with a list of desired parcellations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better understand the borders, you can specify a list of parcellation names. In the code section below, two regions (`\"17Networks_RH_SomMotA_4\"`, `\"17Networks_RH_DorsAttnB_FEF_1\"`) have been selected as examples. You can modify these names or add more regions as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcel_labels = parcels[[\"Color\", \"Label\"]].drop_duplicates(\"Label\").set_index(\"Label\")\n",
    "selected_parcels = ['SomMotA_4_RH', 'DorsAttnB_FEF_1_RH']\n",
    "\n",
    "selected_colors = [parcel_labels.loc[i].Color for i in selected_parcels]\n",
    "\n",
    "b = cdc.VTKSurface.from_trimeshsurface(head_colin27.brain)\n",
    "b = pv.wrap(b.mesh)\n",
    "b[\"parcels\"] = [i if i in selected_colors else (0.6, 0.6, 0.6) for i in parcels.Color.tolist()]\n",
    "\n",
    "plt = pv.Plotter()\n",
    "\n",
    "plt.add_mesh(\n",
    "    b,\n",
    "    scalars=\"parcels\",\n",
    "    rgb=True\n",
    ")\n",
    "\n",
    "\n",
    "legends = tuple([list(a) for a in zip(selected_parcels, selected_colors)])\n",
    "plt.add_legend(labels= legends, face='o', size=(0.3,0.3))\n",
    "\n",
    "\n",
    "cog = head_colin27.brain.vertices.mean(\"label\").values\n",
    "\n",
    "plt.camera.position = cog + [0,0,400]\n",
    "plt.camera.focal_point = cog \n",
    "plt.camera.up = [0,1,0] \n",
    "plt.reset_camera()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICBM 152\n",
    "\n",
    "ICBM152 is a template widely used as a standard brain reference in neuroimaging. Unlike the older Colin27, which is based on a single individual's MRI scans, the ICBM152 template is created from the averaged MRI scans of 152 healthy adult brains, which makes it more representative of the general population. \n",
    "\n",
    "### Limitations\n",
    "- Still Population-Based: While ICBM152 2020 is more generalizable than single-subject templates, it still represents an average of a specific sample, which may not perfectly match individual brains, particularly those outside the demographic profile used for the template.\n",
    "\n",
    "- Not Always Suitable for Pediatric or Clinical Populations: ICBM152 2020 is based on adult brains, so studies involving pediatric, elderly, or clinical populations with specific pathologies may require alternative templates for more accurate representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load segmentation data from the icbm152 atlas\n",
    "SEG_DATADIR_ic152, mask_files_ic152, landmarks_file_ic152 = cedalion.datasets.get_icbm152_segmentation()\n",
    "PARCEL_DIR_ic152 = cedalion.datasets.get_icbm152_parcel_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create forward model class for icbm152 atlas\n",
    "head_icbm152 = fw.TwoSurfaceHeadModel.from_segmentation(\n",
    "    segmentation_dir=SEG_DATADIR_ic152,\n",
    "    mask_files = mask_files_ic152,\n",
    "    landmarks_ras_file=landmarks_file_ic152,\n",
    "    brain_face_count=None,\n",
    "    scalp_face_count=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ICBM headmodel\n",
    "plt = pv.Plotter()\n",
    "cedalion.plots.plot_surface(plt, head_icbm152.brain, color=\"w\")\n",
    "cedalion.plots.plot_surface(plt, head_icbm152.scalp, opacity=.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create forward model class for icbm152 atlas\n",
    "head_icbm152 = fw.TwoSurfaceHeadModel.from_surfaces(\n",
    "    segmentation_dir=SEG_DATADIR_ic152,\n",
    "    mask_files = mask_files_ic152,\n",
    "    brain_surface_file= os.path.join(SEG_DATADIR_ic152, \"mask_brain.obj\"),\n",
    "    scalp_surface_file= os.path.join(SEG_DATADIR_ic152, \"mask_scalp.obj\"),\n",
    "    landmarks_ras_file=landmarks_file_ic152,\n",
    "    brain_face_count=None,\n",
    "    scalp_face_count=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ICBM headmodel\n",
    "plt = pv.Plotter()\n",
    "cedalion.plots.plot_surface(plt, head_icbm152.brain, color=\"w\")\n",
    "cedalion.plots.plot_surface(plt, head_icbm152.scalp, opacity=.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icbm152_mask_data = (\n",
    "    head_icbm152.segmentation_masks.sel(segmentation_type='wm') +\n",
    "    head_icbm152.segmentation_masks.sel(segmentation_type='gm') +\n",
    "    head_icbm152.segmentation_masks.sel(segmentation_type='csf') +\n",
    "    head_icbm152.segmentation_masks.sel(segmentation_type='scalp') +\n",
    "    head_icbm152.segmentation_masks.sel(segmentation_type='skull')\n",
    ")\n",
    "\n",
    "mask_data = icbm152_mask_data.values\n",
    "\n",
    "# Create a PyVista ImageData object with correct dimensions\n",
    "grid = pv.ImageData(dimensions=mask_data.shape)\n",
    "grid.spacing = (1.0, 1.0, 1.0)  # Replace with actual voxel dimensions if available\n",
    "\n",
    "flattened_mask_data = mask_data.flatten(order='F')\n",
    "\n",
    "# Choose the specific label to visualize (e.g., Label 2 for 'gm')\n",
    "label_to_visualize = 5 \n",
    "binary_mask = np.where(flattened_mask_data == label_to_visualize, 1.0, 0.0)\n",
    "\n",
    "# Add binary mask to the grid as 'SpecificLabel'\n",
    "grid.point_data['SpecificLabel'] = binary_mask.astype(float)*100\n",
    "\n",
    "# Plotting\n",
    "plotter = pv.Plotter()\n",
    "# Adding the volume with the appropriate opacity mapping\n",
    "\n",
    "plotter.add_volume(\n",
    "    grid, \n",
    "    scalars='SpecificLabel', \n",
    "    cmap='Greys', \n",
    "    clim=[0, 255], \n",
    "    opacity=[0.0, 0.3], \n",
    "    shade=True, \n",
    "    show_scalar_bar=False)\n",
    "\n",
    "plotter.add_axes()\n",
    "plotter.show_bounds(grid=True)\n",
    "plotter.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_img = nib.Nifti1Image(icbm152_mask_data, affine=head_icbm152.t_ras2ijk)\n",
    "\n",
    "# Plot the Anatomy\n",
    "plotting.plot_anat(mri_img, display_mode='ortho', title='Tissue Segmentations')\n",
    "plotting.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels = cedalion.io.read_parcellations(PARCEL_DIR_ic152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = cdc.VTKSurface.from_trimeshsurface(head_icbm152.brain)\n",
    "b = pv.wrap(b.mesh)\n",
    "b[\"parcels\"] = parcels.Color.tolist()\n",
    "\n",
    "plt = pv.Plotter()\n",
    "\n",
    "plt.add_mesh(b, scalars=\"parcels\", rgb=True)\n",
    "\n",
    "cog = head_icbm152.brain.vertices.mean(\"label\").values\n",
    "\n",
    "plt.camera.position = cog + [0, 0, 400]\n",
    "plt.camera.focal_point = cog\n",
    "plt.camera.up = [0, 1, 0]\n",
    "plt.reset_camera()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcel_labels = parcels[[\"Color\", \"Label\"]].drop_duplicates(\"Label\").set_index(\"Label\")\n",
    "selected_parcels = [\"SomMotA_4_RH\", \"DorsAttnB_FEF_1_RH\"]\n",
    "\n",
    "selected_colors = [parcel_labels.loc[i].Color for i in selected_parcels]\n",
    "\n",
    "b = cdc.VTKSurface.from_trimeshsurface(head_icbm152.brain)\n",
    "b = pv.wrap(b.mesh)\n",
    "b[\"parcels\"] = [\n",
    "    i if i in selected_colors else (0.6, 0.6, 0.6) for i in parcels.Color.tolist()\n",
    "]\n",
    "\n",
    "plt = pv.Plotter()\n",
    "\n",
    "plt.add_mesh(b, scalars=\"parcels\", rgb=True)\n",
    "\n",
    "\n",
    "legends = tuple([list(a) for a in zip(selected_parcels, selected_colors)])\n",
    "plt.add_legend(labels=legends, face=\"o\", size=(0.3, 0.3))\n",
    "\n",
    "cog = head_icbm152.brain.vertices.mean(\"label\").values\n",
    "\n",
    "plt.camera.position = cog + [0, 0, 400]\n",
    "plt.camera.focal_point = cog\n",
    "plt.camera.up = [0, 1, 0]\n",
    "plt.reset_camera()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cedalion_default_3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
