{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Photogrammetric Optode Coregistration\n",
    "\n",
    "Photogrammetry offers a possibility to get subject-specific optode coordinates. This notebook illustrates the individual steps to obtain these coordinates from a textured triangle mesh and a predefined montage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ibs-lab/cedalion/blob/dev/examples/head_models/41_photogrammetric_optode_coregistration.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab Setup\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "if IN_COLAB:\n",
    "    !curl -s https://raw.githubusercontent.com/ibs-lab/cedalion/colab_setup/colab_setup.py -o colab_setup.py\n",
    "    # Select alternative branch (optional: default is \"dev\")\n",
    "    # %run colab_setup.py  --branch \"main\"\n",
    "    %run colab_setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "import xarray as xr\n",
    "\n",
    "import cedalion\n",
    "import cedalion.dataclasses as cdc\n",
    "import cedalion.datasets\n",
    "import cedalion.geometry.registration\n",
    "import cedalion.io\n",
    "import cedalion.plots\n",
    "from cedalion.geometry.photogrammetry.processors import (\n",
    "    ColoredStickerProcessor,\n",
    "    geo3d_from_scan,\n",
    ")\n",
    "from cedalion.geometry.registration import find_spread_points\n",
    "from cedalion.plots import OptodeSelector\n",
    "\n",
    "xr.set_options(display_expand_data=False)\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"cedalion\").setLevel(logging.DEBUG)\n",
    "logging.getLogger('trame_client').setLevel(logging.WARNING)\n",
    "logging.getLogger('trame_server').setLevel(logging.WARNING)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 0. Choose between interactive and static mode\n",
    "\n",
    "This example notebook provides two modes, controlled by the constant `INTERACTIVE`:\n",
    "- a static mode intended for rendering the documentation\n",
    "- an interactive mode, in which the 3D visualizations react\n",
    "  to user input. The camera position can be changed. More importantly,\n",
    "  the optode and landmark picking needs these interactive plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERACTIVE = False\n",
    "\n",
    "if INTERACTIVE:\n",
    "    # option 1: render in the browser\n",
    "    # pv.set_jupyter_backend(\"client\")\n",
    "    # option 2: offload rendering to a server process using trame\n",
    "    pv.set_jupyter_backend(\"server\")\n",
    "else:\n",
    "    pv.set_jupyter_backend(\"static\")  # static rendering (for documentation page)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 1. Loading the triangulated surface mesh\n",
    "\n",
    "Use `cedalion.io.read_einstar_obj` to read the textured triangle mesh produced by the Einstar scanner. By default we use an example dataset. By setting the `fname_` variables the notebook can operate on another scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert here your own files if you do not want to use the example\n",
    "fname_scan = \"\"  # path to .obj scan file\n",
    "fname_snirf = \"\" # path to .snirf file for montage information\n",
    "fname_montage_img = \"\" # path to an image file of the montage\n",
    "\n",
    "if not fname_scan:\n",
    "    fname_scan, fname_snirf, fname_montage_img = (\n",
    "        cedalion.datasets.get_photogrammetry_example_scan()\n",
    "    )\n",
    "\n",
    "surface_mesh = cedalion.io.read_einstar_obj(fname_scan)\n",
    "display(surface_mesh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 2. Identifying sticker vertices\n",
    "\n",
    "Processors are meant to analyze the textured mesh and extract positions. The `ColoredStickerProcessor` searches for colored vertices that form circular areas. We operate in HSV color space and the colors must be specified by their ranges in hue and value. These can be found by usig a color pipette tool on the texture file.\n",
    "\n",
    "Multiple classes with different colors can be specified. In the following only yellow stickers for class \"O(ptode)\" are searched. But it could be extended to search also for differently colored sticker. (e.g. \"L(andmark)\").\n",
    "\n",
    "For each sticker the center and the normal is derived. Labels are generated from the class name and a counter, e.g. \"O-01, O-02, ...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ColoredStickerProcessor(\n",
    "    colors={\n",
    "        \"O\" : ((0.11, 0.21, 0.7, 1)), # (hue_min, hue_max, value_min, value_max)\n",
    "        #\"L\" : ((0.25, 0.37, 0.35, 0.6))\n",
    "    }\n",
    ")\n",
    "\n",
    "sticker_centers, normals, details = processor.process(surface_mesh, details=True)\n",
    "display(sticker_centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Visualize the surface and extraced results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_pos = sticker_centers.mean(\"label\").pint.dequantify() - np.array([-500,0,0])\n",
    "camera_focal_point = sticker_centers.mean(\"label\").pint.dequantify()\n",
    "camera_up = (0., 0. ,1.)\n",
    "\n",
    "pvplt = pv.Plotter()\n",
    "cedalion.plots.plot_surface(pvplt, surface_mesh, opacity=1.0)\n",
    "cedalion.plots.plot_labeled_points(pvplt, sticker_centers, color=\"r\")\n",
    "cedalion.plots.plot_vector_field(pvplt, sticker_centers, normals)\n",
    "\n",
    "pvplt.camera.position = camera_pos\n",
    "pvplt.camera.focal_point = camera_focal_point\n",
    "pvplt.camera.up = camera_up\n",
    "\n",
    "pvplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "The details object is a container for debuging information. It also provides plotting functionality.\n",
    "\n",
    "The following scatter plot shows the vertex colors in the hue-value plane in which the vertex classification operates.\n",
    "\n",
    "The black rectangle illustrates the classification criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "details.plot_vertex_colors()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "The following plots show for each cluster (tentative group of sticker vertices) The vertex positions perpendicular to the sticker normal as well as the minimum enclosing circle which is used to find the sticker's center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "details.plot_cluster_circles()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 3. Manual corrections of sticker detection\n",
    "\n",
    "If not all optodes were found automatically, there's way to remove or add them manually. \n",
    "\n",
    "The `OptodeSelect` class provides an interactive visualization of the head scan and the detected stickers (red spheres): \n",
    "\n",
    "By clicking with the right mouse button on:\n",
    "- a sphere, a misidentified sticker can be removed. \n",
    "- somewhere on the surface, a new sticker position can be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "optode_selector = OptodeSelector(surface_mesh, sticker_centers, normals)\n",
    "optode_selector.plot()\n",
    "optode_selector.enable_picking()\n",
    "cedalion.plots.plot_surface(optode_selector.plotter, surface_mesh, opacity=1.0)\n",
    "\n",
    "optode_selector.plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Interactions modify the `optode_selector.points` and `optode_selector.normals`. After selecting all optodes, update `sticker_centers` and `normals`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sticker_centers = optode_selector.points\n",
    "normals = optode_selector.normals\n",
    "display(sticker_centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## 4. Project from sticker to scalp surface\n",
    "\n",
    "Finally, to get from the sticker centers to the scalp coordinates we have to subtract the known lenght of the optodes in the direction of the normals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "optode_length = 22.6 * cedalion.units.mm\n",
    "\n",
    "scalp_coords = sticker_centers.copy()\n",
    "mask_optodes = sticker_centers.group == \"O\"\n",
    "scalp_coords[mask_optodes] = (\n",
    "    sticker_centers[mask_optodes] - optode_length * normals[mask_optodes]\n",
    ")\n",
    "# we make a copy of this raw set of scalp coordinates to use later in the 2nd case of\n",
    "# the coregistration example that showcases an alternative route if landmark-based\n",
    "# coregistration fails\n",
    "scalp_coords_altcase = scalp_coords.copy()\n",
    "\n",
    "display(scalp_coords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "Visualize sticker centers (red) and scalp coordinates (green)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvplt = pv.Plotter()\n",
    "cedalion.plots.plot_surface(pvplt, surface_mesh, opacity=0.3)\n",
    "cedalion.plots.plot_labeled_points(pvplt, sticker_centers, color=\"r\")\n",
    "cedalion.plots.plot_labeled_points(pvplt, scalp_coords, color=\"g\")\n",
    "cedalion.plots.plot_vector_field(pvplt, sticker_centers, normals)\n",
    "pvplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## 5. Specify landmarks on scanned head surface\n",
    "\n",
    "### 5.1. Pick positions in interactive plot\n",
    "\n",
    "When using the `plot_surface` function with parameter `pick_landmarks` set to *True*, the plot becomes interactive and allows to pick the positions of 5 landmarks. These are \"Nz\", \"Iz\", \"Cz\", \"Lpa\", \"RpA\".\n",
    "\n",
    "After clicking on the mesh, a green sphere marks the picked location. The sphere has a label attached. If this label is not visible, try to zoom further into the plot (mouse wheel). By clicking again with right mouse button on the sphere one can cycle through the different labels or remove a misplaced landmark.\n",
    "\n",
    "It halps to add colored markers at the landmark positions when preparing the subject. Here green stickers where used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvplt = pv.Plotter()\n",
    "get_landmarks = cedalion.plots.plot_surface(\n",
    "    pvplt, surface_mesh, opacity=1.0, pick_landmarks=True\n",
    ")\n",
    "pvplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### 5.2. Retrieve picked positions from interactive plot\n",
    "The `plot_surface` function returns a function `get_landmarks`. Call this function to obtain:\n",
    "* 1st value - coordinates of picked landmarks\n",
    "* 2nd - labels of corresponding landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "if INTERACTIVE:\n",
    "    landmark_coordinates, landmark_labels = get_landmarks()\n",
    "else:\n",
    "    # For documentation purposes and to enable automatically rendered example notebooks\n",
    "    # we provide the hand-picked coordinates here, too.\n",
    "    landmark_labels = [\"Nz\", \"Iz\", \"Cz\", \"Lpa\", \"Rpa\"]\n",
    "    landmark_coordinates = np.asarray(\n",
    "        [\n",
    "            [14.00420712, -7.84856869, 449.77840004],\n",
    "            [99.09920059, 29.72154755, 620.73876117],\n",
    "            [161.63815139, -48.49738938, 494.91210993],\n",
    "            [82.8771277, 79.79500128, 498.3338802],\n",
    "            [15.17214095, -60.56186128, 563.29621021],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "display(landmark_labels)\n",
    "display(landmark_coordinates)\n",
    "\n",
    "assert len(set(landmark_labels)) == 5, \"please select 5 landmarks\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### 5.3 Wrap landmark positions and labels in a xarray.DataArray structure\n",
    "\n",
    "* insert *landmark_coordinates* and *landmark_labels*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = landmark_coordinates\n",
    "labels = landmark_labels\n",
    "\n",
    "types = [cdc.PointType.LANDMARK] * 5\n",
    "groups = [\"L\"] * 5\n",
    "\n",
    "landmarks = xr.DataArray(\n",
    "    np.vstack(coordinates),\n",
    "    dims=[\"label\", \"digitized\"],\n",
    "    coords={\n",
    "        \"label\": (\"label\", labels),\n",
    "        \"type\": (\"label\", types),\n",
    "        \"group\": (\"label\", groups),\n",
    "    },\n",
    ").pint.quantify(\"mm\")\n",
    "\n",
    "display(landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## 6. Mapping the scanned optode positions to a predefined montage.\n",
    "\n",
    "So far the optode positions found in the photogrammetric head scan carry only generic labels. In oder to identify them, they must be matched with a definition of the actual montage. \n",
    "\n",
    "Snirf files store next to the actual time series data also the probe geometry, i.e. 3D coordinates of each source and detector. To label the optodes found in the photogrammetric scan, we map each optode to its counterpart in the snirf file. \n",
    "\n",
    "The snirf coordinates are written during the data acquisition and are typically obtained by arranging the montage on a template head like ICBM-152 or colin27. So despite their similarity, the probe geometries in the snirf file and those from the head scan have differences because of different head geometries aand different coordinate systems. \n",
    "\n",
    "### 6.1 Load the montage information from .snirf file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the example snirf file. Specify a name for the coordinate reference system.\n",
    "rec = cedalion.io.read_snirf(fname_snirf, crs=\"aligned\")[0]\n",
    "\n",
    "# read 3D coordinates of the optodes\n",
    "montage_elements = rec.geo3d\n",
    "\n",
    "# landmark labels must match exactly. Adjust case where they don't match.\n",
    "montage_elements = montage_elements.points.rename({\"LPA\": \"Lpa\", \"RPA\": \"Rpa\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "### 6.2 Find a transformation to align selected landmarks to montage coordinates\n",
    "\n",
    "The coordinates in the snirf file and from the photogrammetric scan use different coordinate reference systems (CRS). In Cedalion the user needs to explicitly name different CRSs. Here the labels 'digitized' and 'aligned' were used.\n",
    "\n",
    "The following plot shows the probe geometry from the snirf file and the landmarks from the head scan. Two black lines Nz-Iz and Lpa-Rpa are added to guide the eye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(12,5))\n",
    "ax1 = f.add_subplot(1,2,1, projection=\"3d\")\n",
    "ax2 = f.add_subplot(1,2,2, projection=\"3d\")\n",
    "colors = {cdc.PointType.SOURCE: \"r\", cdc.PointType.DETECTOR: \"b\"}\n",
    "sizes = {cdc.PointType.SOURCE: 20, cdc.PointType.DETECTOR: 20}\n",
    "\n",
    "for i, (type, x) in enumerate(montage_elements.groupby(\"type\")):\n",
    "    x = x.pint.to(\"mm\").pint.dequantify()\n",
    "    ax1.scatter(x[:, 0], x[:, 1], x[:, 2], c=colors.get(type, \"g\"), s=sizes.get(type, 2))\n",
    "\n",
    "for i, (type, x) in enumerate(landmarks.groupby(\"type\")):\n",
    "    x = x.pint.to(\"mm\").pint.dequantify()\n",
    "    ax2.scatter(x[:, 0], x[:, 1], x[:, 2], c=colors.get(type, \"g\"), s=20)\n",
    "\n",
    "for ax, points in [(ax1, montage_elements), (ax2, landmarks)]:\n",
    "    points = points.pint.to(\"mm\").pint.dequantify()\n",
    "    ax.plot([points.loc[\"Nz\",0], points.loc[\"Iz\",0]],\n",
    "            [points.loc[\"Nz\",1], points.loc[\"Iz\",1]],\n",
    "            [points.loc[\"Nz\",2], points.loc[\"Iz\",2]],\n",
    "            c=\"k\"\n",
    "            )\n",
    "    ax.plot([points.loc[\"Lpa\",0], points.loc[\"Rpa\",0]],\n",
    "            [points.loc[\"Lpa\",1], points.loc[\"Rpa\",1]],\n",
    "            [points.loc[\"Lpa\",2], points.loc[\"Rpa\",2]],\n",
    "            c=\"k\"\n",
    "            )\n",
    "\n",
    "ax1.set_title(f\"from snirf | crs: {montage_elements.points.crs}\")\n",
    "ax2.set_title(f\"from scan | crs: {landmarks.points.crs}\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "Subsequently, to bring the coordinates into the same space, from the landmarks a transformation (translations and rotations) is derived. This transforms the coordinates from the snirf file to the CRS of the photogramettric scan.\n",
    "\n",
    "The following plot illustrates the transformed coordinates of sources (red) and detectors (blue). Deviations between these coordinates and the head surface are expected, since the optode positions where specified on a different head geometry.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "trafo = cedalion.geometry.registration.register_trans_rot(landmarks, montage_elements)\n",
    "\n",
    "filtered_montage_elements = montage_elements.where(\n",
    "    (montage_elements.type == cdc.PointType.SOURCE)\n",
    "    | (montage_elements.type == cdc.PointType.DETECTOR),\n",
    "    drop=True,\n",
    ")\n",
    "filtered_montage_elements_t = filtered_montage_elements.points.apply_transform(trafo)\n",
    "\n",
    "pvplt = pv.Plotter()\n",
    "cedalion.plots.plot3d(\n",
    "    None, surface_mesh.mesh, filtered_montage_elements_t, None, plotter=pvplt\n",
    ")\n",
    "pvplt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "### 6.3 Iterative closest point algorithm to find labels for detected optode centers\n",
    "\n",
    "Finally, the mapping is derived by iteratively trying to find a transformation that yilds the best match between the snirf and the scanned coordinates. \n",
    "\n",
    "The following plot visualizes the result:\n",
    "* Green points represent optode centers\n",
    "* Next to them there shall be labels assumed by ICP algorithm (*show_labels = True*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterative closest point registration\n",
    "idx = cedalion.geometry.registration.icp_with_full_transform(\n",
    "    scalp_coords, filtered_montage_elements_t, max_iterations=100\n",
    ")\n",
    "\n",
    "# extract labels for detected optodes\n",
    "label_dict = {}\n",
    "for i, label in enumerate(filtered_montage_elements.coords[\"label\"].values):\n",
    "    label_dict[i] = label\n",
    "labels = [label_dict[index] for index in idx]\n",
    "\n",
    "# write labels to scalp_coords\n",
    "scalp_coords = scalp_coords.assign_coords(label=labels)\n",
    "\n",
    "# add landmarks\n",
    "geo3Dscan = geo3d_from_scan(scalp_coords, landmarks)\n",
    "\n",
    "display(geo3Dscan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1,2, figsize=(12,6))\n",
    "cedalion.plots.scalp_plot(\n",
    "    rec[\"amp\"],\n",
    "    montage_elements,\n",
    "    cedalion.nirs.channel_distances(rec[\"amp\"], montage_elements),\n",
    "    ax=ax[0],\n",
    "    optode_labels=True,\n",
    "    cb_label=\"channel dist. / mm\",\n",
    "    cmap=\"plasma\",\n",
    "    vmin=25,\n",
    "    vmax=42,\n",
    ")\n",
    "ax[0].set_title(\"montage from snirf file\")\n",
    "cedalion.plots.scalp_plot(\n",
    "    rec[\"amp\"],\n",
    "    geo3Dscan,\n",
    "    cedalion.nirs.channel_distances(rec[\"amp\"], geo3Dscan),\n",
    "    ax=ax[1],\n",
    "    optode_labels=True,\n",
    "    cb_label=\"channel dist. / mm\",\n",
    "    cmap=\"plasma\",\n",
    "    vmin=25,\n",
    "    vmax=42,\n",
    ")\n",
    "ax[1].set_title(\"montage from photogrammetric scan\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "Visualization of successfull assignment *(show_labels = True)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvplt = pv.Plotter()\n",
    "cedalion.plots.plot3d(None, surface_mesh.mesh, None, None, plotter=pvplt)\n",
    "cedalion.plots.plot_labeled_points(pvplt, geo3Dscan, show_labels=True)\n",
    "pvplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "### 6.4 Alternative approach without landmarks\n",
    "\n",
    "Mapping the optode labels can fail for example because of a bad landmark selection. \n",
    "\n",
    "In such cases it is possible to find a new transformation by manually labeling three optodes. This is done by selecting them in a given order. For that it helps to have a visualization of the montage of your experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {
    "tags": [
     "nbsphinx-thumbnail"
    ]
   },
   "outputs": [],
   "source": [
    "if fname_montage_img:\n",
    "    # Load and display the image\n",
    "    img = mpimg.imread(fname_montage_img)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")  # Turn off axis labels and ticks\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No montage image specified.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "Search for three optodes that are evenly spreaded across the head surface. Afterwards prompt the uer to right click on each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_point_labels = find_spread_points(filtered_montage_elements)\n",
    "print(\"Select those points\")\n",
    "print(spread_point_labels)\n",
    "\n",
    "points = []\n",
    "pvplt = pv.Plotter()\n",
    "cedalion.plots.plot_surface(pvplt, surface_mesh, opacity=1.0)\n",
    "cedalion.plots.plot_labeled_points(pvplt, sticker_centers, color=\"r\", ppoints = points)\n",
    "pvplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "Retrieve picked positions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "if INTERACTIVE:\n",
    "    labeled_points = points\n",
    "else:\n",
    "    # For documentation purposes and to enable automatically rendered example notebooks\n",
    "    # we provide the hand-picked coordinates here, too.\n",
    "    labeled_points = [19, 52, 50]\n",
    "\n",
    "labeled_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "Write the selected labels to the corresponding points of *xarray.DataArray scalp_coords*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels = scalp_coords_altcase.label.values.copy()\n",
    "for i, idx in enumerate(labeled_points):\n",
    "    new_labels[idx] = spread_point_labels[i]\n",
    "scalp_coords_altcase = scalp_coords_altcase.assign_coords(label=new_labels)\n",
    "scalp_coords_altcase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "Find the affine transformation for the newly labeled points and apply it to the montage optodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "trafo2 = cedalion.geometry.registration.register_trans_rot(\n",
    "    scalp_coords_altcase, montage_elements\n",
    ")\n",
    "\n",
    "filtered_montage_elements = montage_elements.where(\n",
    "    (montage_elements.type == cdc.PointType.SOURCE)\n",
    "    | (montage_elements.type == cdc.PointType.DETECTOR),\n",
    "    drop=True,\n",
    ")\n",
    "filtered_montage_elements_t = filtered_montage_elements.points.apply_transform(trafo2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "and run ICP algorithm for label assignment once again, extract labels for detected optodes and plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterative closest point registration\n",
    "idx = cedalion.geometry.registration.icp_with_full_transform(\n",
    "    scalp_coords_altcase, filtered_montage_elements_t, max_iterations=100\n",
    ")\n",
    "# extract labels for detected optodes\n",
    "label_dict = {}\n",
    "for i, label in enumerate(filtered_montage_elements.coords[\"label\"].values):\n",
    "    label_dict[i] = label\n",
    "labels = [label_dict[index] for index in idx]\n",
    "\n",
    "# write labels to scalp_coords\n",
    "scalp_coords_altcase = scalp_coords_altcase.assign_coords(label=labels)\n",
    "\n",
    "# add landmarks\n",
    "geo3Dscan_alt = geo3d_from_scan(scalp_coords_altcase, landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1,2, figsize=(12,6))\n",
    "cedalion.plots.scalp_plot(\n",
    "    rec[\"amp\"],\n",
    "    montage_elements,\n",
    "    cedalion.nirs.channel_distances(rec[\"amp\"], montage_elements),\n",
    "    ax=ax[0],\n",
    "    optode_labels=True,\n",
    "    cb_label=\"channel dist. / mm\",\n",
    "    cmap=\"plasma\",\n",
    "    vmin=25,\n",
    "    vmax=42,\n",
    ")\n",
    "ax[0].set_title(\"montage from snirf file\")\n",
    "cedalion.plots.scalp_plot(\n",
    "    rec[\"amp\"],\n",
    "    geo3Dscan_alt,\n",
    "    cedalion.nirs.channel_distances(rec[\"amp\"], geo3Dscan_alt),\n",
    "    ax=ax[1],\n",
    "    optode_labels=True,\n",
    "    cb_label=\"channel dist. / mm\",\n",
    "    cmap=\"plasma\",\n",
    "    vmin=25,\n",
    "    vmax=42,\n",
    ")\n",
    "ax[1].set_title(\"montage from photogrammetric scan\")\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cedalion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
