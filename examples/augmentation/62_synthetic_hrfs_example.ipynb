{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cedalion\n",
    "import cedalion.nirs\n",
    "import cedalion.imagereco.forward_model as fw\n",
    "import cedalion.datasets\n",
    "import os\n",
    "import cedalion.xrutils as xrutils\n",
    "import cedalion.plots\n",
    "import xarray as xr\n",
    "import cedalion.geometry.landmarks as cd_landmarks\n",
    "import matplotlib.pyplot as plt\n",
    "import cedalion.sim.synthetic_hrf as synHRF_ced\n",
    "from cedalion import units\n",
    "import cedalion.dataclasses as cdc\n",
    "import pyvista as pv\n",
    "import cedalion.models.glm as glm\n",
    "from cedalion.imagereco.solver import pseudo_inverse_stacked\n",
    "#pv.set_jupyter_backend('server') # this enables interactive plots\n",
    "import cedalion.sigproc.quality as quality\n",
    "\n",
    "xr.set_options(display_expand_data=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preprocessing the dataset\n",
    "\n",
    "This notebook uses a HD whole head resting state dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = cedalion.datasets.get_nn22_resting_state()\n",
    "\n",
    "geo3d = rec.geo3d\n",
    "meas_list = rec._measurement_lists[\"amp\"]\n",
    "amp = rec[\"amp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cedalion.plots.plot_montage3D(rec[\"amp\"], geo3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp = amp.pint.dequantify().pint.quantify(\"V\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_thresh = 10  # the SNR (std/mean) of a channel.\n",
    "# SNR thresholding using the \"snr\" function of the quality subpackage\n",
    "snr, snr_mask = quality.snr(rec[\"amp\"], snr_thresh)\n",
    "data_masked_snr_2, masked_elements_2 = xrutils.apply_mask(\n",
    "    rec[\"amp\"], snr_mask, \"drop\", \"channel\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "od = cedalion.nirs.int2od(data_masked_snr_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct headmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the the Colin27 headmodel, since we need the geometry for image reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEG_DATADIR, mask_files, landmarks_file = cedalion.datasets.get_colin27_segmentation()\n",
    "SEG_DATADIR += '/colin27_segmentation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = fw.TwoSurfaceHeadModel.from_surfaces(\n",
    "    segmentation_dir=SEG_DATADIR,\n",
    "    mask_files = mask_files,\n",
    "    brain_surface_file= os.path.join(SEG_DATADIR, \"mask_brain.obj\"),\n",
    "    scalp_surface_file= os.path.join(SEG_DATADIR, \"mask_scalp.obj\"),\n",
    "    landmarks_ras_file=landmarks_file,\n",
    "    brain_face_count=None,\n",
    "    scalp_face_count=None,\n",
    "    fill_holes=True,        # needs to be true, otherwise landmark calculation fails\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "head.brain.units = cedalion.units.mm\n",
    "head.scalp.units = cedalion.units.mm\n",
    "head.landmarks = head.landmarks.pint.dequantify()\n",
    "head.landmarks.pint.units = cedalion.units.mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head.brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head.landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "head.landmarks contains the 4 landmarks ['Nz' 'Iz' 'LPA' 'RPA']. \n",
    "Since we want to create synthetic HRFs on the brain surface at landmark positions, we need to build the remaining 10-10 landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmbuilder = cd_landmarks.LandmarksBuilder1010(head.scalp, head.landmarks)\n",
    "all_landmarks = lmbuilder.build()\n",
    "head.landmarks = all_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geo3d_snapped = head.align_and_snap_to_scalp(geo3d)\n",
    "center_brain = np.mean(head.brain.mesh.vertices, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to build the synthetic HRFs at C3 and C4 (green dots in the image below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_pv = pv.Plotter()\n",
    "cedalion.plots.plot_surface(plt_pv, head.brain, color=\"#d3a6a1\")\n",
    "cedalion.plots.plot_surface(plt_pv, head.scalp, opacity=0.1)\n",
    "cedalion.plots.plot_labeled_points(\n",
    "    plt_pv, head.landmarks.sel(label=[\"C3\", \"C4\"]), show_labels=True\n",
    ")\n",
    "#cedalion.plots.plot_labeled_points(\n",
    "#    plt_pv,\n",
    "#    geo3d_snapped[geo3d_snapped.type != cdc.PointType.LANDMARK],\n",
    "#    show_labels=True,\n",
    "#)\n",
    "plt_pv.camera.position = (\n",
    "    head.landmarks.sel(label=\"C3\").values - center_brain\n",
    ") * 7 + center_brain\n",
    "plt_pv.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build spatial activation pattern on brain surface for landmarks C3 and C4\n",
    "\n",
    "Using the the nearest brain vertex to a given landmark, we build a spatial activation pattern on the brain surface. The pattern is a Gaussian of the geodesic distance. The size is determined by the standard deviation of this Gaussian, given by the parameter 'spatial_scale'. The peak intensity is determined by the parameter 'intensity_scale'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3_seed = head.brain.mesh.kdtree.query(head.landmarks.sel(label='C3'))[1]\n",
    "c4_seed = head.brain.mesh.kdtree.query(head.landmarks.sel(label='C4'))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_img_c3 = synHRF_ced.build_spatial_activation(\n",
    "    head,\n",
    "    c3_seed,\n",
    "    spatial_scale=2 * cedalion.units.cm,\n",
    "    intensity_scale=1 * units.micromolar,\n",
    "    hbr_scale=-0.4,\n",
    ")\n",
    "spatial_img_c4 = synHRF_ced.build_spatial_activation(\n",
    "    head,\n",
    "    c4_seed,\n",
    "    spatial_scale=2 * cedalion.units.cm,\n",
    "    intensity_scale=1 * units.micromolar,\n",
    "    hbr_scale=-0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting xarray.DataArray contains an activation value for each vertex and chromophore on the brain surface. We will use this spatial information to create synthetic HRFs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We concatenate the two patterns for C3 and C4 along dimension 'trial_type' to get a single xarray.DataArray with the spatial information for both landmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the two sptaial patterns on axis 2\n",
    "spatial_imgs = xr.concat(\n",
    "    [spatial_img_c3, spatial_img_c4], dim=\"trial_type\"\n",
    ").assign_coords(trial_type=[\"Stim C3\", \"Stim C4\"])\n",
    "spatial_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot spatial patterns @ C3 & C4\n",
    "\n",
    "There exists a helper function to plot the patterns on the brain surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot:\n",
    "    synHRF_ced.plot_spatial_activation(\n",
    "        spatial_img_c3.sel(chromo=\"HbO\"), head.brain, title=\"C3 Activation\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot:\n",
    "    synHRF_ced.plot_spatial_activation(\n",
    "        spatial_img_c4.sel(chromo=\"HbO\"), head.brain, title=\"C4 Activation\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Reconstruction\n",
    "\n",
    "We load the precomputed Adot matrix to be able to map from image to channel space. (See image_reconstruction example notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adot = cedalion.datasets.get_ninjanirs_colin27_precomputed_sensitivity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only map from brain vertices, not scalp\n",
    "Adot_brain = Adot[:, (Adot.is_brain).values,:]\n",
    "# we drop the pruned channels\n",
    "Adot_brain = Adot_brain.sel(channel=od.channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adot_stacked = (\n",
    "    cedalion.imagereco.forward_model.ForwardModel.compute_stacked_sensitivity(\n",
    "        Adot_brain\n",
    "    )\n",
    ")\n",
    "nchans = Adot_stacked.shape[0] // 2\n",
    "Adot_stacked = Adot_stacked.assign_coords(\n",
    "    {\"wavelength\": (\"flat_channel\", [760.0] * nchans + [850.0] * nchans)}\n",
    ")\n",
    "Adot_stacked = Adot_stacked.set_xindex(\"wavelength\")\n",
    "Adot_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = pseudo_inverse_stacked(Adot_stacked)\n",
    "nvertices = B.shape[0]//2\n",
    "B = B.assign_coords({\"chromo\" : (\"flat_vertex\", [\"HbO\"]*nvertices  + [\"HbR\"]* nvertices)})\n",
    "B = B.set_xindex(\"chromo\")\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_imgs_stacked = spatial_imgs.stack({\"flat_vertex\" : [\"chromo\", \"vertex\"]})\n",
    "display(spatial_imgs_stacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can now map our spatial patterns to channel space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_chan_stacked = Adot_stacked @ spatial_imgs_stacked\n",
    "spatial_chan_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undo stacking of channels in flat_channel dimension\n",
    "spatial_chan_wl1 = (\n",
    "    spatial_chan_stacked[(spatial_chan_stacked.wavelength == 760.0).values, :]\n",
    "    .rename({\"flat_channel\": \"channel\"})\n",
    "    .drop_vars(\"wavelength\")\n",
    ")\n",
    "spatial_chan_wl2 = (\n",
    "    spatial_chan_stacked[(spatial_chan_stacked.wavelength == 850.0).values, :]\n",
    "    .rename({\"flat_channel\": \"channel\"})\n",
    "    .drop_vars(\"wavelength\")\n",
    ")\n",
    "spatial_chan = xr.concat([spatial_chan_wl1, spatial_chan_wl2], dim=\"wavelength\")\n",
    "spatial_chan.coords[\"wavelength\"] = [760.0, 850.0]\n",
    "spatial_chan = spatial_chan.assign_coords(channel=od.channel)\n",
    "spatial_chan = spatial_chan.pint.dequantify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the spatial activation in channel space with a scalp plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "# adjust plot size\n",
    "fig.set_size_inches(16, 6)\n",
    "cedalion.plots.scalp_plot(\n",
    "    od,\n",
    "    rec.geo3d,\n",
    "    spatial_chan.sel(trial_type=\"Stim C3\", wavelength=850).values,\n",
    "    ax[0],\n",
    "    cmap=\"jet\",\n",
    "    title=\"C3 synHRFs\",\n",
    "    vmin=spatial_chan.values.min(),\n",
    "    vmax=spatial_chan.values.max(),\n",
    "    cb_label=\"max peak amplitude\",\n",
    ")\n",
    "cedalion.plots.scalp_plot(\n",
    "    od,\n",
    "    rec.geo3d,\n",
    "    spatial_chan.sel(trial_type=\"Stim C4\", wavelength=850).values,\n",
    "    ax[1],\n",
    "    cmap=\"jet\",\n",
    "    title=\"C4 synHRFs\",\n",
    "    vmin=spatial_chan.values.min(),\n",
    "    vmax=spatial_chan.values.max(),\n",
    "    cb_label=\"Max peak amplitude\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 5 channels for each trial type where synthetic activation is highest\n",
    "top5_chans_idx_c3 = np.argpartition(\n",
    "    spatial_chan.sel(trial_type=\"Stim C3\").values.max(axis=0), -5\n",
    ")[-5:]\n",
    "top5_chans_idx_c4 = np.argpartition(\n",
    "    spatial_chan.sel(trial_type=\"Stim C4\").values.max(axis=0), -5\n",
    ")[-5:]\n",
    "roi_chans_c3 = od.channel[top5_chans_idx_c3]\n",
    "roi_chans_c4 = od.channel[top5_chans_idx_c4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: Our spatial_chan is in od. We need to map it to channel space again so we can\n",
    "# rescale the amplitude.\n",
    "# We want a max amplitude of 1 micromolar in our synthetic activation, but it got\n",
    "# scaled by the forward model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpf = xr.DataArray(\n",
    "    [6, 6],\n",
    "    dims=\"wavelength\",\n",
    "    coords={\"wavelength\": rec[\"amp\"].wavelength},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add time axis with one time point so we can convert to conc\n",
    "spatial_chan_w_time = spatial_chan.expand_dims(\"time\")\n",
    "spatial_chan_w_time = spatial_chan_w_time.assign_coords(time=[0])\n",
    "spatial_chan_w_time.time.attrs[\"units\"] = \"second\"\n",
    "spatial_chan_conc = cedalion.nirs.od2conc(\n",
    "    spatial_chan_w_time, geo3d, dpf, spectrum=\"prahl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale so that synthetic hrfs add 1 micromolar at peak.\n",
    "rescale_factor = (1* units.micromolar / spatial_chan_conc.max())\n",
    "spatial_chan *= rescale_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HRFs in channel Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build our temporal HRF model with the same functionality that generates hrf regressors for the GLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we select a basis function, which defines the temporal shape of the HRF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_fct = glm.Gamma(tau=0 * units.s, sigma=3 * units.s, T=3 * units.s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od.time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Stim DataFrame, which contains the onset, duration and amplitude of the synthetic HRFs, is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_df = synHRF_ced.build_stim_df(\n",
    "    max_time=od.time.values[-1] * units.seconds,\n",
    "    trial_types=[\"Stim C3\", \"Stim C4\"],\n",
    "    min_interval=10 * units.seconds,\n",
    "    max_interval=20 * units.seconds,\n",
    "    min_stim_dur = 10 * units.seconds,\n",
    "    max_stim_dur = 10 * units.seconds,\n",
    "    min_stim_value = 1.0,\n",
    "    max_stim_value = 1.0,\n",
    "    order=\"random\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can now use our stim dataframe, basis function, and spatial information to create the synthetic HRF timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_ts = synHRF_ced.build_synthetic_hrf_timeseries(od, stim_df, basis_fct, spatial_chan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We get a synthetic HRF timeseries for each channel, trial_type and chromo / wavelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum the synthetic timeseries over trial_type dimension, so it has the same shape as the resting state data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_ts_sum = syn_ts.sum(dim='trial_type')\n",
    "syn_ts_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add HRFs to the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_w_hrf = od + syn_ts_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recover the HRFs from (Resting Data + syn HRFs)\n",
    "\n",
    "We filter the data and calculate block averages over epochs to recover the HRFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_w_hrf_filtered = od_w_hrf.cd.freq_filter(fmin=0.02, fmax=0.5, butter_order=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = od_w_hrf_filtered.cd.to_epochs(\n",
    "    stim_df,  # stimulus dataframe\n",
    "    [\"Stim C3\", \"Stim C4\"],  # select events\n",
    "    before=5 * units.seconds,  # seconds before stimulus\n",
    "    after=20 * units.seconds,  # seconds after stimulus\n",
    ")\n",
    "\n",
    "# calculate baseline\n",
    "baseline = epochs.sel(reltime=(epochs.reltime < 0)).mean(\"reltime\")\n",
    "# subtract baseline\n",
    "epochs_blcorrected = epochs - baseline\n",
    "\n",
    "# group trials by trial_type. For each group individually average the epoch dimension\n",
    "blockaverage = epochs_blcorrected.groupby(\"trial_type\").mean(\"epoch\")\n",
    "\n",
    "n_roi = roi_chans_c3.size\n",
    "# show results\n",
    "f, ax = plt.subplots(2, n_roi, figsize=(16, 8))\n",
    "ax = ax.flatten()\n",
    "for i_ch, ch in enumerate(roi_chans_c3):\n",
    "    for ls, trial_type in zip([\"-\", \"--\"], blockaverage.trial_type):\n",
    "        ax[i_ch].plot(\n",
    "            blockaverage.reltime,\n",
    "            blockaverage.sel(wavelength=760, trial_type=trial_type, channel=ch),\n",
    "            \"r\",\n",
    "            lw=2,\n",
    "            ls=ls,\n",
    "        )\n",
    "        ax[i_ch].plot(\n",
    "            blockaverage.reltime,\n",
    "            blockaverage.sel(wavelength=850, trial_type=trial_type, channel=ch),\n",
    "            \"b\",\n",
    "            lw=2,\n",
    "            ls=ls,\n",
    "        )\n",
    "    ax[i_ch].grid(1)\n",
    "    ax[i_ch].set_title(ch.values)\n",
    "    ax[i_ch].set_ylim(-0.05, 0.05)\n",
    "\n",
    "for i_ch, ch in enumerate(roi_chans_c4):\n",
    "    for ls, trial_type in zip([\"-\", \"--\"], blockaverage.trial_type):\n",
    "        ax[i_ch + n_roi].plot(\n",
    "            blockaverage.reltime,\n",
    "            blockaverage.sel(wavelength=760, trial_type=trial_type, channel=ch),\n",
    "            \"r\",\n",
    "            lw=2,\n",
    "            ls=ls,\n",
    "        )\n",
    "        ax[i_ch + n_roi].plot(\n",
    "            blockaverage.reltime,\n",
    "            blockaverage.sel(wavelength=850, trial_type=trial_type, channel=ch),\n",
    "            \"b\",\n",
    "            lw=2,\n",
    "            ls=ls,\n",
    "        )\n",
    "    ax[i_ch + n_roi].grid(1)\n",
    "    ax[i_ch + n_roi].set_title(ch.values)\n",
    "    ax[i_ch + n_roi].set_ylim(-0.05, 0.05)\n",
    "\n",
    "plt.suptitle(\n",
    "    \"Blockaverage for channels most sensitive to C3 (top) and C4 (bottom): 760nm: r | 850nm: b | C3: - | C4: --\"\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map block average back to brain surface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We map our extracted block averages back to the brain surface to visualize the recovered HRFs activation for Stim C3.\n",
    "We can compare it to the synthetic HRF image we created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "blockaverage_img = B @ blockaverage.stack({\"flat_channel\" : [\"wavelength\", \"channel\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot HbO time trace of left and right brain hemisphere during FTapping/Right\n",
    "\n",
    "for view in [\"left_hemi\", \"right_hemi\"]:\n",
    "    trial_type = \"Stim C3\"\n",
    "    gif_fname = \"Ftapping-right\" + \"_HbO_\" + view + \".gif\"\n",
    "\n",
    "    hbo = (\n",
    "        blockaverage_img.sel(chromo=\"HbO\", trial_type=trial_type).pint.dequantify()\n",
    "        / 1e-5\n",
    "    )  # FIXME unit handling\n",
    "    hbo_brain = hbo\n",
    "\n",
    "    ntimes = hbo.sizes[\"reltime\"]\n",
    "\n",
    "    b = cdc.VTKSurface.from_trimeshsurface(head.brain)\n",
    "    b = pv.wrap(b.mesh)\n",
    "    b[\"reco_hbo\"] = hbo_brain[:, 0] - hbo_brain[:, 0]\n",
    "\n",
    "    p = pv.Plotter()\n",
    "\n",
    "    p.add_mesh(\n",
    "        b,\n",
    "        scalars=\"reco_hbo\",\n",
    "        cmap=\"seismic\",  # 'gist_earth_r',\n",
    "        clim=(-2.5, 2.5),\n",
    "        scalar_bar_args={\"title\": \"HbO / µM\"},\n",
    "        smooth_shading=True,\n",
    "    )\n",
    "\n",
    "    tl = lambda tt: f\"{trial_type} HbO rel. time: {tt:.3f} s\"\n",
    "    time_label = p.add_text(tl(0))\n",
    "\n",
    "    cog = head.brain.vertices.mean(\"label\").values\n",
    "    if view == \"left_hemi\":\n",
    "        p.camera.position = cog + [-400, 0, 0]\n",
    "    else:\n",
    "        p.camera.position = cog + [400, 0, 0]\n",
    "    p.camera.focal_point = cog\n",
    "    p.camera.up = [0, 0, 1]\n",
    "    p.reset_camera()\n",
    "\n",
    "    p.open_gif(gif_fname)\n",
    "\n",
    "    for i in range(0, ntimes, 3):\n",
    "        b[\"reco_hbo\"] = hbo_brain[:, i] - hbo_brain[:, 0]\n",
    "        time_label.set_text(\"upper_left\", tl(hbo_brain.reltime[i]))\n",
    "\n",
    "        p.write_frame()\n",
    "\n",
    "    p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "display(Image(data=open(\"Ftapping-right_HbO_left_hemi.gif\",'rb').read(), format='png'))\n",
    "display(Image(data=open(\"Ftapping-right_HbO_right_hemi.gif\",'rb').read(), format='png'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cedalion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
