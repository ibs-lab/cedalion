{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Calculating the Scalp Coupling Index\n",
    "\n",
    "This notebook calculates the Scalp Coupling Index[1] metric for assessing the signal quality of a recording.\n",
    "\n",
    "\n",
    "[1] L. Pollonini, C. Olds, H. Abaya, H. Bortfeld, M. S. Beauchamp, and J. S. Oghalai, “Auditory cortex activation to natural speech and simulated cochlear implant speech measured with functional near-infrared spectroscopy,” Hearing Research, vol. 309, pp. 84–93, Mar. 2014, doi: 10.1016/j.heares.2013.11.007.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cedalion\n",
    "import cedalion.nirs\n",
    "import cedalion.xrutils as xrutils\n",
    "from cedalion.datasets import get_fingertapping\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pint\n",
    "import matplotlib.pyplot as p\n",
    "import scipy.signal\n",
    "import os.path\n",
    "\n",
    "xr.set_options(display_expand_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading raw CW-NIRS data from a SNIRF file\n",
    "\n",
    "This notebook uses a finger-tapping dataset in BIDS layout provided by [Rob Luke](https://github.com/rob-luke/BIDS-NIRS-Tapping). It can can be downloaded via `cedalion.datasets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = get_fingertapping()\n",
    "amp = elements[0].data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the SCI\n",
    "\n",
    "From the paper:\n",
    "\n",
    "> Since the LED sources at 760 nm and 850 nm were co-located, an optical channel in good contact with the scalp exhibited a prominent synchronous cardiac pulsation in both photodetected signals. This observation was independent of the\n",
    "> amplitude of the output voltage of the photodetector, which in turn depends on the inter-distance between sources and detector. For each channel, we filtered both photodetected signals between 0.5 and 2.5 Hz to preserve only the cardiac\n",
    "> component and normalized the resulting signals to balance any difference between their amplitude. Then, we computed the cross-correlation and we extracted the value at a time lag of 0 to quantify the similarity between the filtered \n",
    "> signals. In-phase and counter-phase identical waveforms yielded a zero-lag cross-correlation value of 1 and +1 respectively, whereas a null value derived from totally uncorrelated signals. Therefore, the zero-lag cross-correlation\n",
    "> between photodetected signals of the same channel was used as a quantitative measure of the signal-to-noise ratio of the channel. We termed this value the scalp coupling index (SCI).\n",
    "\n",
    "\n",
    "### 0. Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_channel(array, channel, ylabel, xlabel=\"time\", tmin=1000, tmax=1030):\n",
    "    f, ax = p.subplots(1,1, figsize=(12,4))\n",
    "    ax.plot(array.time, array.sel(channel=channel, wavelength=760), \"r-\")\n",
    "    ax.plot(array.time, array.sel(channel=channel, wavelength=850), \"b-\")\n",
    "    p.xlim(tmin, tmax)\n",
    "    p.xlabel(xlabel)\n",
    "    p.ylabel(ylabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bandpass filter to extract the cardiac signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp_filtered = amp.cd.freq_filter(0.5, 2.5, butter_order=4)\n",
    "\n",
    "plot_channel(amp_filtered, \"S5D7\", \"amplitude / V\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Normalize filtered amplitudes\n",
    "\n",
    "Subtract the mean and normalize to each channels standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp_filtered_normed = (amp_filtered - amp_filtered.mean(\"time\")) / amp_filtered.std(\"time\")\n",
    "#amp_filtered_normed = (amp_filtered - amp_filtered.min(\"time\")) / (amp_filtered.max(\"time\") - amp_filtered.min(\"time\"))\n",
    "\n",
    "plot_channel(amp_filtered_normed, \"S5D7\", \"normalized amplitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Moving windows\n",
    "\n",
    "Calculate non-overlapping, moving windows of 5 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_len_s = 5 # seconds\n",
    "window_len_samples = int(np.ceil(window_len_s * amp_filtered_normed.cd.sampling_rate))\n",
    "print(f\"At a sampling rate of {amp_filtered_normed.cd.sampling_rate:.2f} Hz a {window_len_s} second window is {window_len_samples} samples long.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a new DataArray with a new dimension \"window\", that is window_len_samples large.\n",
    "# The time dimension will contain the time coordinate of the first sample in the window.\n",
    "# Setting the stride size to the same value as the window length will result in non-overlapping windows.\n",
    "windows = amp_filtered_normed.rolling(time=window_len_samples).construct(\"window\", stride=window_len_samples)\n",
    "\n",
    "display(windows)\n",
    "\n",
    "f,ax = p.subplots(1,1, figsize=(12,2))\n",
    "p.plot(amp_filtered_normed.time, np.ones(len(amp_filtered_normed.time)), \"r|\", label=\"amp_filtered_normed.time\")\n",
    "p.plot(windows.time, np.ones(len(windows.time)), \"ks\", label=\"windows.time\")\n",
    "p.xlim(0,40)\n",
    "p.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Calculate the correlation coefficient for each window\n",
    "\n",
    "The cross-correlation of two time series $X$ and $Y$ at time lag $\\tau$ is:\n",
    "\n",
    "$$ \\rho_{XY}(\\tau) = \\frac{E \\left[(X_t - \\mu_X)\\cdot (Y_{t+\\tau} - \\mu_Y) \\right] }{\\sigma_X \\sigma_Y} $$\n",
    "\n",
    "At time lag $\\tau=0$ this reduces to:\n",
    "\n",
    "$$ \\rho_{XY}(\\tau=0) = \\frac{E \\left[(X_t - \\mu_X)\\cdot (Y_{t} - \\mu_Y) \\right] }{\\sigma_X \\sigma_Y} = \\frac{\\frac{1}{N}\\left(\\sum_{t=t_1}^{t_2}(X_t - \\mu_X)\\cdot (Y_{t} - \\mu_Y) \\right) }{\\sigma_X \\sigma_Y}.$$\n",
    "\n",
    "This is here computed over the time window $[t_1, t_2] $ of length $N$. The standard deviations $\\sigma_X$ and $\\sigma_X$ are calculated over the same time windows. The time series $X$ and $Y$ denote the two different wavelengths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci = (windows - windows.mean(\"window\")).prod(\"wavelength\").sum(\"window\") / window_len_samples\n",
    "sci /= windows.std(\"window\").prod(\"wavelength\")\n",
    "display(sci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Illustrate heat maps of SCIs for the whole recording and all channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "colors = [\"black\", \"#DC3220\", \"#5D3A9B\", \"#0C7BDC\"]\n",
    "nodes = [0.0, 0.75, 0.751, 1.0]\n",
    "sci_cmap = LinearSegmentedColormap.from_list(\"sci_cmap\", list(zip(nodes,colors)))\n",
    "sci_binary_cmap = LinearSegmentedColormap.from_list(\"sci_binary_cmap\", list(zip([0,0.5,0.5,1],[\"#DC3220\",\"#DC3220\",\"#0C7BDC\",\"#0C7BDC\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = p.subplots(1,1,figsize=(17,8))\n",
    "\n",
    "m = ax.pcolormesh(sci.time, np.arange(len(sci.channel)), sci, shading=\"nearest\", cmap=sci_cmap)\n",
    "cb = p.colorbar(m, ax=ax)\n",
    "cb.set_label(\"SCI\")\n",
    "ax.set_xlabel(\"time / s\")\n",
    "p.tight_layout()\n",
    "ax.yaxis.set_ticks(np.arange(len(sci.channel)))\n",
    "ax.yaxis.set_ticklabels(sci.channel.values);\n",
    "\n",
    "f,ax = p.subplots(1,1,figsize=(17,8))\n",
    "\n",
    "m = ax.pcolormesh(sci.time, np.arange(len(sci.channel)), sci>0.75, shading=\"nearest\", cmap=sci_binary_cmap)\n",
    "cb = p.colorbar(m, ax=ax)\n",
    "p.tight_layout()\n",
    "ax.yaxis.set_ticks(np.arange(len(sci.channel)))\n",
    "ax.yaxis.set_ticklabels(sci.channel.values);\n",
    "cb.set_label(\"SCI > 0.75\")\n",
    "ax.set_xlabel(\"time / s\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Inspect time courses of good and bad channels\n",
    "\n",
    "S1D1: SCI <  0.75 of the times\n",
    "\n",
    "S3D3: SCI < 0.75 around t=2000s\n",
    "\n",
    "S3D11: SCI < 0.75 around t=2000s\n",
    "\n",
    "S6D5: SCI > 0.75 for all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in [\"S1D1\", \"S3D3\", \"S3D11\", \"S6D5\"]:\n",
    "    tmin, tmax  = 2000, 2100\n",
    "    f,ax = p.subplots(2,1, figsize=(18,4), sharex=True)\n",
    "\n",
    "    m = (tmin <= amp.time) & (amp.time <= tmax)\n",
    "    ax[0].plot(amp.time[m], amp.sel(channel=channel, wavelength=760, time=m), \"r-\", alpha=.5)\n",
    "    ax[0].set_ylabel(\"amp. 760nm / V\", color=\"r\")\n",
    "    ax2 =ax[0].twinx()\n",
    "    ax2.plot(amp.time[m], amp.sel(channel=channel, wavelength=850, time = m), \"b-\", alpha=.5)\n",
    "    ax2.set_ylabel(\"amp. 850nm / V\", color=\"b\")\n",
    "\n",
    "    m = (tmin <= sci.time) & (sci.time <= tmax)\n",
    "    ax[1].scatter(sci.time[m], sci.sel(channel=channel, time=m), c=sci_cmap(sci.sel(channel=channel, time=m)))\n",
    "    ax[1].set_ylabel(\"SCI\")\n",
    "    ax[1].set_xlabel(\"time / s\")\n",
    "    ax[1].axhline(0.75, c=\"k\", ls=\"--\")\n",
    "    ax[1].set_ylim(0,1)\n",
    "\n",
    "    ax[0].grid(1)\n",
    "    ax[1].grid(axis=\"x\")\n",
    "\n",
    "    f.suptitle(channel)\n",
    "    f.set_tight_layout(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Calculate a quality mask for each sample of the recording "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sci.time coordinates contain the time of the first sample of each window.\n",
    "# Use these as bin edges and calculate for each sample to which window it belongs.\n",
    "# Subtract one from the indices returned by np.digitize as 0 denotes the underflow bin.\n",
    "window_indices = np.digitize(amp.time, sci.time) - 1\n",
    "\n",
    "# To obtain a quality mask for each sample we can threshold the sci array and then\n",
    "# inflate it along the time dimension from n_windows values to n_samples: \n",
    "qmask = (sci > 0.75)[:, window_indices]\n",
    "qmask[\"time\"] = amp.time # carry over time coordinates from original array\n",
    "\n",
    "print(f'raw amplitude array has {len(amp.time)} values in the time dimension.')\n",
    "print(f'SCI has {len(sci.time)} values in the time dimension.')\n",
    "print(f'qmask has {len(qmask.time)} values in the time dimension.')\n",
    "\n",
    "f,ax = p.subplots(1,1,figsize=(17,8))\n",
    "m = ax.pcolormesh(\n",
    "    qmask.time, \n",
    "    np.arange(len(qmask.channel)), \n",
    "    qmask, \n",
    "    shading=\"nearest\", \n",
    "    cmap=sci_binary_cmap,\n",
    "    edgecolors=\"w\",\n",
    "    linewidths=0.5)\n",
    "cb = p.colorbar(m, ax=ax)\n",
    "cb.set_label(\"SCI > 0.75\")\n",
    "ax.set_xlabel(\"time / s\")\n",
    "p.tight_layout()\n",
    "ax.yaxis.set_ticks(np.arange(len(qmask.channel)))\n",
    "ax.yaxis.set_ticklabels(qmask.channel.values);\n",
    "ax.set_xlim(500,520)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
