{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization Examples using Cedalion Plot Functions\n",
    "This notebook will be continuously extended. We un-necessarily re-import cedalion dependencies to clarify which of these are needed for the plots in each corresponding cell. PLEASE NOTE: we are in the process of re-organizing the locations for our plotting functions. This notebook will be kept up to date with the latest release to enable an easy look up. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages\n",
    "### 3rd party plotting packages\n",
    "Most of Cedalion's plotting functionality is based on Matplotlib and Pyvista packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "#pv.set_jupyter_backend('server') # this enables interactive plots\n",
    "pv.set_jupyter_backend('static') # this enables static rendering\n",
    "#pv.OFF_SCREEN=True\n",
    "\n",
    "import matplotlib.pyplot as p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other packages that will be useful in this notebook\n",
    "Dependencies for data processing and manipulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data for Visuatization\n",
    "This cell fetches a variety example datasets from the cloud for visualization. This can take a bit of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cedalion\n",
    "import cedalion.datasets\n",
    "import cedalion.io\n",
    "import cedalion.imagereco.forward_model as fw\n",
    "\n",
    "# Loads a high-density finger tapping fNIRS example snirf dataset into a recording container\n",
    "cedalion.units\n",
    "rec = cedalion.datasets.get_fingertappingDOT()\n",
    "\n",
    "# Loads a photogrammetric example scan\n",
    "fname_scan, fname_snirf, fname_montage = cedalion.datasets.get_photogrammetry_example_scan()\n",
    "pscan = cedalion.io.read_einstar_obj(fname_scan)\n",
    "\n",
    "# Loads a precalculated example fluence profile that does not belong with this recording though\n",
    "fluence_all, fluence_at_optodes = cedalion.datasets.get_precomputed_fluence(\"fingertappingDOT\", \"colin27\")\n",
    "\n",
    "# Lads a segmented MRI Scan (here the Colin27 average brain) and creates a TwoSurfaceHeadModel\n",
    "SEG_DATADIR, mask_files, landmarks_file = cedalion.datasets.get_colin27_segmentation()\n",
    "head = fw.TwoSurfaceHeadModel.from_segmentation(\n",
    "    segmentation_dir=SEG_DATADIR,\n",
    "    mask_files = mask_files,\n",
    "    landmarks_ras_file=landmarks_file\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Time Series Using Matplotlib\n",
    "We are working on a nice function that abstracts most of the work away from you. Until then you will have use standard python matplotlib functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cedalion.nirs as nirs\n",
    "import cedalion.plots as plots\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# calculate HbO/HbR from raw data\n",
    "dpf = xr.DataArray(\n",
    "        [6, 6],\n",
    "        dims=\"wavelength\",\n",
    "        coords={\"wavelength\": rec[\"amp\"].wavelength},\n",
    "    )\n",
    "rec[\"conc\"] = nirs.beer_lambert(rec[\"amp\"], rec.geo3d, dpf, spectrum = \"prahl\")\n",
    "# rename events\n",
    "rec.stim.cd.rename_events(\n",
    "        {\"1\": \"rest\", \"2\": \"Tapping/Left\", \"3\": \"Tapping/Right\", \"4\": \"Squeezing/Left\", \"5\": \"Squeezing/Right\"}\n",
    "    )\n",
    "\n",
    "# select which time series we work with\n",
    "ts = rec[\"conc\"]\n",
    "\n",
    "# Thanks to the xarray DataArray structure, we can easily select the data we want to plot\n",
    "# plot four channels and their stim markers\n",
    "f, ax = plt.subplots(4, 1, sharex=True, figsize=(12, 6))\n",
    "for i, ch in enumerate([\"S1D1\", \"S1D2\", \"S7D9\", \"S7D11\"]):\n",
    "    ax[i].plot(ts.time, ts.sel(channel=ch, chromo=\"HbO\"), \"r-\", label=\"HbO\")\n",
    "    ax[i].plot(ts.time, ts.sel(channel=ch, chromo=\"HbR\"), \"b-\", label=\"HbR\")\n",
    "    ax[i].set_title(f\"Ch. {ch}\")\n",
    "    # add stim markers using Cedalion's plot_stim_markers function\n",
    "    cedalion.plots.plot_stim_markers(ax[i], rec.stim, y=1)\n",
    "    ax[i].set_ylabel(r\"$\\Delta$ c / uM\")\n",
    "\n",
    "ax[0].legend(ncol=6)\n",
    "ax[3].set_label(\"time / s\")\n",
    "ax[3].set_xlim(0,100)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalp Plot\n",
    "Plots a metric, e.g. channel quality or amplitude at a time point on the scalp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbsphinx-thumbnail"
    ]
   },
   "outputs": [],
   "source": [
    "import cedalion.plots as plots\n",
    "import cedalion.sigproc.quality as quality\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "n_channels = len(rec[\"amp\"].channel)\n",
    "# Calculate channel SNR to display as a metric in the plot\n",
    "snr, snr_mask = quality.snr(rec[\"amp\"], 3)\n",
    "# the plots \"metric\" input needs dimension (nchannels,) so we focus on the 760nm wavelength for each channel\n",
    "snr_metric = snr.sel(wavelength=\"760\").values\n",
    "\n",
    "# Create scalp plot showing SNR in each channel\n",
    "fig, ax = plt.subplots(1,1)\n",
    "plots.scalp_plot(\n",
    "    rec[\"amp\"],\n",
    "    rec.geo3d,\n",
    "    snr_metric, \n",
    "    ax, \n",
    "    cmap=\"jet\", title='760nm Channel SNR Scalp Plot', vmin=0, vmax=n_channels, cb_label=\"SNR\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Time Series Using an interactive GUI\n",
    "run_vis() from the vis.timeseries package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cedalion.vis import time_series\n",
    "\n",
    "# this calls a GUI to interactively select channels from a 2D probe. \n",
    "# Input is a recording container, you can choose which time series (e.g. raw, OD, concentrations) in the container  to plot\n",
    "\n",
    "# UNCOMMENT to use the GUI. Commented out for documentation autogeneration purposes.\n",
    "#time_series.run_vis(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![GUI_Snapshot](../../docs/img/time_series_guiexample.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting an fNIRS Montage in 3D\n",
    "Using **plot_montage3D()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cedalion.plots\n",
    "\n",
    "# use the plot_montage3D() function. It requires a recording container and a geo3d object\n",
    "cedalion.plots.plot_montage3D(rec[\"amp\"], rec.geo3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting a Headmodel\n",
    "For instance the default Colin27 or ICBM152, using **plot_surface()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cedalion.plots\n",
    "\n",
    "plt = pv.Plotter()\n",
    "cedalion.plots.plot_surface(plt, head.brain, color=\"#d3a6a1\")\n",
    "cedalion.plots.plot_surface(plt, head.scalp, opacity=.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a montage to the headmodel\n",
    "For this the montage has to be registered to the headmodel's scalp first. Then we use **plot_labeled_points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo3d_snapped = head.align_and_snap_to_scalp(rec.geo3d)\n",
    "\n",
    "# now we plot the head same as before...\n",
    "plt = pv.Plotter()\n",
    "cedalion.plots.plot_surface(plt, head.brain, color=\"#d3a6a1\")\n",
    "cedalion.plots.plot_surface(plt, head.scalp, opacity=.1)\n",
    "# but use the plot_labeled_points() function to add the snapped geo3d. The flag \"show_labels\" can be used to show the source, detector, and landmark names \n",
    "cedalion.plots.plot_labeled_points(plt, geo3d_snapped, show_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also easily remove the EEG landmarks for a better visual..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cedalion.dataclasses as cdc\n",
    "# keep only points that are not of type \"landmark\", i.e. source and detector points\n",
    "geo3d_snapped = geo3d_snapped[geo3d_snapped.type != cdc.PointType.LANDMARK]\n",
    "\n",
    "# now we plot the head same as before...\n",
    "plt = pv.Plotter()\n",
    "cedalion.plots.plot_surface(plt, head.brain, color=\"#d3a6a1\")\n",
    "cedalion.plots.plot_surface(plt, head.scalp, opacity=.1)\n",
    "# but use the plot_labeled_points() function to add the snapped geo3d. The flag \"show_labels\" can be used to show the source, detector, and landmark names \n",
    "cedalion.plots.plot_labeled_points(plt, geo3d_snapped, show_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surface Plot of 3D Scans\n",
    "Uses the same function as for head models, **plot_surface()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cedalion.plots\n",
    "\n",
    "plt = pv.Plotter()\n",
    "get_landmarks = cedalion.plots.plot_surface(plt, pscan, opacity=1.0)\n",
    "plt.show(interactive = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive 3D Plot to select Landmarks\n",
    "using **plot_surface** with \"pick_landmarks = True\". Here we use a photogrammetric scan, and the landmarks are indicated by green dots. Right-clicking again on an existing landmark changes the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cedalion.plots\n",
    "\n",
    "plt = pv.Plotter()\n",
    "get_landmarks = cedalion.plots.plot_surface(plt, pscan, opacity=1.0, pick_landmarks = True)\n",
    "plt.show(interactive = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for documentation purposes and to enable automatically rendered example notebooks we provide the hand-picked coordinates here too.\n",
    "landmark_labels = ['Nz', 'Iz', 'Cz', 'Lpa', 'Rpa']\n",
    "landmark_coordinates = [np.array([14.00420712, -7.84856869, 449.77840004]), \n",
    "                                  np.array([99.09920059, 29.72154755, 620.73876117]),\n",
    "                                  np.array([161.63815139, -48.49738938, 494.91210993]),\n",
    "                                  np.array([82.8771277, 79.79500128, 498.3338802]),\n",
    "                                  np.array([15.17214095, -60.56186128, 563.29621021])]\n",
    "\n",
    "# uncommentif you want to see your own picked results: when you are done run get_landmarks() to get the landmarks. \n",
    "# landmark_coordinates, landmark_labels = get_landmarks()\n",
    "display (landmark_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Probe Fluence / Sensitivity on Cortex\n",
    "Plot the fluence between a source-detector pair, or the accumulated sensitivity profile on the cortex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fluence between two optodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cedalion.plots\n",
    "\n",
    "# pull fluence values from the corresponding source and detector pair\n",
    "f = fluence_all.loc[\"S12\", 760].values * fluence_all.loc[\"D19\",760].values\n",
    "f[f<=0] = f[f>0].min()\n",
    "f = np.log10(f)\n",
    "vf = pv.wrap(f)\n",
    "\n",
    "plt = pv.Plotter()\n",
    "\n",
    "# plot fluence values\n",
    "plt.add_volume(\n",
    "    vf,\n",
    "    log_scale=False, \n",
    "    cmap='plasma_r',\n",
    "    clim=(-10,0),\n",
    ")\n",
    "# add head model\n",
    "cedalion.plots.plot_surface(plt, head.brain, color=\"#d3a6a1\")\n",
    "cedalion.plots.plot_surface(plt, head.scalp, opacity=.1)\n",
    "cedalion.plots.plot_labeled_points(plt, geo3d_snapped, show_labels=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Sensitivity Profile on Cortex\n",
    "Using the calculated fluence. This will be simplified in the future to make it easier for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cedalion.vis import plot_sensitivity_matrix\n",
    "import cedalion.imagereco.forward_model as fwm\n",
    "\n",
    "# to plot sensitivity on the cortex we need a forward model\n",
    "fwm = cedalion.imagereco.forward_model.ForwardModel(head, geo3d_snapped, rec._measurement_lists[\"amp\"])\n",
    "Adot = fwm.compute_sensitivity(fluence_all, fluence_at_optodes)\n",
    "\n",
    "\n",
    "plotter = plot_sensitivity_matrix.Main(\n",
    "    sensitivity=Adot,\n",
    "    brain_surface=head.brain,\n",
    "    head_surface=head.scalp,\n",
    "    labeled_points=geo3d_snapped,\n",
    ")\n",
    "plotter.plot(high_th=0, low_th=-3)\n",
    "plotter.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ImageRecon HRF Activation (from HD fNIRS/DOT) on Cortex\n",
    "Since this requires a lot of preprocessing, please use the Image Reconstruction Jupyter Example Notebook [HERE](https://github.com/ibs-lab/cedalion/blob/main/examples/image_reconstruction.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cedalion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
