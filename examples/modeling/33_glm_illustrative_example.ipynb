{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLM Illustrative Example\n",
    "\n",
    "This notebook explores cedalion's GLM functionality. Using simulated timeseries with a known 'ground truth' allows us to clearly see how the GLM works. We fit several different models to the timeseries and showcase the GLM statistics afforded by cedalion's statsmodels integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cells setups the environment when executed in Google Colab.\n",
    "try:\n",
    "    import google.colab\n",
    "    !curl -s https://raw.githubusercontent.com/ibs-lab/cedalion/dev/scripts/colab_setup.py -o colab_setup.py\n",
    "    # Select branch with --branch \"branch name\" (default is \"dev\")\n",
    "    %run colab_setup.py\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cedalion\n",
    "import cedalion.io\n",
    "import cedalion.nirs\n",
    "import cedalion.dataclasses as cdc\n",
    "import cedalion.models.glm as glm\n",
    "import cedalion.plots as plots\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as p\n",
    "import pandas as pd\n",
    "from cedalion import units\n",
    "from cedalion.sim.synthetic_hrf import RandomGaussianSum\n",
    "xr.set_options(display_expand_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a simple simulated timeseries\n",
    "\n",
    "In this section, we simulate an fNIRS timeseries by generating some random noise and then adding a simple HRF regressor.\n",
    "\n",
    "### 1. Build a NDTimeSeries with noise\n",
    "\n",
    "First, we'll use the utility function `build_timeseries` to create a timeseries containing normally distributed noise. The `build_timeseries` function takes the following arguments:\n",
    "- data : The data values.\n",
    "- dims : The dimension names.\n",
    "- time : The time values.\n",
    "- channel : The channel names.\n",
    "- value_units : The units of the data values.\n",
    "- time_units : The units of the time values.\n",
    "- other_coords : dict[str, ArrayLike] Additional coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fs = 10.0 * cedalion.units.Hz # sampling rate\n",
    "T = 240 * cedalion.units.s # time series length\n",
    "channel = [\"S1D1\", \"S1D2\"] # two channels\n",
    "chromo = [\"HbO\", \"HbR\"] # two chromophores\n",
    "nsample = int(T * fs)  # number of samples\n",
    "\n",
    "# create a NDTimeSeries that contains normal distributed noise\n",
    "ts = cdc.build_timeseries(\n",
    "    np.random.normal(0, 0.05, (nsample, len(channel), len(chromo))),\n",
    "    dims=[\"time\", \"channel\", \"chromo\"],\n",
    "    time=np.arange(nsample) / fs,\n",
    "    channel=channel,\n",
    "    value_units=units.uM,\n",
    "    time_units=units.s,\n",
    "    other_coords={\"chromo\": chromo},\n",
    ")\n",
    "display(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build the Stimulus DataFrame\n",
    "\n",
    "A stimulus Dataframe contains information about the experimental stimuli. It should have columns 'trial_type', 'onset', 'duration' and 'value'.\n",
    "\n",
    "In this example, we specify two trial types: 'StimA', 'StimB' and define for each 3 trials with a duration of 10s.\n",
    "\n",
    "The trials get different values assigned, which we'll use to control the amplitude of the hemodynamic response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim = pd.concat(\n",
    "    (\n",
    "        pd.DataFrame({\"onset\": o, \"trial_type\": \"StimA\"} for o in [10, 80, 150]),\n",
    "        pd.DataFrame({\"onset\": o, \"trial_type\": \"StimB\"} for o in [45, 115, 185]),\n",
    "    )\n",
    ")\n",
    "\n",
    "stim[\"value\"] = [0.5, 1, 1.5, 1.25, 0.75, 1.0]\n",
    "stim[\"duration\"] = 10.\n",
    "display(stim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a Design Matrix\n",
    "\n",
    "We'll use cedalion's design matrix functionality to create a simulated HRF function that we can add to our timeseries.\n",
    "\n",
    "We build a design matrix by concatenating different regressors. The regressor functions are found in `glm.design_matrix`. A regressor or sum of regressors returns a `DesignMatrix` object with two attributes:\n",
    "  1. common (xr.DataArray): regressors that apply to all channels, e.g.\n",
    "    - HRF regressors\n",
    "    - drift regressors\n",
    "    - constant term\n",
    "  2. channel_wise (list[xr.DataArray]): regressors that can differ between channels. The motivating use-case is short-distance channel regression, in which one describes superficial components in long channels with a regressor made from a nearby short channel. \n",
    "\n",
    "The functional form of the HRF regressors is specified by the `basis_function` argument. Please refer to the notebook `glm_basis_functions.ipynb` and the documentation for more details. In this section, we use the `Gamma` basis function, which takes these arguments:\n",
    "- tau: specifies a delay of the response with respect ot stimulus onset time.\n",
    "- sigma: specifies the width of the hemodynamic reponse.\n",
    "- T: If > 0, the response is additionally convoluted by a square wave of this width.\n",
    "\n",
    "`DesignMatrix.common` stores regressors in an `xr.DataArray` with dimensions 'time', 'chromo' (or 'wavelength') and 'regressor'.\n",
    "\n",
    "Each regressor has a string label for clarity. The convention used by cedalion regressor functions is to\n",
    "use labels of the form `'HRF <trial_typ> <number>'` for the HRF regressors and `'Drift <number>'` for the\n",
    "drift components. \n",
    "\n",
    "Using such a schema is convenient when one needs to select regressors. If there would be multiple regressors \n",
    "for stimulus \"StimA\" one could distinguish all these from other HRF or drift regressors by selecting labels \n",
    "that start with 'HRF StimA'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design matrix built by concatenating the HRF and drift regressors\n",
    "dms = (\n",
    "    glm.design_matrix.hrf_regressors(\n",
    "        ts, stim, glm.Gamma(tau=0 * units.s, sigma=5 * units.s)\n",
    "    )\n",
    "    & glm.design_matrix.drift_regressors(ts, drift_order=0)\n",
    ")\n",
    "display(dms.common) \n",
    "dm = dms.common # there are no channel-wise regressors in this example\n",
    "\n",
    "# For this use case we want the HbR regressors to be \n",
    "# inverted and smaller in amplitude than their HbO counterparts.\n",
    "dm.loc[:, [\"HRF StimA\", \"HRF StimB\"], \"HbR\"] *= -0.25\n",
    "\n",
    "# Plot the design matrix/regressors\n",
    "f, ax = p.subplots(1,2,figsize=(12,5))\n",
    "dm.sel(chromo=\"HbO\").plot(ax=ax[0], vmin=-1, vmax=1, cmap='RdBu_r')\n",
    "dm.sel(chromo=\"HbR\").plot(ax=ax[1], vmin=-1, vmax=1, cmap='RdBu_r')\n",
    "p.xticks(rotation=90)\n",
    "p.show()\n",
    "\n",
    "f, ax = p.subplots(1,2,figsize=(12,3))\n",
    "for i,chromo in enumerate(dm.chromo.values):\n",
    "    for reg in dm.regressor.values:\n",
    "        ax[i].plot(dm.time, dm.sel(chromo=chromo, regressor=reg), label=reg)\n",
    "    plots.plot_stim_markers(ax[i], stim, y=1)\n",
    "    ax[i].set_title(f\"chromo={chromo}\")\n",
    "    ax[i].legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Add regressors to time series with noise\n",
    "\n",
    "The time series has two channels: 'S1D1' and 'S1D2'. In this toy example the stimuli will correspond to distinct channels: activations from trial 'StimA' should occur only in 'S1D1', and 'StimB' activations occur only in 'S1D2'.\n",
    "\n",
    "The regressors are added with different offsets and scaling factors, which determine the amplitude of the function. Later on we will compare our GLM results to these 'ground truth' amplitude values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define offsets and scaling factors\n",
    "SCALE_STIMA = 1.25\n",
    "OFFSET_STIMA = 0.5\n",
    "SCALE_STIMB = 0.75\n",
    "OFFSET_STIMB = 0.25\n",
    "\n",
    "# add scaled regressor and offsets to time series, which up to now contains only noise\n",
    "ts.loc[:, \"S1D1\", :] += (\n",
    "    SCALE_STIMA * dm.sel(regressor=\"HRF StimA\").pint.quantify(\"uM\")\n",
    "    + OFFSET_STIMA * cedalion.units.uM\n",
    ")\n",
    "ts.loc[:, \"S1D2\", :] += (\n",
    "    SCALE_STIMB * dm.sel(regressor=\"HRF StimB\").pint.quantify(\"uM\")\n",
    "    + OFFSET_STIMB * cedalion.units.uM\n",
    ")\n",
    "\n",
    "# plot original regressors for StimA and StimB\n",
    "f, ax = p.subplots(1, 2, sharex=True, sharey=True, figsize=(12,3))\n",
    "for i, reg in enumerate([\"HRF StimA\", \"HRF StimB\"]):\n",
    "    ax[i].plot(dm.time, dm.sel(regressor=reg, chromo=\"HbO\"), \"r-\")\n",
    "    ax[i].plot(dm.time, dm.sel(regressor=reg, chromo=\"HbR\"), \"b-\")\n",
    "    ax[i].set_title(f\"Reg {reg}\")\n",
    "    plots.plot_stim_markers(ax[i], stim, y=1)\n",
    "    ax[i].grid(True)\n",
    "p.tight_layout()\n",
    "\n",
    "# plot the resulting time series\n",
    "f, ax = p.subplots(1, 2, sharex=True, sharey=True, figsize=(12,3))\n",
    "for i, ch in enumerate(ts.channel.values):\n",
    "    ax[i].plot(ts.time, ts.sel(channel=ch, chromo=\"HbO\"), \"r-\")\n",
    "    ax[i].plot(ts.time, ts.sel(channel=ch, chromo=\"HbR\"), \"b-\")\n",
    "    ax[i].set_title(f\"Ch {ch}\")\n",
    "    ax[i].grid(True)\n",
    "    plots.plot_stim_markers(ax[i], stim, y=1)\n",
    "p.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the GLM - using the same design matrix\n",
    "\n",
    "In this section, we'll fit our simulated timeseries using the same design matrix that we used to create it, just to make sure that everything is working as expected.\n",
    "\n",
    "The method `glm.fit` is used to fit the GLM to the time series. The required arguments are timeseries and design matrix. We can optionally specify the noise model from the following currently available options:\n",
    "- ols (default): ordinary least squares\n",
    "- rls: recursive least squares\n",
    "- wls: weighted least squares\n",
    "- ar_irls: autoregressive iteratively reweighted least squares\n",
    "    (:cite:t:`Barker2013`)\n",
    "- gls: generalized least squares\n",
    "- glsar: generalized least squares with autoregressive covariance structure\n",
    "\n",
    "The fit method returns an `xr.DataArray` of statsmodels `RegressionResults` objects with dimensions (channel, chromo). Any `RegressionResults` method can be called on this `DataArray` using the `.sm` accessor. For example, we access the betas or model coefficients by using `result.sm.params`. Please refer to the [statsmodels documentation](https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.RegressionResults.html) for a full list of methods and attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = glm.fit(ts, dms, noise_model=\"ols\")\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = result.sm.params\n",
    "betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll display our coefficiients in table.\n",
    "\n",
    "The weights of the fitted model should correspond to the amplitudes of our original timeseries, which we know are just the scaling factors and offsets that we used above. We'll add these amplitude values in an additional column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = betas.rename(\"betas_S1D1\").to_dataframe()\n",
    "# add a column with expected values\n",
    "df[\"Expected\"] = [\n",
    "    SCALE_STIMA, 0.0, OFFSET_STIMA, \n",
    "    SCALE_STIMA, 0.0, OFFSET_STIMA,\n",
    "    0.0, SCALE_STIMB, OFFSET_STIMB,\n",
    "    0.0, SCALE_STIMB, OFFSET_STIMB,\n",
    "]\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use the design matrix and fitted coefficients to predict the timeseries using glm.predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to compare original time series and model prediction\n",
    "def plot_data_to_fit_comparison(ts, pred, stim):\n",
    "    f, ax = p.subplots(2,1, sharex=True, figsize=(12,4))\n",
    "    for i, ch in enumerate(ts.channel.values):\n",
    "        ax[i].plot(ts.time, ts.sel(channel=ch, chromo=\"HbO\"), \"r-\")\n",
    "        ax[i].plot(ts.time, ts.sel(channel=ch, chromo=\"HbR\"), \"b-\")\n",
    "        ax[i].plot(pred.time, pred.sel(channel=ch, chromo=\"HbO\"), \"-\", c=\"#e41a1c\", lw=2)\n",
    "        ax[i].plot(pred.time, pred.sel(channel=ch, chromo=\"HbR\"), \"-\", c=\"#377eb8\", lw=2)\n",
    "        ax[i].set_title(f\"Ch {ch}\")\n",
    "        plots.plot_stim_markers(ax[i], stim, y=1)\n",
    "    p.tight_layout()\n",
    "\n",
    "# use all regressors of the design matrix to predict the time series\n",
    "pred = glm.predict(ts, betas, dms)\n",
    "display(pred)\n",
    "plot_data_to_fit_comparison(ts, pred, stim)\n",
    "\n",
    "\n",
    "# use only HRF-related regressors, i.e. remove the drift/offset\n",
    "pred = glm.predict(\n",
    "    ts,\n",
    "    # select regressor whose label start with HRF Stim\n",
    "    betas.sel(regressor=betas.regressor.str.startswith(\"HRF Stim\")),\n",
    "    dms\n",
    ")\n",
    "plot_data_to_fit_comparison(ts, pred, stim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the GLM - this time using a slightly different model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we create a new design matrix that encodes less prior knowledge about the timeseries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the stimulus DataFrame and set all values to 1, i.e.\n",
    "# there is no prior knowledge about amplitude differences between trials\n",
    "stim_other = stim.copy()\n",
    "stim_other[\"value\"] = 1.\n",
    "display(stim_other)\n",
    "\n",
    "# this design matrix also uses Gamma basis functions but \n",
    "# the onset (tau) is delayed and the HRF width (sigma) is longer.\n",
    "dms_other = (\n",
    "    glm.design_matrix.hrf_regressors(\n",
    "        ts, stim, glm.Gamma(tau=1 * units.s, sigma=7 * units.s)\n",
    "    )\n",
    "    & glm.design_matrix.drift_regressors(ts, drift_order=0)\n",
    ")\n",
    "\n",
    "\n",
    "betas = glm.fit(ts, dms_other, noise_model=\"ols\").sm.params\n",
    "\n",
    "# display the fitted betas as a DataFrame\n",
    "display(betas.rename(\"betas_S1D1\").to_dataframe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = glm.predict(ts, betas, dms_other)\n",
    "display(pred)\n",
    "plot_data_to_fit_comparison(ts, pred, stim_other)\n",
    "\n",
    "\n",
    "pred = glm.predict(\n",
    "    ts,\n",
    "    betas.sel(regressor=betas.regressor.str.startswith(\"HRF Stim\")),\n",
    "    dms_other\n",
    ")\n",
    "plot_data_to_fit_comparison(ts, pred, stim_other)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a new, more complicated time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll build a more complicated simulated HRF, following the same steps as in the first part of this notebook. The only thing we do differently is pass a different basis function (`RandomGaussianSum`) to `glm.design_matrix.hrf_regressors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fs = 10.0 * cedalion.units.Hz # sampling rate\n",
    "T = 240 * cedalion.units.s # time series length\n",
    "channel = [\"S1D1\", \"S1D2\"] # two channels\n",
    "chromo = [\"HbO\", \"HbR\"] # two chromophores\n",
    "nsample = int(T * fs)  # number of samples\n",
    "\n",
    "# create a NDTimeSeries that contains normal distributed noise\n",
    "ts = cdc.build_timeseries(\n",
    "    np.random.normal(0, 0.05, (nsample, len(channel), len(chromo))),\n",
    "    dims=[\"time\", \"channel\", \"chromo\"],\n",
    "    time=np.arange(nsample) / fs,\n",
    "    channel=channel,\n",
    "    value_units=units.uM,\n",
    "    time_units=units.s,\n",
    "    other_coords={\"chromo\": chromo},\n",
    ")\n",
    "\n",
    "# Create a design matrix with a random Gaussian sum HRF\n",
    "dms = (\n",
    "    glm.design_matrix.hrf_regressors(\n",
    "        ts, stim, RandomGaussianSum(\n",
    "    t_start=0 * units.s,\n",
    "    t_end=30 * units.s,\n",
    "    t_delta=2 * units.s,\n",
    "    t_std=3 * units.s,\n",
    "    seed=22,\n",
    ")\n",
    "    )\n",
    "    & glm.design_matrix.drift_regressors(ts, drift_order=0)\n",
    ")\n",
    "\n",
    "dm = dms.common # there are no channel-wise regressors in this example\n",
    "\n",
    "# For this simulated example we again want the HbR regressors to be \n",
    "# inverted and smaller in amplitude than their HbO counterparts.\n",
    "dm.loc[:, [\"HRF StimA\", \"HRF StimB\"], \"HbR\"] *= -0.25\n",
    "\n",
    "# define offsets and scaling factors\n",
    "SCALE_STIMA = 1.25\n",
    "OFFSET_STIMA = 0.5\n",
    "SCALE_STIMB = 0.75\n",
    "OFFSET_STIMB = 0.25\n",
    "\n",
    "# add scaled regressor and offsets to time series, which up to now contains only noise\n",
    "ts.loc[:, \"S1D1\", :] += (\n",
    "    SCALE_STIMA * dm.sel(regressor=\"HRF StimA\").pint.quantify(\"uM\")\n",
    "    + OFFSET_STIMA * cedalion.units.uM\n",
    ")\n",
    "ts.loc[:, \"S1D2\", :] += (\n",
    "    SCALE_STIMB * dm.sel(regressor=\"HRF StimB\").pint.quantify(\"uM\")\n",
    "    + OFFSET_STIMB * cedalion.units.uM\n",
    ")\n",
    "\n",
    "# plot original regressors for StimA and StimB\n",
    "f, ax = p.subplots(1, 2, sharex=True, sharey=True, figsize=(12,3))\n",
    "for i, reg in enumerate([\"HRF StimA\", \"HRF StimB\"]):\n",
    "    ax[i].plot(dm.time, dm.sel(regressor=reg, chromo=\"HbO\"), \"r-\")\n",
    "    ax[i].plot(dm.time, dm.sel(regressor=reg, chromo=\"HbR\"), \"b-\")\n",
    "    ax[i].set_title(f\"Reg {reg}\")\n",
    "    plots.plot_stim_markers(ax[i], stim, y=1)\n",
    "    ax[i].grid(True)\n",
    "p.tight_layout()\n",
    "\n",
    "# plot the resulting time series\n",
    "f, ax = p.subplots(1, 2, sharex=True, sharey=True, figsize=(12,3))\n",
    "for i, ch in enumerate(ts.channel.values):\n",
    "    ax[i].plot(ts.time, ts.sel(channel=ch, chromo=\"HbO\"), \"r-\")\n",
    "    ax[i].plot(ts.time, ts.sel(channel=ch, chromo=\"HbR\"), \"b-\")\n",
    "    ax[i].set_title(f\"Ch {ch}\")\n",
    "    ax[i].grid(True)\n",
    "    plots.plot_stim_markers(ax[i], stim, y=1)\n",
    "p.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the GLM - Uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this section is to showcase some uncertainty measurements of the GLM fit that are accessible through statsmodels. First, we'll create a simple design matrix using gamma basis functions, following the same steps as in the previous sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dms_simple = (\n",
    "    glm.design_matrix.hrf_regressors(\n",
    "        ts, stim, glm.Gamma(tau=0 * units.s, sigma=5 * units.s)\n",
    "    )\n",
    "    & glm.design_matrix.drift_regressors(ts, drift_order=0)\n",
    ")\n",
    "\n",
    "dm_simple = dms_simple.common\n",
    "\n",
    "dm_simple.loc[:, [\"HRF StimA\", \"HRF StimB\"], \"HbR\"] *= -0.25 # invert HbR regressors\n",
    "\n",
    "f, ax = p.subplots(1,2,figsize=(12,5))\n",
    "dm_simple.sel(chromo=\"HbO\").plot(ax=ax[0], vmin=-1, vmax=1, cmap='RdBu_r')\n",
    "dm_simple.sel(chromo=\"HbR\").plot(ax=ax[1], vmin=-1, vmax=1, cmap='RdBu_r')\n",
    "p.xticks(rotation=90)\n",
    "p.show()\n",
    "\n",
    "f, ax = p.subplots(1,2,figsize=(12,3))\n",
    "for i,chromo in enumerate(dm_simple.chromo.values):\n",
    "    for reg in dm_simple.regressor.values:\n",
    "        ax[i].plot(dm_simple.time, dm_simple.sel(chromo=chromo, regressor=reg), label=reg)\n",
    "    plots.plot_stim_markers(ax[i], stim, y=1)\n",
    "    ax[i].set_title(f\"chromo={chromo}\")\n",
    "    ax[i].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we fit the GLM and showcase some useful uncertainty measures. As noted above, the `glm.fit` function returns a `DataArray` of `statsmodels RegressionResults` objects, and the full list of available methods can be found in the [statsmodels documentation](https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.RegressionResults.html). Here, we calculate the standard error, variance, and confidence intervals of our GLM coefficients.\n",
    "\n",
    "Even though our HRF is more complicated now, the weights of the fitted simple model should still roughly correspond to the max amplitudes of our original timeseries (TS Amplitude), which we know are just the scaling factors and offsets that we used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model to the time series\n",
    "result = glm.fit(ts, dms_simple, noise_model=\"ols\")\n",
    "betas = result.sm.params\n",
    "\n",
    "# display the fitted betas as a DataFrame\n",
    "df = betas.rename(\"betas_S1D1\").to_dataframe()\n",
    "# add a column with expected values\n",
    "df[\"TS Amplitude\"] = [\n",
    "    SCALE_STIMA, 0.0, OFFSET_STIMA, \n",
    "    SCALE_STIMA, 0.0, OFFSET_STIMA,\n",
    "    0.0, SCALE_STIMB, OFFSET_STIMB,\n",
    "    0.0, SCALE_STIMB, OFFSET_STIMB,\n",
    "]\n",
    "\n",
    "# calculate uncertainty measures and add to table\n",
    "df[\"Standard Error\"] = result.sm.bse.rename(\"Standard Error\").to_dataframe() # standard error\n",
    "conf_int_df = result.sm.conf_int().to_dataframe(name=\"conf_int\").unstack() # confidence intervals\n",
    "conf_int_df.columns = [\"Confidence Interval Lower\", \"Confidence Interval Upper\"]\n",
    "df = df.join(conf_int_df)\n",
    "df[\"Variance\"] = result.sm.regressor_variances().rename(\"Variance\").to_dataframe() # variance\n",
    "\n",
    "# reorder columns\n",
    "df = df[[\"TS Amplitude\", \"Confidence Interval Lower\", \"betas_S1D1\", \"Confidence Interval Upper\", \"Standard Error\", \"Variance\"]]\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we plot the model prediction and compare it to the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use all regressors of the design matrix to predict the time series\n",
    "pred = glm.predict(ts, betas, dms_simple)\n",
    "display(pred)\n",
    "plot_data_to_fit_comparison(ts, pred, stim)\n",
    "\n",
    "\n",
    "# use only HRF-related regressors, i.e. remove the drift/offset\n",
    "pred = glm.predict(\n",
    "    ts,\n",
    "    # select regressor whose label start with HRF Stim\n",
    "    betas.sel(regressor=betas.regressor.str.startswith(\"HRF Stim\")),\n",
    "    dms_simple\n",
    ")\n",
    "plot_data_to_fit_comparison(ts, pred, stim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting with multiple gaussian kernels\n",
    "\n",
    "In this section, we'll build a new design matrix using the `GaussianKernels` basis function. This basis function consists of multiple time-shifted gaussians. Therefore, the model is capable of describing also more complex hemodynamic repsonse - like the one we just simulated. However, the obtained coefficients are not as easy to interprete as in the simpler model above. There the size of the coefficient directly related to the amplitude of the response. Here, the coefficients of the Gaussians encode both the shape and the amplitude.\n",
    "\n",
    "The GaussianKernels basis function takes the following arguments:\n",
    "- t_pre : time before trial onset\n",
    "- t_post : time after trial onset\n",
    "- t_delta : the temporal spacing between consecutive gaussians\n",
    "- t_std : time width of the gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build design matrix with Gaussian kernels\n",
    "dms_gauss = glm.design_matrix.hrf_regressors(\n",
    "    ts,\n",
    "    stim,\n",
    "    glm.GaussianKernels(\n",
    "        t_pre=5 * units.s, t_post=30 * units.s, t_delta=3 * units.s, t_std=2 * units.s\n",
    "    ),\n",
    ") & glm.design_matrix.drift_regressors(ts, drift_order=0)\n",
    "\n",
    "dm_gauss = dms_gauss.common\n",
    "\n",
    "# Plot the regressors\n",
    "f,ax = p.subplots(1,1, figsize=(12,4))\n",
    "for reg in dm_gauss.regressor.values:\n",
    "    p.plot(dm_gauss.time, dm_gauss.sel(chromo=\"HbO\", regressor=reg), label=reg)\n",
    "plots.plot_stim_markers(ax, stim, y=1.)\n",
    "p.legend(ncol=3, loc=\"center right\")\n",
    "p.xlim(0,90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the new design matrix to fit the GLM.\n",
    "\n",
    "Note that we have many regressors and thus no longer can easily infer the HRF amplitude from the coefficients. We also need a more sophisticated way to display the uncertainty of our fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the time series\n",
    "results = glm.fit(ts, dms_gauss, noise_model=\"ols\")\n",
    "betas = results.sm.params\n",
    "\n",
    "# translate the xr.DataArray into a pd.DataFrame which are displayed as tables\n",
    "display(betas.rename(\"betas_S1D1\").to_dataframe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again use the fitted model to predict the time series. This time, the prediction is quite accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = glm.predict(ts, betas, dms_gauss)\n",
    "plot_data_to_fit_comparison(ts, pred, stim)\n",
    "\n",
    "\n",
    "# use only HRF-related regressors, i.e. remove the drift/offset\n",
    "pred_stim = glm.predict(\n",
    "    ts,\n",
    "    # select regressor whose label start with HRF Stim\n",
    "    betas.sel(regressor=betas.regressor.str.startswith(\"HRF Stim\")),\n",
    "    dms_gauss\n",
    ")\n",
    "plot_data_to_fit_comparison(ts, pred_stim, stim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last part of the notebook, we'll explore some options for using a derived statistic to enable quantitative comparisons between the prediction and the original timeseries.\n",
    "\n",
    "First, we compare the peak amplitude and area under the curve of the prediction and the original timeseries. \n",
    "\n",
    "TODO: uncertainty measurements for these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate peak amplitude and area under the curve (AUC) for each channel and chromophore\n",
    "peak_amp_pred = pred.max(dim=[\"time\"]).to_dataframe(name=\"peak_amp_pred\")\n",
    "auc_pred = pred.integrate(coord=\"time\").to_dataframe(name=\"auc_pred\")\n",
    "\n",
    "# calculate peak amplitude and AUC for the original time series\n",
    "peak_amp_ts = ts.pint.dequantify().max(dim=[\"time\"]).to_dataframe(name=\"peak_amp_ts\")\n",
    "auc_ts = ts.pint.dequantify().integrate(coord=\"time\").to_dataframe(name=\"auc_ts\")\n",
    "\n",
    "# merge the results into a single DataFrame and display\n",
    "df = peak_amp_ts.join(peak_amp_pred).join(auc_ts).join(auc_pred)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we try out a way to visualize the uncertainty of the GLM fit. In the simple case, we could just look at the uncertainties of each coefficient. Now that we have so many coefficients, this is no longer feasible. \n",
    "\n",
    "This method visualizes the uncertainty in a GLM fit by drawing multiple samples of the beta coefficients from their estimated covariance (via multivariate normal sampling). It then uses these sampled betas to generate predicted time courses, and plots the mean prediction with a shaded band representing ±3 standard deviations across samples, thus capturing the variability due to model uncertainty. The band is quite narrow because uncertainty is low in this toy example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = results.sm.cov_params()\n",
    "sampled_betas = xr.zeros_like(betas).expand_dims({\"sample\" : 100}, axis=-1).copy()\n",
    "for i_ch in range(sampled_betas.shape[0]):\n",
    "    for i_cr in range(sampled_betas.shape[1]):\n",
    "        sampled_betas[i_ch, i_cr, :, :] = np.random.multivariate_normal(\n",
    "            betas[i_ch, i_cr, :],\n",
    "            cov[i_ch, i_cr, :, :],\n",
    "            size=100,\n",
    "        ).T\n",
    "pred = glm.predict(ts, sampled_betas, dms_gauss)\n",
    "\n",
    "pred_mean = pred.mean(\"sample\")\n",
    "pred_std = pred.std(\"sample\")\n",
    "mm = pred_mean.loc[slice(0,400), \"S1D1\", \"HbO\"]\n",
    "ss = pred_std.loc[slice(0,400), \"S1D1\", \"HbO\"]\n",
    "\n",
    "p.plot(mm.time, mm, c=\"r\")\n",
    "p.fill_between(mm.time, mm-3*ss, mm+3*ss, fc=\"y\", alpha=.8)\n",
    "\n",
    "p.xlabel(\"time / s\")\n",
    "p.ylabel(r\"$\\Delta$  c / uM\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cedalion_250621",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
